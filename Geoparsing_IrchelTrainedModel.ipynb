{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd2ed2-f0a0-43df-a360-5a9a68e83065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This set of scripts is for using your finely-tuned custom model \n",
    "with the Irchel Geoparser, NOT its pre-trained model \n",
    "\n",
    "(see \"Geoparsing_IrchelPreTrained\" Jupyter notebook file if you want to use the pre-trained model, \n",
    "but I would highly recommend training your own fine-tuned model like the one used below!)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1a373-6f9b-4733-85d9-9e044e3359c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for CUDA-enabled GPU. \n",
    "#If available (True), then Geoparser will automatically use the GPU.\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7b573-70a8-4c42-825c-2fd069cf8af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "With your trained model, you can use your custom model to parse new texts \n",
    "\n",
    "Here, we are specifying the trained transformer model's path when instantiating Geoparser\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from geoparser import Geoparser\n",
    "\n",
    "geo = Geoparser(transformer_model=\"C:/Users/....../TrainedModel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf52d23-2af1-46e1-84d2-788eee490474",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load your data...\n",
    "This create a comprehensive \"list of strings\" from all .txt files in a directory, which \n",
    "represents your data.\n",
    "You have to use \"f.read\" not \"f.readlines\".\n",
    "If you use \"f.readlines\" you get a list within a list, and the geoparser cannot read it!\n",
    "\"\"\"\n",
    "\n",
    "# This establishes the path to your data.\n",
    "import os\n",
    "path = \"C:/Users/YOUR_PATH/Data/\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    # Reads all .txt files in a directory and returns a list of their contents.\n",
    "\n",
    "    file_contents = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
    "                file_contents.append(f.read())\n",
    "    return file_contents\n",
    "\n",
    "texts = read_txt_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47c3b1-3795-4ac3-8e5d-29b74b426f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calls the GeoParser parse method, parses the 'texts',\n",
    "and limits the toponym resolution of location to France.\n",
    "\"\"\"\n",
    "\n",
    "docs = geo.parse(texts, country_filter=['FR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb0df3-f753-4d1c-ad79-75b21da8f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterates over the toponyms, showing their GeoName ID, latitude, and longitude,\n",
    "but limits the results to those which have a toponym resolution  \n",
    "thru using 'if toponym.location'\n",
    "\"\"\"\n",
    "\n",
    "for doc in docs:\n",
    "    for toponym in doc.toponyms:\n",
    "        if toponym.location:\n",
    "            print(toponym, toponym.location['geonameid'], toponym.location['latitude'], toponym.location['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81991871-6668-4f16-a6fd-a30b773da6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the results with the toponym, alternative names, administrative divisions, features type,\n",
    "and population.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "    identifiers = doc.locations['name', 'alternatenames', 'admin2_name', 'admin1_name', 'country_name', 'feature_name', 'population']\n",
    "    for toponym, identifier in zip(doc.toponyms, identifiers):\n",
    "        if toponym.location:\n",
    "            print(toponym, \"->\", identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269e2f09-2a16-4914-9ada-4b9a6f3b9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the results with the toponym, resolved location, features type, coordinates, and\n",
    "confidence score in the resolved location.\n",
    "\n",
    "If it was not resolved, it returns any unresolved toponyms as well.\n",
    "\"\"\"\n",
    "\n",
    "for doc in docs:\n",
    "    for toponym, location in zip(doc.toponyms, doc.locations):\n",
    "        print(f\"- Toponym: {toponym.text}\")\n",
    "        if toponym.location:\n",
    "            print(f\"  Resolved Location: {toponym.location['name'], toponym.location['admin2_name'], toponym.location['admin1_name'], toponym.location['country_name']}\")\n",
    "            print(f\"  Feature Type: {toponym.location['feature_name']}\")\n",
    "            print(f\"  Coordinates: {toponym.location['latitude'], toponym.location['longitude']}\")\n",
    "            print(f\"  Score: {toponym.score}\")\n",
    "            print(f\"  \")\n",
    "        else:\n",
    "            print(\"Location could not be resolved.\")\n",
    "            print(\"  \")\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c025a9-17ad-4499-a806-ee23be43f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This also returns the toponym and its resolved latitude and longitude coordinates, as well\n",
    "as any unresolved toponyms.\n",
    "\n",
    "It then create separate csv files of all resolved and unresolved toponyms via separate pandas dataframes.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Toponyms_Resolved = []\n",
    "Toponyms_UnResolved = []\n",
    "for doc in docs:\n",
    "    for toponym in doc.toponyms:\n",
    "        if toponym.location:\n",
    "            Toponyms_Resolved.append({\"Toponym\": toponym, \"Latitude\": toponym.location['latitude'], \"Longitude\": toponym.location['longitude']})\n",
    "        else:\n",
    "            Toponyms_UnResolved.append({\"Toponym UnResolved\": toponym})\n",
    "            \n",
    "df = pd.DataFrame(Toponyms_Resolved, dtype=\"string\")\n",
    "df_UnResolved = pd.DataFrame(Toponyms_UnResolved, dtype=\"string\")\n",
    "df.to_csv(\"C:/Users/....../Results_Geoparser_Resolved.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")\n",
    "df_UnResolved.to_csv(\"C:/Users/....../Results_Geoparser_UnResolved.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622a628-e1cc-4a05-bc25-da77e28562b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
