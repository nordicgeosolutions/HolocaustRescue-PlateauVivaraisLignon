{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2170699-e0fb-4f48-9357-d796c4d9d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This set of scripts is for using the Irchel Geoparser with its pre-trained model, \n",
    "not the fine-tuned model that you can create! \n",
    "\n",
    "(see \"Training_IrchelFineTunedModel\" and \"Geoparsing_IrchelTrainedModel\" Jupyter notebook files \n",
    "if you want to use the fine-tuned model, which is highly recommended!)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd95862-8152-4cfe-b69e-acded12a9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for CUDA-enabled GPU. \n",
    "#If available (True), then Geoparser will automatically use the GPU.\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25733f0e-e2e2-4c03-b648-6b9f144a1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load library and instantiate the geoparser.  Again, this is just the standard pre-trainined model, not \n",
    "the fine-tuned model.\n",
    "\"\"\"\n",
    "\n",
    "from geoparser import Geoparser\n",
    "\n",
    "geo = Geoparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398965e4-3bc1-4065-bc43-890a929edcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load your data...\n",
    "This create a comprehensive \"list of strings\" from all .txt files in a directory, which \n",
    "represents your data.\n",
    "You have to use \"f.read\" not \"f.readlines\".\n",
    "If you use \"f.readlines\" you get a list within a list, and the geoparser cannot read it!\n",
    "\"\"\"\n",
    "\n",
    "# This establishes the path to your data.\n",
    "import os\n",
    "path = \"C:/Users/YOUR_PATH/Data/\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    # Reads all .txt files in a directory and returns a list of their contents.\n",
    "\n",
    "    file_contents = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
    "                file_contents.append(f.read())\n",
    "    return file_contents\n",
    "\n",
    "texts = read_txt_files(path)\n",
    "\n",
    "# The following line prints the entire combined list of strings, so beware if it is a long set of data!\n",
    "print(texts) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea75ffa-76f0-4321-8c47-0f55fcfe6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calls the GeoParser parse method, parses the 'texts',\n",
    "and limits the toponym resolution of location to France.\n",
    "\"\"\"\n",
    "docs = geo.parse(texts, country_filter=['FR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868d9ab-51fc-4c15-915b-18ae40e338ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterates over the toponyms, giving starting and ending character location in the data,\n",
    "but limits the results to those which have a toponym resolution thru using 'if toponym.location'\n",
    "\"\"\"\n",
    "for doc in docs:\n",
    "    for toponym in doc.toponyms:\n",
    "        if toponym.location:\n",
    "            print(toponym, toponym.start_char, toponym.end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff84ee-24bb-40c5-b1fd-46d2ba985571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the results with their GeoName ID, latitude, and longitude\n",
    "\n",
    "for doc in docs:\n",
    "    for toponym in doc.toponyms:\n",
    "        if toponym.location:\n",
    "            print(toponym, toponym.location['geonameid'], toponym.location['latitude'], toponym.location['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d134973-8346-4b00-a462-b3a48f9ce450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the results with the toponym, alternative names, administrative divisions, features type,\n",
    "and population.\n",
    "\"\"\"\n",
    "\n",
    "for doc in docs:\n",
    "    identifiers = doc.locations['name', 'alternatenames', 'admin2_name', 'admin1_name', 'country_name', 'feature_name', 'population']\n",
    "    for toponym, identifier in zip(doc.toponyms, identifiers):\n",
    "        if toponym.location:\n",
    "            print(toponym, \"->\", identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a211557-216a-4951-873d-00f4a9f1076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the results with the toponym, resolved location, features type, coordinates, and\n",
    "confidence score in the resolved location.\n",
    "\n",
    "If it was not resolved, it returns any unresolved toponyms as well.\n",
    "\"\"\"\n",
    "\n",
    "for doc in docs:\n",
    "    for toponym, location in zip(doc.toponyms, doc.locations):\n",
    "        print(f\"- Toponym: {toponym.text}\")\n",
    "        if toponym.location:\n",
    "            print(f\"  Resolved Location: {toponym.location['name'], toponym.location['admin2_name'], toponym.location['admin1_name'], toponym.location['country_name']}\")\n",
    "            print(f\"  Feature Type: {toponym.location['feature_name']}\")\n",
    "            print(f\"  Coordinates: {toponym.location['latitude'], toponym.location['longitude']}\")\n",
    "            print(f\"  Score: {toponym.score}\")\n",
    "            print(f\"  \")\n",
    "        else:\n",
    "            print(\"Location could not be resolved.\")\n",
    "            print(\"  \")\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc18abd5-8b4f-415f-94c3-91ea8725c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This also returns the toponym and its resolved latitude and longitude coordinates, as well\n",
    "as any unresolved toponyms.\n",
    "\n",
    "It then create separate csv files of all resolved and unresolved toponyms via separate pandas dataframes.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Toponyms_Resolved = []\n",
    "Toponyms_UnResolved = []\n",
    "for doc in docs:\n",
    "    for toponym in doc.toponyms:\n",
    "        if toponym.location:\n",
    "            Toponyms_Resolved.append({\"Toponym\": toponym, \"Latitude\": toponym.location['latitude'], \"Longitude\": toponym.location['longitude']})\n",
    "        else:\n",
    "            Toponyms_UnResolved.append({\"Toponym UnResolved\": toponym})\n",
    "            \n",
    "df = pd.DataFrame(Toponyms_Resolved, dtype=\"string\")\n",
    "df_UnResolved = pd.DataFrame(Toponyms_UnResolved, dtype=\"string\")\n",
    "df.to_csv(\"C:/Users/....../Results_Geoparser_Resolved.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")\n",
    "df_UnResolved.to_csv(\"C:/Users/....../Results_Geoparser_UnResolved.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72184f-e09c-4311-bc33-e9dcdf9ae0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
