{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d9c5d-e989-45e2-8d85-1fa2a77561a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following set of scripts is for geoparsing directly using OpenAI's GPT-4.1 for both toponym \n",
    "recognition and resolution, with NO need for separate entity linking via a knowledge base.\n",
    "\n",
    "After enabling the GPU, it begins with loading the data for analysis.\n",
    "\n",
    "Then there are two different cells that essentially do the same thing, but the first cell (commented\n",
    "out) is if you require streaming of responses due to response size issues. \n",
    "\n",
    "Each of these cells load the libraries, instantiate the model, load the instructions file,\n",
    "then create and run the function using the parameter settings indicated. \n",
    "\n",
    "Then the responses are json normalized and then put into a pandas dataframe.\n",
    "\n",
    "These results are then exported to a csv file.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86cb0dd-3e07-4a27-8ce3-d215cb3b565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for CUDA-enabled GPU. \n",
    "#If available (True), then it will automatically use the GPU.\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea02a0b-938e-4a08-b8e9-84dea9839dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load your data...\n",
    "This create a combined string from all .txt files in a directory, which \n",
    "represents your data.\n",
    "You have to use \"f.read\" not \"f.readlines\".\n",
    "\"\"\"\n",
    "\n",
    "# Establish the path to your data\n",
    "import os\n",
    "path = \"C:/Users/....../Data/\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    # Reads all .txt files in a directory and returns a combined string of their contents.\n",
    "\n",
    "    file_contents = ''\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
    "                file_contents = file_contents + (f.read())\n",
    "    return file_contents\n",
    "\n",
    "texts = read_txt_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe257eb-7162-4a53-a869-f04541ced6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use this cell if you need to do streaming of response due to size.\n",
    "##########      OTHERWISE - USE THE CELL BELOW     ########\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Set a global variable for my OpenAI API key so that the model can be accessed.\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your_OpenAI_API_Key\"\n",
    "\n",
    "# Import libraries\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Instantiate the model\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Bring \"Instructions\" txt file into memory for the response function to access\n",
    "\n",
    "with open(\"C:/Users/....../openai_toponym_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    instructions = f.read()\n",
    "\n",
    "# Create response function to recognize and resolve toponyms\n",
    "\n",
    "stream = client.responses.create(\n",
    "  model=\"gpt-4.1-2025-04-14\",\n",
    "  instructions=instructions,\n",
    "  input=texts,\n",
    "  text={\n",
    "    \"format\": {\n",
    "      \"type\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  reasoning={},\n",
    "  tools=[\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"name\": \"toponym_recognition_resolution\",\n",
    "      \"strict\": True,\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"input_string\",\n",
    "          \"toponyms\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"toponyms\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "              \"type\": \"object\",\n",
    "              \"required\": [\n",
    "                \"name\",\n",
    "                \"latitude\",\n",
    "                \"longitude\"\n",
    "              ],\n",
    "              \"properties\": {\n",
    "                \"name\": {\n",
    "                  \"type\": \"string\",\n",
    "                  \"description\": \"The name of the toponym.\"\n",
    "                },\n",
    "                \"latitude\": {\n",
    "                  \"type\": \"number\",\n",
    "                  \"description\": \"The latitude of the toponym.\"\n",
    "                },\n",
    "                \"longitude\": {\n",
    "                  \"type\": \"number\",\n",
    "                  \"description\": \"The longitude of the toponym.\"\n",
    "                }\n",
    "              },\n",
    "              \"additionalProperties\": False\n",
    "            },\n",
    "            \"description\": \"Array of all identified and disambiguated toponyms with their geographical coordinates.\"\n",
    "          },\n",
    "          \"input_string\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The input string containing potential toponyms to recognize and resolve.\"\n",
    "          }\n",
    "        },\n",
    "        \"additionalProperties\": False\n",
    "      },\n",
    "      \"description\": \"Model takes string as input and performs toponym recognition and resolution using logic and context, with output response being all of the identified and correctly disambiguated toponyms and their latitude and longitude, even duplicates.  ALL instances of the identified and correctly disambiguated toponyms and their latitude and longitude are included in the response, even when there are duplicates or many instances of the same toponyms in the input text, including variations of spelling of the same toponymns.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_output_tokens=32768,\n",
    "  top_p=1,\n",
    "  store=True,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "\n",
    "# This streams the responses into a dictionary\n",
    "final_tool_calls = {}\n",
    "\n",
    "for event in stream:\n",
    "    if event.type == 'response.output_item.added':\n",
    "        final_tool_calls[event.output_index] = event.item;\n",
    "    elif event.type == 'response.function_call_arguments.delta':\n",
    "        index = event.output_index\n",
    "\n",
    "        if final_tool_calls[index]:\n",
    "            final_tool_calls[index].arguments += event.delta\n",
    "\n",
    "print(final_tool_calls)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebffa4d-56a0-4879-adff-b76058655745",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "##########      USE THIS CELL (UNLESS YOU NEED STREAMING OF RESPONSES)     ########\n",
    "\"\"\"\n",
    "\n",
    "# Set a global variable for my OpenAI API key so that the model can be accessed.\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your_OpenAI_API_Key\"\n",
    "\n",
    "# Import libraries\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Instantiate the model\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Bring \"Instructions\" txt file into memory for the response function to access\n",
    "\n",
    "with open(\"C:/Users/....../openai_toponym_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    instructions = f.read()\n",
    "\n",
    "# Create response function to recognize and resolve toponyms\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4.1-2025-04-14\",\n",
    "  instructions=instructions,\n",
    "  input=texts,\n",
    "  text={\n",
    "    \"format\": {\n",
    "      \"type\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  reasoning={},\n",
    "  tools=[\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"name\": \"toponym_recognition_resolution\",\n",
    "      \"strict\": True,\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"input_string\",\n",
    "          \"toponyms\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"toponyms\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "              \"type\": \"object\",\n",
    "              \"required\": [\n",
    "                \"name\",\n",
    "                \"latitude\",\n",
    "                \"longitude\"\n",
    "              ],\n",
    "              \"properties\": {\n",
    "                \"name\": {\n",
    "                  \"type\": \"string\",\n",
    "                  \"description\": \"The name of the toponym.\"\n",
    "                },\n",
    "                \"latitude\": {\n",
    "                  \"type\": \"number\",\n",
    "                  \"description\": \"The latitude of the toponym.\"\n",
    "                },\n",
    "                \"longitude\": {\n",
    "                  \"type\": \"number\",\n",
    "                  \"description\": \"The longitude of the toponym.\"\n",
    "                }\n",
    "              },\n",
    "              \"additionalProperties\": False\n",
    "            },\n",
    "            \"description\": \"Array of all identified and disambiguated toponyms with their geographical coordinates.\"\n",
    "          },\n",
    "          \"input_string\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The input string containing potential toponyms to recognize and resolve.\"\n",
    "          }\n",
    "        },\n",
    "        \"additionalProperties\": False\n",
    "      },\n",
    "      \"description\": \"Model takes string as input and performs toponym recognition and resolution using logic and context, with output response being all of the identified and correctly disambiguated toponyms and their latitude and longitude, even duplicates.  ALL instances of the identified and correctly disambiguated toponyms and their latitude and longitude are included in the response, even when there are duplicates or many instances of the same toponyms in the input text, including variations of spelling of the same toponyms.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_output_tokens=32768,\n",
    "  top_p=1,\n",
    "  store=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714852a-a812-46c5-b880-e532b497b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take response output, convert into json format, then normalize the data that I want and put into a dataframe.\n",
    "\n",
    "output = json.loads(response.output[0].arguments)\n",
    "df = pd.json_normalize(output['toponyms'], meta=['name', 'latitude', 'longitude'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f126e176-3720-40c9-a7c8-7257f53dfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to csv file...\n",
    "\n",
    "df.to_csv(\"C:/Users/....../Results_ResolvedToponyms.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73695eb0-6a03-4df7-9a1f-a3619d912935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
