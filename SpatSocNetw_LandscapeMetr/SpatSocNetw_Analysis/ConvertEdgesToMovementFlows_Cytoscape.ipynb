{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d18eee-a53f-425c-bb70-1b0b0ead8985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script converts an exported social network from Cytoscape software and converts it to \n",
    "a network based on sequential movement flows in the narrative of texts, based on the\n",
    "already-encoded sentence location of the social-network-detection-at-locationABC that\n",
    "was extracted using the social network detection process using BookNLP\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "INPUT  = \"MergedNetwork_MovementFlows_WorkingCopy.csv\"\n",
    "OUTPUT = \"MergedNetwork_MovementFlows_Final.csv\"\n",
    "\n",
    "# Columns present in the input\n",
    "required_cols = [\n",
    "    \"BookID\", \"Location\", \"LocationSentence\",\n",
    "    \"X_Coord\", \"Y_Coord\", \"Z_Coord\"\n",
    "]\n",
    "\n",
    "# Read\n",
    "df = pd.read_csv(INPUT, usecols=required_cols)\n",
    "\n",
    "# Fix the specific accented name to ASCII version\n",
    "df[\"Location\"] = df[\"Location\"].replace({\n",
    "    \"CollÃ¨ge CÃ©venol\": \"College Cevenol\",\n",
    "    \"Collège Cévenol\": \"College Cevenol\"\n",
    "})\n",
    "\n",
    "# Ensure numeric coordinate types (floats); invalid values -> NaN\n",
    "for c in [\"X_Coord\", \"Y_Coord\", \"Z_Coord\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Sort within each book by LocationSentence (numeric if possible; stable for ties)\n",
    "df[\"_loc_num\"] = pd.to_numeric(df[\"LocationSentence\"], errors=\"coerce\")\n",
    "df = df.sort_values(by=[\"BookID\", \"_loc_num\", \"LocationSentence\"], kind=\"mergesort\")\n",
    "\n",
    "# Shift to make consecutive edges within each BookID\n",
    "df[\"Target\"] = df.groupby(\"BookID\")[\"Location\"].shift(-1)\n",
    "df[\"X_Coord_Target\"] = df.groupby(\"BookID\")[\"X_Coord\"].shift(-1)\n",
    "df[\"Y_Coord_Target\"] = df.groupby(\"BookID\")[\"Y_Coord\"].shift(-1)\n",
    "df[\"Z_Coord_Target\"] = df.groupby(\"BookID\")[\"Z_Coord\"].shift(-1)\n",
    "\n",
    "# Keep only rows that have a next row (an edge)\n",
    "edges = df[df[\"Target\"].notna()].copy()\n",
    "\n",
    "# Rename source fields\n",
    "edges = edges.rename(columns={\n",
    "    \"Location\": \"Source\",\n",
    "    \"X_Coord\": \"X_Coord_Source\",\n",
    "    \"Y_Coord\": \"Y_Coord_Source\",\n",
    "    \"Z_Coord\": \"Z_Coord_Source\"\n",
    "})\n",
    "\n",
    "# Enforce float dtype in output coordinate columns (good for ArcGIS)\n",
    "coord_cols_out = [\n",
    "    \"X_Coord_Source\", \"Y_Coord_Source\", \"Z_Coord_Source\",\n",
    "    \"X_Coord_Target\", \"Y_Coord_Target\", \"Z_Coord_Target\"\n",
    "]\n",
    "edges[coord_cols_out] = edges[coord_cols_out].astype(\"float64\")\n",
    "\n",
    "# Compute great-circle distance (km) using haversine (WGS84, X=lon, Y=lat)\n",
    "R = 6371.0088  # mean Earth radius in km (WGS84)\n",
    "lat1 = np.radians(edges[\"Y_Coord_Source\"])\n",
    "lon1 = np.radians(edges[\"X_Coord_Source\"])\n",
    "lat2 = np.radians(edges[\"Y_Coord_Target\"])\n",
    "lon2 = np.radians(edges[\"X_Coord_Target\"])\n",
    "dlat = lat2 - lat1\n",
    "dlon = lon2 - lon1\n",
    "a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "edges[\"DistanceKM\"] = (R * c).astype(\"float64\") # NaNs propagate automatically for missing coords\n",
    "\n",
    "# If you prefer to drop any edge with missing coords, uncomment:\n",
    "# edges = edges.dropna(subset=coord_cols_out)\n",
    "\n",
    "# Final column order (added DistanceKM)\n",
    "out = edges[\n",
    "    [\"Source\", \"Target\"] +\n",
    "    coord_cols_out +\n",
    "    [\"DistanceKM\", \"BookID\", \"LocationSentence\"]\n",
    "]\n",
    "\n",
    "out.to_csv(OUTPUT, index=False)\n",
    "print(f\"Wrote {len(out):,} rows to {OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3d02c-bc5f-4d9b-9371-45930830e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Aggregate identical Source–Target edges ---\n",
    "OUTPUT_AGG = OUTPUT.replace(\".csv\", \"_Aggregated_Edges.csv\")\n",
    "\n",
    "agg_out = out.groupby([\"Source\", \"Target\"], as_index=False).agg(\n",
    "    X_Coord_Source=(\"X_Coord_Source\", \"first\"),\n",
    "    Y_Coord_Source=(\"Y_Coord_Source\", \"first\"),\n",
    "    Z_Coord_Source=(\"Z_Coord_Source\", \"first\"),\n",
    "    X_Coord_Target=(\"X_Coord_Target\", \"first\"),\n",
    "    Y_Coord_Target=(\"Y_Coord_Target\", \"first\"),\n",
    "    Z_Coord_Target=(\"Z_Coord_Target\", \"first\"),\n",
    "    DistanceKM=(\"DistanceKM\", \"first\"),\n",
    "    Weight=(\"Source\", \"size\")  # count of edges consolidated\n",
    ")\n",
    "\n",
    "# Enforce dtypes (floats for coords/dist, int for Weight)\n",
    "float_cols = [\n",
    "    \"X_Coord_Source\", \"Y_Coord_Source\", \"Z_Coord_Source\",\n",
    "    \"X_Coord_Target\", \"Y_Coord_Target\", \"Z_Coord_Target\",\n",
    "    \"DistanceKM\"\n",
    "]\n",
    "agg_out[float_cols] = agg_out[float_cols].astype(\"float64\")\n",
    "agg_out[\"Weight\"] = agg_out[\"Weight\"].astype(\"int64\")\n",
    "\n",
    "agg_out.to_csv(OUTPUT_AGG, index=False)\n",
    "print(f\"Wrote {len(agg_out):,} aggregated rows to {OUTPUT_AGG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76319cf-882e-42a5-8c29-3cf81a8f892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Nodes CSV from aggregated edges ---\n",
    "# Builds a node list of distinct locations with their coordinates.\n",
    "# Requires 'agg_out' from the previous aggregation block.\n",
    "\n",
    "NODES_OUT = OUTPUT.replace(\".csv\", \"_Aggregated_Nodes.csv\")  # -> MergedNetwork_MovementFlows_Final_Aggregated_Nodes.csv\n",
    "\n",
    "nodes_src = agg_out[[\"Source\", \"X_Coord_Source\", \"Y_Coord_Source\", \"Z_Coord_Source\"]].rename(\n",
    "    columns={\n",
    "        \"Source\": \"name\",\n",
    "        \"X_Coord_Source\": \"X_Coord\",\n",
    "        \"Y_Coord_Source\": \"Y_Coord\",\n",
    "        \"Z_Coord_Source\": \"Z_Coord\",\n",
    "    }\n",
    ")\n",
    "\n",
    "nodes_tgt = agg_out[[\"Target\", \"X_Coord_Target\", \"Y_Coord_Target\", \"Z_Coord_Target\"]].rename(\n",
    "    columns={\n",
    "        \"Target\": \"name\",\n",
    "        \"X_Coord_Target\": \"X_Coord\",\n",
    "        \"Y_Coord_Target\": \"Y_Coord\",\n",
    "        \"Z_Coord_Target\": \"Z_Coord\",\n",
    "    }\n",
    ")\n",
    "\n",
    "nodes = pd.concat([nodes_src, nodes_tgt], ignore_index=True)\n",
    "nodes = nodes.dropna(subset=[\"name\"])\n",
    "nodes = nodes.drop_duplicates(subset=[\"name\"], keep=\"first\")  # assumes coords are consistent per name\n",
    "nodes = nodes[[\"name\", \"X_Coord\", \"Y_Coord\", \"Z_Coord\"]].sort_values(\"name\")\n",
    "\n",
    "# Enforce float dtype for coordinates\n",
    "nodes[[\"X_Coord\", \"Y_Coord\", \"Z_Coord\"]] = nodes[[\"X_Coord\", \"Y_Coord\", \"Z_Coord\"]].astype(\"float64\")\n",
    "\n",
    "nodes.to_csv(NODES_OUT, index=False)\n",
    "print(f\"Wrote {len(nodes):,} nodes to {NODES_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f3f1c-95a3-4091-a994-b689dae76bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
