{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ba5686-647e-4661-8d24-7763582361dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load basic libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "\n",
    "# Set model to use GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b407e-6f2f-4bca-bbd4-46f676139a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL Keywords extracted from:  Rules-Based Entity Ruler Custom-built Geoparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7b2ff4-985e-4d3b-9c53-4746d842f63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Plateau_Locations        LAT       LON     ALT\n",
      "0                 Chambon  45.060810  4.302941   961.0\n",
      "1      Chambon sur Lignon  45.060810  4.302941   961.0\n",
      "2      Chambon-sur-Lignon  45.060810  4.302941   961.0\n",
      "3            Chaumargeais  45.090061  4.344000  1004.0\n",
      "4                     Fay  44.985435  4.226421  1181.0\n",
      "5          Fay-sur-Lignon  44.985435  4.226421  1181.0\n",
      "6                Fourezon  45.087067  4.248799  1041.0\n",
      "7               Freycenet  45.077240  4.216540  1047.0\n",
      "8            La Papeterie  45.132137  4.284565   822.0\n",
      "9   Le Chambon-sur-Lignon  45.060810  4.302941   961.0\n",
      "10            Le Fourezon  45.087067  4.248799  1041.0\n",
      "11              le Lignon  45.060810  4.302941   961.0\n",
      "12            Mazelgirard  45.082169  4.280830   969.0\n",
      "13                  Mazet  45.047192  4.244734  1027.0\n",
      "14        Mazet-Saint-Voy  45.047192  4.244734  1027.0\n",
      "15                 Mézenc  44.914280  4.189920  1744.0\n",
      "16            Mont Mézenc  44.914280  4.189920  1744.0\n",
      "17      montagnes Cévenol  45.060810  4.302941   961.0\n",
      "18             Montfaucon  45.185612  4.313760   919.0\n",
      "19        plateau Cévenol  45.060810  4.302941   961.0\n",
      "20       Plateau Vivarais  45.060810  4.302941   961.0\n",
      "21           Saint-Agreve  45.010014  4.395049  1066.0\n",
      "22           Saint-Agrève  45.010014  4.395049  1066.0\n",
      "23            Saint-André  45.121132  4.411250  1096.0\n",
      "24          Saint-Clément  44.952831  4.264970  1151.0\n",
      "25                  Tence  45.116135  4.289156   849.0\n",
      "['Chambon', 'Chambon sur Lignon', 'Chambon-sur-Lignon', 'Chaumargeais', 'Fay', 'Fay-sur-Lignon', 'Fourezon', 'Freycenet', 'La Papeterie', 'Le Chambon-sur-Lignon', 'Le Fourezon', 'le Lignon', 'Mazelgirard', 'Mazet', 'Mazet-Saint-Voy', 'Mézenc', 'Mont Mézenc', 'montagnes Cévenol', 'Montfaucon', 'plateau Cévenol', 'Plateau Vivarais', 'Saint-Agreve', 'Saint-Agrève', 'Saint-André', 'Saint-Clément', 'Tence']\n"
     ]
    }
   ],
   "source": [
    "## Reading in the csv file, from FRENCH language Rules-Based NLP results, of the extracted names and coordinates of\n",
    "## the towns, villages, and named features of the Plateau, creating a pandas dataframe with these locations and their\n",
    "## coordinates, then creating a list of just the location names, which then becomes one of the lists of keywords.\n",
    "\n",
    "df_PlatLoc = pd.read_csv(\"YOUR_DATA_keywords\")\n",
    "df_PlatLoc = df_PlatLoc.dropna()\n",
    "df_PlatLoc = df_PlatLoc[[\"Plateau_Locations\", \"LAT\", \"LON\", \"ALT\"]]\n",
    "df_PlatLoc[\"LAT\"] = pd.to_numeric(df_PlatLoc[\"LAT\"], downcast=\"float\")\n",
    "df_PlatLoc[\"LON\"] = pd.to_numeric(df_PlatLoc[\"LON\"], downcast=\"float\")\n",
    "df_PlatLoc[\"ALT\"] = pd.to_numeric(df_PlatLoc[\"ALT\"], downcast=\"float\")\n",
    "df_PlatLoc.columns = [\"Plateau_Locations\", \"LAT\", \"LON\", \"ALT\"]\n",
    "print(df_PlatLoc)\n",
    "PlatLoc = df_PlatLoc[\"Plateau_Locations\"].to_list()\n",
    "print(PlatLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1934596-6343-4a0d-a475-c89bc806e0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   other_French_Locations        LAT      LON    ALT\n",
      "0            camp de Gurs  43.273762 -0.74031  186.0\n",
      "1                  Drancy  48.925831  2.44528   47.0\n",
      "2                 Dunière  44.823132  4.65988  151.0\n",
      "3                 Etienne  45.433891  4.39000  529.0\n",
      "4                 Étienne  45.433891  4.39000  529.0\n",
      "5                    Gurs  43.273762 -0.74031  186.0\n",
      "6                    Lyon  45.748459  4.84671  173.0\n",
      "7               Marseille  43.296951  5.38107   28.0\n",
      "8                Mulhouse  47.752048  7.32866  238.0\n",
      "9                   Paris  48.853409  2.34880   42.0\n",
      "10                    Puy  45.043659  3.88523  640.0\n",
      "11                  Rouen  49.443130  1.09932   21.0\n",
      "12         Sainte-Étienne  45.433891  4.39000  529.0\n",
      "13          Saint-Etienne  45.433891  4.39000  529.0\n",
      "14          Saint-Étienne  45.433891  4.39000  529.0\n",
      "15             Yssingeaux  45.142818  4.12372  864.0\n",
      "['camp de Gurs', 'Drancy', 'Dunière', 'Etienne', 'Étienne', 'Gurs', 'Lyon', 'Marseille', 'Mulhouse', 'Paris', 'Puy', 'Rouen', 'Sainte-Étienne', 'Saint-Etienne', 'Saint-Étienne', 'Yssingeaux']\n"
     ]
    }
   ],
   "source": [
    "## Reading in the csv file, from FRENCH language Rules-Based NLP results, of the extracted names and coordinates of\n",
    "## the other locations in France (not on Plateau), creating a pandas dataframe with these locations and their\n",
    "## coordinates, then creating a list of just the location names, which then becomes one of the lists of keywords.\n",
    "\n",
    "df_FranceLoc = pd.read_csv(\"YOUR_DATA_keywords\")\n",
    "df_FranceLoc = df_FranceLoc.dropna()\n",
    "df_FranceLoc = df_FranceLoc[[\"other_French_Locations\", \"LAT\", \"LON\", \"ALT\"]]\n",
    "df_FranceLoc[\"LAT\"] = pd.to_numeric(df_FranceLoc[\"LAT\"], downcast=\"float\")\n",
    "df_FranceLoc[\"LON\"] = pd.to_numeric(df_FranceLoc[\"LON\"], downcast=\"float\")\n",
    "df_FranceLoc[\"ALT\"] = pd.to_numeric(df_FranceLoc[\"ALT\"], downcast=\"float\")\n",
    "df_FranceLoc.columns = [\"other_French_Locations\", \"LAT\", \"LON\", \"ALT\"]\n",
    "print(df_FranceLoc)\n",
    "FranceLoc = df_FranceLoc[\"other_French_Locations\"].to_list()\n",
    "print(FranceLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cc6e8b-ef83-4320-93d9-1017b2f6932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Childrens_Homes        LAT       LON     ALT\n",
      "0            Airelles  45.066315  4.305011   995.0\n",
      "1            Grillons  45.071281  4.326289  1067.0\n",
      "2      Heures Claires  45.063877  4.309932   981.0\n",
      "3      Joyeuse-Nichée  45.060829  4.311157  1002.0\n",
      "4           La Ruchée  45.062370  4.306548   994.0\n",
      "5        Les Grillons  45.071281  4.326289  1067.0\n",
      "6  Les Heures Claires  45.063877  4.309932   981.0\n",
      "7              Ruchée  45.062370  4.306548   994.0\n",
      "8          Tante Soly  45.060757  4.304197   958.0\n",
      "['Airelles', 'Grillons', 'Heures Claires', 'Joyeuse-Nichée', 'La Ruchée', 'Les Grillons', 'Les Heures Claires', 'Ruchée', 'Tante Soly']\n"
     ]
    }
   ],
   "source": [
    "## Reading in the csv file, from FRENCH language Rules-Based NLP results, of the extracted names and coordinates of\n",
    "## the Childrens Homes on the Plateau, creating a pandas dataframe with these locations and their\n",
    "## coordinates, then creating a list of just the location names, which then becomes one of the lists of keywords.\n",
    "\n",
    "df_homes = pd.read_csv(\"YOUR_DATA_keywords\")\n",
    "df_homes = df_homes.dropna()\n",
    "df_homes = df_homes[[\"Childrens_Homes\", \"LAT\", \"LON\", \"ALT\"]]\n",
    "df_homes[\"LAT\"] = pd.to_numeric(df_homes[\"LAT\"], downcast=\"float\")\n",
    "df_homes[\"LON\"] = pd.to_numeric(df_homes[\"LON\"], downcast=\"float\")\n",
    "df_homes[\"ALT\"] = pd.to_numeric(df_homes[\"ALT\"], downcast=\"float\")\n",
    "df_homes.columns = [\"Childrens_Homes\", \"LAT\", \"LON\", \"ALT\"]\n",
    "print(df_homes)\n",
    "homes = df_homes[\"Childrens_Homes\"].to_list()\n",
    "print(homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b8ad32-136a-437a-9a12-4e3d61234c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Farms        LAT       LON     ALT\n",
      "0  Les Digons  45.036205  4.371174  1084.0\n",
      "1     Remière  45.042877  4.323951  1053.0\n",
      "['Les Digons', 'Remière']\n"
     ]
    }
   ],
   "source": [
    "## Reading in the csv file, from FRENCH language Rules-Based NLP results, of the extracted names and coordinates of\n",
    "## the Farms on the Plateau, creating a pandas dataframe with these locations and their\n",
    "## coordinates, then creating a list of just the location names, which then becomes one of the lists of keywords.\n",
    "\n",
    "df_farms = pd.read_csv(\"YOUR_DATA_keywords\")\n",
    "df_farms = df_farms.dropna()\n",
    "df_farms = df_farms[[\"Farms\", \"LAT\", \"LON\", \"ALT\"]]\n",
    "df_farms[\"LAT\"] = pd.to_numeric(df_farms[\"LAT\"], downcast=\"float\")\n",
    "df_farms[\"LON\"] = pd.to_numeric(df_farms[\"LON\"], downcast=\"float\")\n",
    "df_farms[\"ALT\"] = pd.to_numeric(df_farms[\"ALT\"], downcast=\"float\")\n",
    "df_farms.columns = [\"Farms\", \"LAT\", \"LON\", \"ALT\"]\n",
    "print(df_farms)\n",
    "farms = df_farms[\"Farms\"].to_list()\n",
    "print(farms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c61c6fe-f023-48e1-85ca-cc3af5466bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hotels_GermanConvalescence        LAT      LON    ALT\n",
      "0            hôtel du Lignon  45.060642  4.30448  958.0\n",
      "['hôtel du Lignon']\n"
     ]
    }
   ],
   "source": [
    "## Reading in the csv file, from FRENCH language Rules-Based NLP results, of the extracted names and coordinates of\n",
    "## the hotels used by the Germans on the Plateau, creating a pandas dataframe with these locations and their\n",
    "## coordinates, then creating a list of just the location names, which then becomes one of the lists of keywords.\n",
    "\n",
    "df_hotels = pd.read_csv(\"YOUR_DATA_keywords\")\n",
    "df_hotels = df_hotels.dropna()\n",
    "df_hotels = df_hotels[[\"Hotels_GermanConvalescence\", \"LAT\", \"LON\", \"ALT\"]]\n",
    "df_hotels[\"LAT\"] = pd.to_numeric(df_hotels[\"LAT\"], downcast=\"float\")\n",
    "df_hotels[\"LON\"] = pd.to_numeric(df_hotels[\"LON\"], downcast=\"float\")\n",
    "df_hotels[\"ALT\"] = pd.to_numeric(df_hotels[\"ALT\"], downcast=\"float\")\n",
    "df_hotels.columns = [\"Hotels_GermanConvalescence\", \"LAT\", \"LON\", \"ALT\"]\n",
    "print(df_hotels)\n",
    "hotels = df_hotels[\"Hotels_GermanConvalescence\"].to_list()\n",
    "print(hotels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799660ac-070b-44e9-8dae-b95b689fb864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Schools        LAT       LON    ALT\n",
      "0  collège Cévenol  45.060959  4.303929  961.0\n",
      "1  Collège Cévenol  45.060959  4.303929  961.0\n",
      "2    école Cévenol  45.060959  4.303929  961.0\n",
      "3    Lycée Cévenol  45.060959  4.303929  961.0\n",
      "['collège Cévenol', 'Collège Cévenol', 'école Cévenol', 'Lycée Cévenol']\n"
     ]
    }
   ],
   "source": [
    "## Reading in the csv file, from FRENCH language Rules-Based NLP results, of the extracted names and coordinates of\n",
    "## the Schools on the Plateau, creating a pandas dataframe with these locations and their\n",
    "## coordinates, then creating a list of just the location names, which then becomes one of the lists of keywords.\n",
    "\n",
    "df_schools = pd.read_csv(\"YOUR_DATA_keywords\")\n",
    "df_schools = df_schools.dropna()\n",
    "df_schools = df_schools[[\"Schools\", \"LAT\", \"LON\", \"ALT\"]]\n",
    "df_schools[\"LAT\"] = pd.to_numeric(df_schools[\"LAT\"], downcast=\"float\")\n",
    "df_schools[\"LON\"] = pd.to_numeric(df_schools[\"LON\"], downcast=\"float\")\n",
    "df_schools[\"ALT\"] = pd.to_numeric(df_schools[\"ALT\"], downcast=\"float\")\n",
    "df_schools.columns = [\"Schools\", \"LAT\", \"LON\", \"ALT\"]\n",
    "print(df_schools)\n",
    "schools = df_schools[\"Schools\"].to_list()\n",
    "print(schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "980e6d59-ff94-42e4-a09d-e698cf7b3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Features\n",
      "0   village\n",
      "1     école\n",
      "2    maison\n",
      "3     ferme\n",
      "4   collège\n",
      "..      ...\n",
      "71    ponts\n",
      "72   prison\n",
      "73  plateau\n",
      "74   forêts\n",
      "75    tombe\n",
      "\n",
      "[76 rows x 1 columns]\n",
      "['village', 'école', 'maison', 'ferme', 'collège', 'hôtel', 'train', 'appartement', 'bois', 'route', 'forêt', 'fermes', 'mairie', 'temple', 'routes', 'voiture', 'camp', 'maisons', 'église', 'côte', 'gare', 'camion', 'Gorges', 'marché', 'couloir', 'plage', 'rivière', 'montagne', 'fort', 'portes', 'mur', 'chemin de fer', 'champ', 'camions', 'théâtre', 'camps', 'trains', 'bureau', 'commissariat de police', 'vallée', 'stade', 'cirque', 'collines', 'cour', 'terrasse', 'jardin', 'restaurant', 'université', 'frontière', 'arbre', 'arbres', 'colline', 'carrière', 'champs', 'pont', 'voitures', 'bibliothèque', 'réservoirs', 'caserne', 'place du village', 'vallées', 'désert', 'écoles', 'marches', 'camps de concentration', 'château', 'marche', 'Vallées', 'réservoir', 'hôtels', 'rivières', 'ponts', 'prison', 'plateau', 'forêts', 'tombe']\n"
     ]
    }
   ],
   "source": [
    "## Reading in the csv file, from FRENCH language Rules-Based NLP results, of the extracted non-named\n",
    "## features mentioned in the testimonies, creating a pandas dataframe with features,\n",
    "## then creating a list of the features, which then becomes one of the lists of keywords.\n",
    "\n",
    "df_features = pd.read_csv(\"YOUR_DATA_keywords\")\n",
    "df_features = df_features.dropna()\n",
    "df_features = df_features[[\"Features\"]]\n",
    "df_features.columns = [\"Features\"]\n",
    "print(df_features)\n",
    "features = df_features[\"Features\"].to_list()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70e3a330-1b56-4278-b9b4-93126c072167",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the FRENCH-language dataset for analysis.\n",
    "\n",
    "path = \"YOUR_DATA_Fre\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    # Reads all .txt files in a directory and returns a combined string of their contents.\n",
    "\n",
    "    file_contents = ''\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
    "                file_contents = file_contents + (f.read())\n",
    "    return file_contents\n",
    "\n",
    "texts = read_txt_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a900ab61-c8b6-4f18-ad0c-43d554368980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'joy', 'score': 0.9963505268096924}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import FRENCH emotion classification model, and \"warm it up\" on the simple sentence.\n",
    "# See site https://huggingface.co/astrosbd/french_emotion_camembert for model\n",
    "# See site https://huggingface.co/almanach/camembert-base for how to cite base model\n",
    "\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"astrosbd/french_emotion_camembert\")\n",
    "\n",
    "text = \"Je suis très heureux de votre service rapide et efficace.\" \n",
    "classifier(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27f60e-5432-4f9f-839b-2d606a0800f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
