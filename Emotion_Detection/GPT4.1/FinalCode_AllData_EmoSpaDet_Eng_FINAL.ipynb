{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86cb0dd-3e07-4a27-8ce3-d215cb3b565f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea02a0b-938e-4a08-b8e9-84dea9839dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## Load the ENGLISH-language dataset for analysis.\n",
    "path = \"YOUR_DATA_Eng\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    # Reads all .txt files in a directory and returns a combined string of their contents.\n",
    "\n",
    "    file_contents = ''\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
    "                file_contents = file_contents + (f.read())\n",
    "    return file_contents\n",
    "\n",
    "texts = read_txt_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7511b215-311d-4f70-b272-c743d37d8213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 508 char-based chunks for extraction.\n",
      "\n",
      "Initial extraction stage complete: Got 687 toponym instances (with possible duplicates).\n",
      "Deduplicated toponyms: 687 → 141\n",
      "\n",
      "Stage 1 complete: Saved 141 unique toponym instances to file.\n",
      "Warning: Toponym 7th arrondissement not found in text.\n",
      "Analyzed: Le Chambon-sur-Lignon (from .toponym_instances)\n",
      "Analyzed: Germany (from .toponym_instances)\n",
      "Analyzed: France (from .toponym_instances)\n",
      "Analyzed: La Guespy (from .toponym_instances)\n",
      "Analyzed: Poland (from .toponym_instances)\n",
      "Analyzed: L'Abric (from .toponym_instances)\n",
      "Analyzed: Les Tavas (from .toponym_instances)\n",
      "Analyzed: Ferme École (from .toponym_instances)\n",
      "Analyzed: Le Faïdoli (from .toponym_instances)\n",
      "Analyzed: Rivesaltes (from .toponym_instances)\n",
      "Analyzed: College Cévenol (from .toponym_instances)\n",
      "Analyzed: Lyon (from .toponym_instances)\n",
      "Analyzed: Departements (from .toponym_instances)\n",
      "Analyzed: Vichy (from .toponym_instances)\n",
      "Analyzed: Studio Cévenol (from .toponym_instances)\n",
      "Analyzed: Switzerland (from .toponym_instances)\n",
      "Analyzed: L'Abric House (from .toponym_instances)\n",
      "Analyzed: Corsica (from .toponym_instances)\n",
      "Analyzed: St. Etienne (from .toponym_instances)\n",
      "Analyzed: Swiss (from .toponym_instances)\n",
      "Analyzed: Spanish (from .toponym_instances)\n",
      "Analyzed: Normandy (from .toponym_instances)\n",
      "Analyzed: Gurs (from .toponym_instances)\n",
      "Analyzed: Dunkirk (from .toponym_instances)\n",
      "Analyzed: Le Puy (from .toponym_instances)\n",
      "Analyzed: Viennese (from .toponym_instances)\n",
      "Analyzed: Cévenol (from .toponym_instances)\n",
      "Analyzed: Collège Cévenol (from .toponym_instances)\n",
      "Analyzed: the village (from .toponym_instances)\n",
      "Analyzed: Wesleyan (from .toponym_instances)\n",
      "Analyzed: Saint-Étienne (from .toponym_instances)\n",
      "Analyzed: Valence (from .toponym_instances)\n",
      "Analyzed: these mountains (from .toponym_instances)\n",
      "Analyzed: American (from .toponym_instances)\n",
      "Analyzed: Marseilles (from .toponym_instances)\n",
      "Analyzed: Saint-Etienne (from .toponym_instances)\n",
      "Analyzed: Department of Haute Loire (from .toponym_instances)\n",
      "Analyzed: Berlin (from .toponym_instances)\n",
      "Analyzed: Massif Central (from .toponym_instances)\n",
      "Analyzed: Figeac (from .toponym_instances)\n",
      "Analyzed: Le Collège Cévenol (from .toponym_instances)\n",
      "Analyzed: Les Grillons (from .toponym_instances)\n",
      "Analyzed: Czechoslovakia (from .toponym_instances)\n",
      "Analyzed: Spain (from .toponym_instances)\n",
      "Analyzed: lot department (from .toponym_instances)\n",
      "Analyzed: United States (from .toponym_instances)\n",
      "Analyzed: Auschwitz (from .toponym_instances)\n",
      "Analyzed: England (from .toponym_instances)\n",
      "Analyzed: Luca, France (from .toponym_instances)\n",
      "Analyzed: Auch (from .toponym_instances)\n",
      "Analyzed: Haute-Loire (from .toponym_instances)\n",
      "Analyzed: Pension De Famille (from .toponym_instances)\n",
      "Analyzed: Lavoulte bridge (from .toponym_instances)\n",
      "Analyzed: La Rouvière (from .toponym_instances)\n",
      "Analyzed: Les Caillols (from .toponym_instances)\n",
      "Analyzed: St. Agrève (from .toponym_instances)\n",
      "Analyzed: Le Chambon sur Lignon (from .toponym_instances)\n",
      "Analyzed: Gers (from .toponym_instances)\n",
      "Analyzed: College Cevenol (from .toponym_instances)\n",
      "Analyzed: Cheylard (from .toponym_instances)\n",
      "Analyzed: Eastern Europe (from .toponym_instances)\n",
      "Analyzed: Romania (from .toponym_instances)\n",
      "Analyzed: Hungary (from .toponym_instances)\n",
      "Analyzed: Millouse (from .toponym_instances)\n",
      "Analyzed: Russian front (from .toponym_instances)\n",
      "Analyzed: Swiss border (from .toponym_instances)\n",
      "Analyzed: Europe (from .toponym_instances)\n",
      "Analyzed: Drancy (from .toponym_instances)\n",
      "Analyzed: Austria (from .toponym_instances)\n",
      "Analyzed: Belgium (from .toponym_instances)\n",
      "Analyzed: Maison des Roches (from .toponym_instances)\n",
      "Analyzed: Perpignan (from .toponym_instances)\n",
      "Analyzed: Camp de Gurs (from .toponym_instances)\n",
      "Analyzed: Alps (from .toponym_instances)\n",
      "Analyzed: Washington (from .toponym_instances)\n",
      "Analyzed: Trocme household (from .toponym_instances)\n",
      "Analyzed: Cuba (from .toponym_instances)\n",
      "Analyzed: Toulouse (from .toponym_instances)\n",
      "Analyzed: Algiers (from .toponym_instances)\n",
      "Analyzed: Le Puy-en-Velay (from .toponym_instances)\n",
      "Analyzed: Annecy (from .toponym_instances)\n",
      "Analyzed: Alsace-Lorraine (from .toponym_instances)\n",
      "Analyzed: German (from .toponym_instances)\n",
      "Analyzed: Vienna (from .toponym_instances)\n",
      "Analyzed: New York (from .toponym_instances)\n",
      "Analyzed: University of Lyon (from .toponym_instances)\n",
      "Analyzed: Bayside (from .toponym_instances)\n",
      "Analyzed: Grenoble (from .toponym_instances)\n",
      "Analyzed: Britain (from .toponym_instances)\n",
      "Analyzed: Camp Saint-Cyprien (from .toponym_instances)\n",
      "Analyzed: Le Chambon-sur Lignon (from .toponym_instances)\n",
      "Analyzed: Majdanek (from .toponym_instances)\n",
      "Analyzed: Mediterranean (from .toponym_instances)\n",
      "Analyzed: Spanish Civil War (from .toponym_instances)\n",
      "Analyzed: Palatinate (from .toponym_instances)\n",
      "Analyzed: Baden (from .toponym_instances)\n",
      "Analyzed: Atlas (from .toponym_instances)\n",
      "Analyzed: Tence (from .toponym_instances)\n",
      "Analyzed: Karlsruhe (from .toponym_instances)\n",
      "Analyzed: French Alps (from .toponym_instances)\n",
      "Analyzed: West Germany (from .toponym_instances)\n",
      "Analyzed: Mannheim (from .toponym_instances)\n",
      "Analyzed: Annemasse (from .toponym_instances)\n",
      "Analyzed: Les Roches (from .toponym_instances)\n",
      "Analyzed: Mont (from .toponym_instances)\n",
      "Analyzed: Saint Étienne (from .toponym_instances)\n",
      "Analyzed: Côteau Fleuri (from .toponym_instances)\n",
      "Analyzed: College in Chambon-sur-Lignon (from .toponym_instances)\n",
      "Analyzed: La Maison des de Roches (from .toponym_instances)\n",
      "Analyzed: La Maison des Roches (from .toponym_instances)\n",
      "Analyzed: Saint‐Gervais (from .toponym_instances)\n",
      "Analyzed: Holland (from .toponym_instances)\n",
      "Analyzed: Lithuania (from .toponym_instances)\n",
      "Analyzed: Le Plateau (from .toponym_instances)\n",
      "Analyzed: Nuremberg (from .toponym_instances)\n",
      "Analyzed: Chamonix (from .toponym_instances)\n",
      "Analyzed: Le Mazet (from .toponym_instances)\n",
      "Analyzed: La Fayolle (from .toponym_instances)\n",
      "Analyzed: Villeurbanne (from .toponym_instances)\n",
      "Analyzed: Ardeche (from .toponym_instances)\n",
      "Analyzed: Saint-Agreve (from .toponym_instances)\n",
      "Analyzed: l'Ardeche (from .toponym_instances)\n",
      "Analyzed: Rohner (from .toponym_instances)\n",
      "Analyzed: North Africa (from .toponym_instances)\n",
      "Analyzed: La Bergerie (from .toponym_instances)\n",
      "Analyzed: La Demi-Lune (from .toponym_instances)\n",
      "Analyzed: Rhône (from .toponym_instances)\n",
      "Analyzed: Geneva (from .toponym_instances)\n",
      "Analyzed: pre-Alps (from .toponym_instances)\n",
      "Analyzed: Italy (from .toponym_instances)\n",
      "Analyzed: Siberia (from .toponym_instances)\n",
      "Analyzed: Argentina (from .toponym_instances)\n",
      "Analyzed: Limoges (from .toponym_instances)\n",
      "Analyzed: Germanic countries (from .toponym_instances)\n",
      "Analyzed: central France (from .toponym_instances)\n",
      "Analyzed: House of the Rocks (from .toponym_instances)\n",
      "Analyzed: Saint-Jeures (from .toponym_instances)\n",
      "Analyzed: Fay-sur-Lignon (from .toponym_instances)\n",
      "Analyzed: Le College Cevenol (from .toponym_instances)\n",
      "Analyzed: Africa (from .toponym_instances)\n",
      "[API] Analysis error for '7th arrondissement': Request timed out.\n",
      "Retrying in 1s...\n",
      "Analyzed: 7th arrondissement (from .toponym_instances)\n",
      "\n",
      "Stage 2 complete: Produced 137 detailed toponym analyses.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Developing function to identify and resolve toponyms, and detect emotions in context \n",
    "on either side of each toponym.  Context length is based on trying different lengths,\n",
    "with the final context length chosen based on which gives the most likely detected emotion\n",
    "with the highest confidence score.\n",
    "\n",
    "\"\"\"\n",
    "# Access libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import hashlib\n",
    "from difflib import SequenceMatcher\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Set a global variable for my OpenAI API key so that the model can be accessed.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_KEY\"\n",
    "client = OpenAI()\n",
    "\n",
    "# Alternative data for testing and to DEBUG:\n",
    "#texts = \"I traveled from Paris to Berlin and saw New York on the way.  It was fantastic.  I was so happy.\"\n",
    "\n",
    "# ========== Robust OpenAI Output Extraction ==========\n",
    "def extract_json_from_arguments(response):\n",
    "    \"\"\"\n",
    "    Robust extraction for OpenAI responses.\n",
    "    Handles both function call and text output scenarios.\n",
    "    Returns dict or list or [].\n",
    "    \"\"\"\n",
    "    # Case 1: Function call pattern\n",
    "    if hasattr(response, \"output\") and response.output:\n",
    "        first = response.output[0]\n",
    "        if hasattr(first, \"arguments\"): # should be a string\n",
    "            arguments_string = first.arguments\n",
    "            if isinstance(arguments_string, (str, bytes)):\n",
    "                try:\n",
    "                    return json.loads(arguments_string)\n",
    "                except Exception as e:\n",
    "                    print(f\"JSON parsing error: {e}\")\n",
    "                    return []\n",
    "            else:\n",
    "                # If already parsed (rare)\n",
    "                return arguments_string\n",
    "        # If it's classic text response\n",
    "        if hasattr(first, \"content\") and first.content:\n",
    "            text_fragment = getattr(first.content[0], \"text\", None)\n",
    "            if text_fragment:\n",
    "                try:\n",
    "                    return json.loads(text_fragment)\n",
    "                except Exception as e:\n",
    "                    print(f\"JSON parsing error (text): {e}\\nTEXT: {text_fragment}\")\n",
    "                    return []\n",
    "    # Case 2: Tool-style .outputs (not present in your current responses)\n",
    "    if hasattr(response, \"outputs\") and response.outputs and hasattr(response.outputs[0], \"arguments\"):\n",
    "        arguments = response.outputs[0].arguments\n",
    "        if arguments is not None:\n",
    "            return arguments\n",
    "    print(\"No recognizable output format found in OpenAI response.\")\n",
    "    return []\n",
    "\n",
    "# 2. Character-based Chunking (if needed).\n",
    "# Reduced number of characters to just 600, with no overlap at all.  \n",
    "\n",
    "def chunk_text_by_chars(text, chunk_size=600, overlap=0):\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    text_len = len(text)\n",
    "    while i < text_len:\n",
    "        start_char = i\n",
    "        end_char = min(i + chunk_size, text_len)\n",
    "        chunk_text = text[start_char:end_char]\n",
    "        chunks.append((chunk_text, start_char))\n",
    "        if end_char == text_len:\n",
    "            break\n",
    "        i += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# 3. API Call with Retry for Thread Use\n",
    "\n",
    "def call_api_with_retry_chunk(chunk, extraction_instructions, client, max_output_tokens=2048, retries=4):\n",
    "    # print(\"Chunk being sent:\", repr(chunk))     # Can use this to DEBUG chunk issues\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4.1-2025-04-14\",\n",
    "                instructions=extraction_instructions,\n",
    "                input=chunk,\n",
    "                text={\"format\": {\"type\": \"text\"}},\n",
    "                reasoning={},\n",
    "                tools=[\n",
    "                    {\n",
    "                        \"type\": \"function\",\n",
    "                        \"name\": \"recognize_toponyms\",\n",
    "                        \"description\": \"Given the user input text, identify all the toponyms in the text.\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"required\": [\"input_text\", \"toponyms\"],\n",
    "                            \"properties\": {\n",
    "                                \"input_text\": {\n",
    "                                    \"type\": \"string\", \n",
    "                                    \"description\": \"The text string from which to recognize and identify toponyms.\"\n",
    "                                },\n",
    "                                \"toponyms\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"description\": \"Array of recognized and identified toponyms.\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"toponym\": {\"type\": \"string\"}\n",
    "                                        },\n",
    "                                        \"required\": [\"toponym\"],\n",
    "                                        \"additionalProperties\": False\n",
    "                                    }\n",
    "                                }\n",
    "                            },\n",
    "                            \"additionalProperties\": False\n",
    "                        },\n",
    "                        \"strict\": True\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "                tool_choice=\"required\",\n",
    "                max_output_tokens=max_output_tokens,\n",
    "                top_p=1,\n",
    "                store=True\n",
    "            )\n",
    "            \"\"\" These next three lines can be used to DEBUG responses or lack thereof\n",
    "            print(\"Raw response:\", response)\n",
    "            extracted = extract_json_from_arguments(response)\n",
    "            print(\"Extracted:\", extracted)\n",
    "            \"\"\"\n",
    "            return extract_json_from_arguments(response)         \n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"[API] Error: {e}\\nRetrying in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "    print(f\"[API] Failed after retries.\")\n",
    "    return []\n",
    "\n",
    "# 4. Stage 1: Parallel Toponym Extraction\n",
    "\n",
    "# ====== Load Extraction Prompt ======\n",
    "with open(\"FinalPrompt_openai_ToponymExtraction_prompt_FINAL.txt\", encoding=\"utf-8\") as f:\n",
    "    extraction_instructions = f.read()\n",
    "\n",
    "# ====== Chunk Input ======\n",
    "    # chunk via characters\n",
    "chunks = chunk_text_by_chars(texts, chunk_size=600, overlap=0)\n",
    "print(f\"Text split into {len(chunks)} char-based chunks for extraction.\")\n",
    "\n",
    "# ====== Run Extraction in Parallel ======\n",
    "max_workers = 20   # safe for modern high-tier; can adjust up/down\n",
    "extracted_toponyms = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            call_api_with_retry_chunk, chunk, extraction_instructions, client\n",
    "        )\n",
    "        for chunk, _ in chunks\n",
    "    ]\n",
    "    for f in as_completed(futures):\n",
    "        result = f.result()\n",
    "        # print(\"DEBUG:\", result)          # Can use this if need to DEBUG results\n",
    "        if isinstance(result, dict) and \"toponyms\" in result:\n",
    "            extracted_toponyms += result[\"toponyms\"]\n",
    "        elif isinstance(result, list):\n",
    "            extracted_toponyms += result\n",
    "        else:\n",
    "            print(\"Warning: Unexpected result format\", result)\n",
    "\n",
    "print(f\"\\nInitial extraction stage complete: Got {len(extracted_toponyms)} toponym instances (with possible duplicates).\")\n",
    "\n",
    "# ------------------ DEDUPLICATION STEP --------------------\n",
    "def get_local_context(text, name, window=50):\n",
    "    \"\"\"Find the first occurrence of name in text and return local context window.\"\"\"\n",
    "    lowers = text.lower()\n",
    "    name_lower = name.lower()\n",
    "    idx = lowers.find(name_lower)\n",
    "    if idx == -1:\n",
    "        # fallback: just use the first window of the text (may dedupe global substrings, edge case)\n",
    "        return text[:2*window]\n",
    "    start = max(0, idx - window)\n",
    "    end = min(len(text), idx + len(name) + window)\n",
    "    return text[start:end]\n",
    "\n",
    "def deduplicate_by_fuzzy_context_and_longest(toponym_list, texts, window=50, similarity=0.90):\n",
    "    \"\"\"\n",
    "    Group extracted toponyms by fuzzy context similarity.\n",
    "    Keeps only the longest (most specific) name in each group.\n",
    "    Can be more aggressive with wider window & lower similarity threshold!!\n",
    "    \"\"\"\n",
    "    items = [\n",
    "        (t['toponym'].strip(), get_local_context(texts, t['toponym'].strip(), window), t)\n",
    "        for t in toponym_list\n",
    "    ]\n",
    "    groups = []\n",
    "    used = set()\n",
    "    for i, (name_i, ctx_i, obj_i) in enumerate(items):\n",
    "        if i in used: continue\n",
    "        group = [(name_i, ctx_i, obj_i)]\n",
    "        used.add(i)\n",
    "        for j, (name_j, ctx_j, obj_j) in enumerate(items):\n",
    "            if j <= i or j in used: continue\n",
    "            if ctx_i and ctx_j:\n",
    "                score = SequenceMatcher(None, ctx_i, ctx_j).ratio()\n",
    "                if score >= similarity:\n",
    "                    group.append((name_j, ctx_j, obj_j))\n",
    "                    used.add(j)\n",
    "        # Within the group, eliminate all substrings: keep only the longest(s)\n",
    "        group.sort(key=lambda g: len(g[0]), reverse=True)\n",
    "        deduped_names = set()\n",
    "        deduped_objs = []\n",
    "        for name, ctx, obj in group:\n",
    "            if not any(name in longer for longer in deduped_names if len(name) < len(longer)):\n",
    "                deduped_names.add(name)\n",
    "                deduped_objs.append(obj)\n",
    "        # Option 1: Only keep the very longest:\n",
    "        groups.append(deduped_objs[0])\n",
    "        # Option 2: To keep all equally-long max variants, use:\n",
    "        # groups.extend(deduped_objs[:1])  # or groups.extend(deduped_objs)\n",
    "    return groups\n",
    "    \n",
    "before = len(extracted_toponyms)\n",
    "extracted_toponyms = deduplicate_by_fuzzy_context_and_longest(extracted_toponyms, texts, window=50, similarity=0.90)\n",
    "after = len(extracted_toponyms)\n",
    "print(f\"Deduplicated toponyms: {before} → {after}\")\n",
    "\n",
    "# ------------------ END DEDUPLICATION STEP --------------------\n",
    "\n",
    "\n",
    "with open(\"extracted_toponyms.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(extracted_toponyms, f, ensure_ascii=False, indent=2)\n",
    "print(f\"\\nStage 1 complete: Saved {len(extracted_toponyms)} unique toponym instances to file.\")\n",
    "\n",
    "# 5. Stage 2: Parallel Toponym Analysis\n",
    "\n",
    "# ====== Load Analysis Prompt ======\n",
    "with open(\"FinalPrompt_openai_ToponymEmotionAnalysis_prompt_FINAL.txt\", encoding=\"utf-8\") as f:\n",
    "    analysis_instructions = f.read()\n",
    "\n",
    "def call_api_with_retry_analysis(\n",
    "    toponym_obj,\n",
    "    texts,\n",
    "    client,\n",
    "    analysis_instructions,\n",
    "    max_output_tokens=32000,\n",
    "    retries=4,\n",
    "):\n",
    "    toponym_str = toponym_obj[\"toponym\"]\n",
    "    user_input = {\n",
    "        \"original_text\": texts,\n",
    "        \"toponym_instances\": [{**toponym_obj}]\n",
    "    }\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4.1-2025-04-14\",\n",
    "                instructions=analysis_instructions,\n",
    "                input=json.dumps(user_input),\n",
    "                text={\"format\": {\"type\": \"text\"}},\n",
    "                reasoning={},\n",
    "                tools=[{\n",
    "                    \"type\": \"function\",\n",
    "                    \"name\": \"resolve_toponyms_and_detect_emotions\",\n",
    "                    \"description\": (\n",
    "                        \"Given the user input of the original text and extracted toponyms, determine latitude and longitude of each toponym.\"\n",
    "                        \"If the toponym is in France then proceed and perform emotion detection. If not in France, then do no futher action on that toponym and do not include it in your response.\"\n",
    "                        \"Try multiple possible context window sizes (~different context lengths) for each French toponym and \"\n",
    "                        \"return the window (context) that maximizes the confidence score for the most likely detected emotion.\"\n",
    "                    ),\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"required\": [\"original_text\", \"toponym_instances\"],\n",
    "                        \"properties\": {\n",
    "                            \"original_text\": {\"type\": \"string\", \"description\": \"The text string from which to disambiguate toponyms and utilize their surrounding context.\"},\n",
    "                            \"toponym_instances\": {\n",
    "                                \"type\": \"array\",\n",
    "                \t\t\t\t\"description\": \"Array of identified toponyms, each containing properties of location details and emotional context.\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"required\": [\n",
    "                                        \"toponym\", \"resolved_name\", \"latitude\",\n",
    "                                        \"longitude\", \"emotion\", \"confidence_score\",\n",
    "                                        \"context\", \"context_length\", \"sub_category_emotion\"\n",
    "                                    ],\n",
    "                                    \"properties\": {\n",
    "                                        \"toponym\": {\"type\": \"string\", \"description\": \"The name of the toponym as found in the previous step.\"},\n",
    "                                        \"resolved_name\": {\"type\": \"string\", \"description\": \"The name of the resolved toponym as identified and disambiguated.\"},\n",
    "                                        \"latitude\": {\"type\": \"number\", \"description\": \"The latitude coordinate of the toponym.\"},\n",
    "                                        \"longitude\": {\"type\": \"number\", \"description\": \"The longitude coordinate of the toponym.\"},\n",
    "                                        \"emotion\": {\"type\": \"string\", \"description\": \"The most likely detected emotion around the toponym.\", \"enum\": [\n",
    "                                            \"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"\n",
    "                                        ]},\n",
    "                                        \"confidence_score\": {\"type\": \"number\", \"description\": \"The confidence score for the detected emotion, on a scale of 0 to 1.\"},\n",
    "                                        \"context\": {\"type\": \"string\", \"description\": \"The text block surrounding the toponym used for emotion detection, whose length is determined based on trying different lengths and seeing which one gives the highest confidence score for the most likely detected emotion.\"},\n",
    "                                        \"context_length\": {\"type\": \"number\", \"description\": \"The length, in characters including spaces, of the final text block surrounding the toponym used for emotion detection.\"},\n",
    "                                        \"sub_category_emotion\": {\"type\": \"string\", \"description\":  \"For each of the emotions that you concluded (anger, disgust, fear, joy, sadness, surprise, neutral), tell us which of the following sub-category of that emotion is most likely, using the Ekman emotion classification system\",\n",
    "                                                                \"enum\": [\"Annoyance\", \"Frustration\", \"Exasperation\", \"Argumentativeness\", \"Bitterness\", \"Vengefulness\", \"Fury\",\n",
    "                                                                         \"Dislike\", \"Aversion\", \"Distaste\", \"Repugnance\", \"Revulsion\", \"Abhorrence\", \"Loathing\",\n",
    "                                                                         \"Trepidation\", \"Nervousness\", \"Anxiety\", \"Dread\", \"Desperation\", \"Panic\", \"Horror\", \"Terror\",\n",
    "                                                                         \"Sensory Pleasure\", \"Rejoicing\", \"Compassion/Joy\", \"Amusement\", \"Schadenfreude\", \"Relief\", \"Peace\", \"Pride\", \"Fiero\", \"Naches\", \"Wonder\", \"Excitement\", \"Ecstasy\",\n",
    "                                                                         \"Disappointment\", \"Discouragement\", \"Distraughtness\", \"Resignation\", \"Helplessness\", \"Hopelessness\", \"Misery\", \"Despair\", \"Grief\", \"Sorrow\", \"Anguish\",\n",
    "                                                                         \"Surprise\",\n",
    "                                                                         \"Neutral\"\n",
    "                                                                        ]}\n",
    "                                    },\n",
    "                                    \"additionalProperties\": False,\n",
    "                                },\n",
    "                            }\n",
    "                        },\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                    \"strict\": True\n",
    "                }],\n",
    "                temperature=1,\n",
    "                tool_choice=\"required\",\n",
    "                max_output_tokens=max_output_tokens,\n",
    "                top_p=1,\n",
    "                store=True\n",
    "            )\n",
    "            return extract_json_from_arguments(response), toponym_str\n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"[API] Analysis error for '{toponym_str}': {e}\\nRetrying in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "    print(f\"[API] Analysis failed after retries for '{toponym_str}'.\")\n",
    "    return {\"toponym\": toponym_str, \"error\": \"Failed after retries\"}, toponym_str\n",
    "\n",
    "# Run Stage 2 in Parallel\n",
    "\n",
    "# ---- Load the extracted_toponyms ----\n",
    "with open(\"extracted_toponyms.json\", encoding=\"utf-8\") as f:\n",
    "    extracted_toponyms = json.load(f)\n",
    "\"\"\"    \n",
    "# This sets a context window that is at the maximum of 600 characters to avoid the sometimes random \n",
    "5000-character context windows that the model decides to use when calling the function, even though\n",
    "I told it to not give me more than 600 character windows\n",
    "\"\"\"\n",
    "def get_context(text, toponym, window=600):\n",
    "    idx = text.lower().find(toponym.lower())\n",
    "    if idx == -1:\n",
    "        print(f\"Warning: Toponym {toponym} not found in text.\")\n",
    "        return text\n",
    "    start = max(0, idx - window)\n",
    "    end = min(len(text), idx + len(toponym) + window)\n",
    "    return text[start:end]\n",
    "\n",
    "analysis_results = []\n",
    "\"\"\"\n",
    "Keep max_workers relatively low to prevent truncation of output (which results in \"JSON parsing errors\" \n",
    "due to attempting this on a truncated \"list\" rather than the actual dictionary that it is).  \n",
    "Also keeps it below rate limits.\n",
    "\"\"\"\n",
    "max_workers_analysis = 6\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers_analysis) as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            call_api_with_retry_analysis, t, get_context(texts, t[\"toponym\"]), client, analysis_instructions, 32000\n",
    "        )\n",
    "        for t in extracted_toponyms\n",
    "    ]\n",
    "    for f in as_completed(futures):\n",
    "        batch_result, toponym_str = f.result()\n",
    "        # Handle lists/dicts as before\n",
    "        if isinstance(batch_result, list):\n",
    "            analysis_results += batch_result\n",
    "            print(f\"Analyzed: {toponym_str} (got list)\")\n",
    "        elif isinstance(batch_result, dict) and \"toponym_instances\" in batch_result:\n",
    "            analysis_results += batch_result[\"toponym_instances\"]\n",
    "            print(f\"Analyzed: {toponym_str} (from .toponym_instances)\")\n",
    "        else:\n",
    "            analysis_results.append(batch_result)\n",
    "            print(f\"Analyzed: {toponym_str} (error or unexpected shape)\")\n",
    "\n",
    "with open(\"analysis_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(analysis_results, f, ensure_ascii=False, indent=2)\n",
    "print(f\"\\nStage 2 complete: Produced {len(analysis_results)} detailed toponym analyses.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f318a2a6-3a2a-4f32-8a15-e61c29ea310a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toponym</th>\n",
       "      <th>resolved_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>emotion</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>sub_category_emotion</th>\n",
       "      <th>emotion_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le Chambon-sur-Lignon</td>\n",
       "      <td>Le Chambon-sur-Lignon</td>\n",
       "      <td>45.060810</td>\n",
       "      <td>4.302941</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.70</td>\n",
       "      <td>It was part of Le Chambon-sur-Lignon. And Le C...</td>\n",
       "      <td>348</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>51.165691</td>\n",
       "      <td>10.451526</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>46.603354</td>\n",
       "      <td>1.888334</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.64</td>\n",
       "      <td>who also lived in France as a refugee.  There ...</td>\n",
       "      <td>522</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La Guespy</td>\n",
       "      <td>La Guespy</td>\n",
       "      <td>45.061000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.87</td>\n",
       "      <td>We began to set up the second home in October....</td>\n",
       "      <td>427</td>\n",
       "      <td>Compassion/Joy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poland</td>\n",
       "      <td>Poland</td>\n",
       "      <td>51.919438</td>\n",
       "      <td>19.145136</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Jews who had come from Poland, from Germany, w...</td>\n",
       "      <td>217</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Saint-Jeures</td>\n",
       "      <td>Saint-Jeures</td>\n",
       "      <td>45.120749</td>\n",
       "      <td>4.235172</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.70</td>\n",
       "      <td>It was not only that village. It was also all ...</td>\n",
       "      <td>308</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Fay-sur-Lignon</td>\n",
       "      <td>Fay-sur-Lignon</td>\n",
       "      <td>45.042338</td>\n",
       "      <td>4.233682</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.77</td>\n",
       "      <td>It was not only that village. It was also all ...</td>\n",
       "      <td>527</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Le College Cevenol</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Africa</td>\n",
       "      <td>-8.783195</td>\n",
       "      <td>34.508523</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7th arrondissement</td>\n",
       "      <td>7th arrondissement of Paris</td>\n",
       "      <td>48.856144</td>\n",
       "      <td>2.312619</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.67</td>\n",
       "      <td>And we used to see all this activity. Men runn...</td>\n",
       "      <td>1634</td>\n",
       "      <td>Sensory Pleasure</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   toponym                resolved_name   latitude  longitude  \\\n",
       "0    Le Chambon-sur-Lignon        Le Chambon-sur-Lignon  45.060810   4.302941   \n",
       "1                  Germany                      Germany  51.165691  10.451526   \n",
       "2                   France                       France  46.603354   1.888334   \n",
       "3                La Guespy                    La Guespy  45.061000   4.300000   \n",
       "4                   Poland                       Poland  51.919438  19.145136   \n",
       "..                     ...                          ...        ...        ...   \n",
       "132           Saint-Jeures                 Saint-Jeures  45.120749   4.235172   \n",
       "133         Fay-sur-Lignon               Fay-sur-Lignon  45.042338   4.233682   \n",
       "134     Le College Cevenol                                0.000000   0.000000   \n",
       "135                 Africa                       Africa  -8.783195  34.508523   \n",
       "136     7th arrondissement  7th arrondissement of Paris  48.856144   2.312619   \n",
       "\n",
       "     emotion  confidence_score  \\\n",
       "0    neutral              0.70   \n",
       "1    neutral              0.00   \n",
       "2    neutral              0.64   \n",
       "3        joy              0.87   \n",
       "4    neutral              0.50   \n",
       "..       ...               ...   \n",
       "132  neutral              0.70   \n",
       "133  neutral              0.77   \n",
       "134  neutral              0.00   \n",
       "135  neutral              0.00   \n",
       "136      joy              0.67   \n",
       "\n",
       "                                               context  context_length  \\\n",
       "0    It was part of Le Chambon-sur-Lignon. And Le C...             348   \n",
       "1                                                                    0   \n",
       "2    who also lived in France as a refugee.  There ...             522   \n",
       "3    We began to set up the second home in October....             427   \n",
       "4    Jews who had come from Poland, from Germany, w...             217   \n",
       "..                                                 ...             ...   \n",
       "132  It was not only that village. It was also all ...             308   \n",
       "133  It was not only that village. It was also all ...             527   \n",
       "134                                                                  0   \n",
       "135                                                                  0   \n",
       "136  And we used to see all this activity. Men runn...            1634   \n",
       "\n",
       "    sub_category_emotion emotion_numeric  \n",
       "0                Neutral               4  \n",
       "1                Neutral               4  \n",
       "2                Neutral               4  \n",
       "3         Compassion/Joy               3  \n",
       "4                Neutral               4  \n",
       "..                   ...             ...  \n",
       "132              Neutral               4  \n",
       "133              Neutral               4  \n",
       "134              Neutral               4  \n",
       "135              Neutral               4  \n",
       "136     Sensory Pleasure               3  \n",
       "\n",
       "[137 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take response output in json format, put into a dataframe, then assign numeric values \n",
    "# to the detected emotions.\n",
    "\n",
    "df = pd.DataFrame(analysis_results)\n",
    "\n",
    "conditions = [\n",
    "    df[\"emotion\"] == \"anger\",\n",
    "    df[\"emotion\"] == \"disgust\",\n",
    "    df[\"emotion\"] == \"fear\",\n",
    "    df[\"emotion\"] == \"joy\",\n",
    "    df[\"emotion\"] == \"neutral\",\n",
    "    df[\"emotion\"] == \"sadness\",\n",
    "    df[\"emotion\"] == \"surprise\"\n",
    "]\n",
    "values = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "df[\"emotion_numeric\"] = np.select(conditions, values, default=\"Unknown\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8507d3b1-0e7e-4a8d-b3d8-045f6a81eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to csv\n",
    "\n",
    "df.to_csv(\"Results_ToponymsEmotions_GPT.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d710ff0e-440b-43f0-a17f-8be216546394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      latitude   longitude emotion_value  proportion emotion_label  \\\n",
      "0   -34.000000  -64.000000             4         1.0       neutral   \n",
      "1    -8.783195   34.508523             4         1.0       neutral   \n",
      "2     0.000000    0.000000             4         1.0       neutral   \n",
      "3    21.521757  -77.781167             5         1.0       sadness   \n",
      "4    26.000000   17.000000             4         1.0       neutral   \n",
      "..         ...         ...           ...         ...           ...   \n",
      "98   54.526000   15.255100             4         1.0       neutral   \n",
      "99   55.000000   40.000000             4         1.0       neutral   \n",
      "100  55.169438   23.881275             4         1.0       neutral   \n",
      "101  55.378051   -3.435973             4         1.0       neutral   \n",
      "102  60.000000  105.000000             4         1.0       neutral   \n",
      "\n",
      "     average_confidence_score  \n",
      "0                        0.00  \n",
      "1                        0.00  \n",
      "2                        0.00  \n",
      "3                        0.92  \n",
      "4                        0.00  \n",
      "..                        ...  \n",
      "98                       0.00  \n",
      "99                       0.00  \n",
      "100                      0.50  \n",
      "101                      0.00  \n",
      "102                      0.70  \n",
      "\n",
      "[103 rows x 6 columns]\n",
      "      latitude   longitude emotion_value  proportion emotion_label  \\\n",
      "3    21.521757  -77.781167             5         1.0       sadness   \n",
      "10   40.712775  -74.005973             4         1.0       neutral   \n",
      "11   40.764400  -73.774100             4         1.0       neutral   \n",
      "15   42.624167    3.023333             5         1.0       sadness   \n",
      "17   42.799072    2.872403             1         1.0       disgust   \n",
      "..         ...         ...           ...         ...           ...   \n",
      "92   51.165700   10.451500             4         1.0       neutral   \n",
      "94   51.919438   19.145136             4         1.0       neutral   \n",
      "97   52.520007   13.404954             4         1.0       neutral   \n",
      "100  55.169438   23.881275             4         1.0       neutral   \n",
      "102  60.000000  105.000000             4         1.0       neutral   \n",
      "\n",
      "     average_confidence_score                   resolved_name  \n",
      "3                        0.92                            Cuba  \n",
      "10                       0.82                   New York City  \n",
      "11                       0.15  Bayside, Queens, New York, USA  \n",
      "15                       0.87              Camp Saint-Cyprien  \n",
      "17                       0.83                      Rivesaltes  \n",
      "..                        ...                             ...  \n",
      "92                       0.30                    West Germany  \n",
      "94                       0.50                          Poland  \n",
      "97                       0.80                          Berlin  \n",
      "100                      0.50                       Lithuania  \n",
      "102                      0.70                         Siberia  \n",
      "\n",
      "[70 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# COUNT/PROPORTION of EMOTION SCORES of LOCATIONS:  Calculate the COUNT of each emotion detected at a \n",
    "# given set of coordinates then calculate the proportion at that location of each emotion...\n",
    "# The first line groups by the coordinates of the locations, and COUNTS the occurrences of emotion \n",
    "# scores (in the column \"emotion_numeric\"), then the \"normalize=True\" argument calculates and returns the \n",
    "# relative frequency of that score.  \n",
    "# The next line renames the column for \"emotion_numeric\" to \"emotion_value.\"\n",
    "# The next sequence of lines sets conditions to add the \"labels\" to the \"emotion_value\" scores.\n",
    "# The next 3 lines calculates the confidence scores for the detected emotions at each location, merges the\n",
    "# results with the normalized count dataframe and prints the results.\n",
    "# Then the next line exports results to a csv.\n",
    "\n",
    "df_count = df.groupby([\"latitude\", \"longitude\"], as_index=False)[\"emotion_numeric\"].value_counts(normalize=True)\n",
    "df_count = df_count.rename(columns={\"emotion_numeric\": \"emotion_value\"})\n",
    "conditions = [\n",
    "    df_count[\"emotion_value\"] == \"0\",\n",
    "    df_count[\"emotion_value\"] == \"1\",\n",
    "    df_count[\"emotion_value\"] == \"2\",\n",
    "    df_count[\"emotion_value\"] == \"3\",\n",
    "    df_count[\"emotion_value\"] == \"4\",\n",
    "    df_count[\"emotion_value\"] == \"5\",\n",
    "    df_count[\"emotion_value\"] == \"6\"\n",
    "]\n",
    "values = [\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "df_count[\"emotion_label\"] = np.select(conditions, values, default=\"Unknown\")\n",
    "df_confScore = df.groupby([\"latitude\", \"longitude\"], as_index=False)[\"confidence_score\"].mean()\n",
    "df_confScore = df_confScore.rename(columns={\"confidence_score\": \"average_confidence_score\"})\n",
    "df_count_conf = pd.merge(df_count, df_confScore, on=(\"latitude\", \"longitude\"), how=\"left\")\n",
    "print(df_count_conf)\n",
    "\n",
    "# To merge the above results with the names, in order to have labels on the coordinates...\n",
    "# Create subset of original dataframe with the toponyms and coordinates\n",
    "df_toponyms = df[[\"resolved_name\", \"latitude\", \"longitude\"]]\n",
    "# Delete rows with a value of zero in latitude and longitude (i.e. they were not resolved because GPT \n",
    "# did not think they were toponyms)\n",
    "df_toponyms = df_toponyms[~((df_toponyms['latitude'] == 0) & (df_toponyms['longitude'] == 0))]\n",
    "# Now, have to get reduce to one the toponyms at a set of coordinates, since, for example, in Le Chambon\n",
    "# there are multiple toponyms with the same coordinates (the village, L'Abric, College Cevenol, etc.). We\n",
    "# will do this by simply returning the column with the longest length.  Not ideal, but it works OK.\n",
    "# First, create a column for string length\n",
    "df_toponyms['Toponym_Length'] = df_toponyms['resolved_name'].str.len()\n",
    "# Then, sort dataframe in descending order based on the merge keys and the new length column.  \n",
    "# This ensures that the rows with the longest strings will appear first for each key. \n",
    "df_toponyms = df_toponyms.sort_values(by=[\"latitude\", \"longitude\", 'Toponym_Length'], ascending=[True, True, False])\n",
    "#  Use drop_duplicates() on the merge key column ('ID' in this case), keeping only the first occurrence \n",
    "# for each key. Since the DataFrame is sorted by length, this will effectively keep the row with the \n",
    "# longest string for each duplicate key\n",
    "df_toponyms = df_toponyms.drop_duplicates(subset=[\"latitude\", \"longitude\"], keep='first')\n",
    "# Drop the temporary length column:\n",
    "df_toponyms = df_toponyms.drop(columns=['Toponym_Length'])\n",
    "# Merge the dataframe with the proportional emotion detection results with the new one with the names, \n",
    "# merged on the coordinates, and with no duplicate names at any coordinates.\n",
    "df_count_conf_labeled = pd.merge(df_count_conf, df_toponyms, on=(\"latitude\", \"longitude\"), how=\"left\")\n",
    "# Delete rows with a value of zero in the average confidence score column, since these are (supposed to be) \n",
    "# only toponyms outside of France that no emotion analysis was run on and thus irrelevant.\n",
    "df_count_conf_labeled = df_count_conf_labeled[df_count_conf_labeled['average_confidence_score'] != 0]\n",
    "print(df_count_conf_labeled)\n",
    "df_count_conf_labeled.to_csv(\"Results_ToponymsEmotions_GPT_Proportion.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241b63d-e363-48b0-aabe-cad6f54f0ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
