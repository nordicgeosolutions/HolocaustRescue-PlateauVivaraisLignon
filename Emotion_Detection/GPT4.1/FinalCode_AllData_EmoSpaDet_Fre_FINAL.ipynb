{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86cb0dd-3e07-4a27-8ce3-d215cb3b565f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea02a0b-938e-4a08-b8e9-84dea9839dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## Load the FRENCH-language dataset for analysis.\n",
    "path = \"YOUR_DATA_Fre\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    # Reads all .txt files in a directory and returns a combined string of their contents.\n",
    "\n",
    "    file_contents = ''\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
    "                file_contents = file_contents + (f.read())\n",
    "    return file_contents\n",
    "\n",
    "texts = read_txt_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef35a15-aaeb-4098-b995-50bb20e68e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 465 char-based chunks for extraction.\n",
      "\n",
      "Initial extraction stage complete: Got 561 toponym instances (with possible duplicates).\n",
      "Deduplicated toponyms: 561 → 154\n",
      "\n",
      "Stage 1 complete: Saved 154 unique toponym instances to file.\n",
      "Warning: Toponym la Joyeuse-Nichée not found in text.\n",
      "Analyzed: Chambon-sur-Lignon (from .toponym_instances)\n",
      "Analyzed: France (from .toponym_instances)\n",
      "Analyzed: Suisse (from .toponym_instances)\n",
      "Analyzed: Haute-Loire (from .toponym_instances)\n",
      "Analyzed: Marseille (from .toponym_instances)\n",
      "Analyzed: Fay-sur-Lignon (from .toponym_instances)\n",
      "Analyzed: Le Chambon-sur-Lignon (from .toponym_instances)\n",
      "Analyzed: vallée du Rhône (from .toponym_instances)\n",
      "Analyzed: Lyon (from .toponym_instances)\n",
      "Analyzed: le Puy (from .toponym_instances)\n",
      "Analyzed: Lausanne (from .toponym_instances)\n",
      "Analyzed: Treblinka (from .toponym_instances)\n",
      "Analyzed: La Voulte-sur-Rhône (from .toponym_instances)\n",
      "Analyzed: Livron (from .toponym_instances)\n",
      "Analyzed: Au Puy (from .toponym_instances)\n",
      "Analyzed: Gurs (from .toponym_instances)\n",
      "Analyzed: l'Ardèche (from .toponym_instances)\n",
      "Analyzed: Paris (from .toponym_instances)\n",
      "Analyzed: Sainte-Étienne (from .toponym_instances)\n",
      "Analyzed: massif central (from .toponym_instances)\n",
      "Analyzed: Espagne (from .toponym_instances)\n",
      "Analyzed: Collège Cévenol (from .toponym_instances)\n",
      "Analyzed: Tarbes (from .toponym_instances)\n",
      "Analyzed: Paris 9e, arrondissement (from .toponym_instances)\n",
      "Analyzed: la drôme (from .toponym_instances)\n",
      "Analyzed: Pétersbourg (from .toponym_instances)\n",
      "Analyzed: Dieu le Fil (from .toponym_instances)\n",
      "Analyzed: Drancy (from .toponym_instances)\n",
      "Analyzed: Nice (from .toponym_instances)\n",
      "Analyzed: Moirance (from .toponym_instances)\n",
      "Analyzed: Yssingeaux (from .toponym_instances)\n",
      "Analyzed: la rue (from .toponym_instances)\n",
      "Analyzed: Krzemieniec (from .toponym_instances)\n",
      "Analyzed: Ukraine (from .toponym_instances)\n",
      "Analyzed: Saint-Étienne (from .toponym_instances)\n",
      "Analyzed: Wołyń (from .toponym_instances)\n",
      "Analyzed: Russie (from .toponym_instances)\n",
      "Analyzed: L.Rose (from .toponym_instances)\n",
      "Analyzed: Etats-Unis (from .toponym_instances)\n",
      "Analyzed: pension Barraud (from .toponym_instances)\n",
      "Analyzed: Rouen (from .toponym_instances)\n",
      "Analyzed: Égypte (from .toponym_instances)\n",
      "Analyzed: Provence (from .toponym_instances)\n",
      "Analyzed: Saint-Etienne (from .toponym_instances)\n",
      "Analyzed: Tence (from .toponym_instances)\n",
      "Analyzed: Plateau Vivarais (from .toponym_instances)\n",
      "Analyzed: école Cévenol (from .toponym_instances)\n",
      "Analyzed: village (from .toponym_instances)\n",
      "Analyzed: la Drey (from .toponym_instances)\n",
      "Analyzed: 12e arrondissement (from .toponym_instances)\n",
      "Analyzed: Les Digons (from .toponym_instances)\n",
      "Analyzed: temple (from .toponym_instances)\n",
      "Analyzed: Cévennes (from .toponym_instances)\n",
      "Analyzed: Stalingrad (from .toponym_instances)\n",
      "Analyzed: zone libre (from .toponym_instances)\n",
      "Analyzed: Les Sèches (from .toponym_instances)\n",
      "Analyzed: Montfaucon (from .toponym_instances)\n",
      "Analyzed: Mont Mézenc (from .toponym_instances)\n",
      "Analyzed: Remière (from .toponym_instances)\n",
      "Analyzed: Mazet-Saint-Voy (from .toponym_instances)\n",
      "Analyzed: Tunis (from .toponym_instances)\n",
      "Analyzed: Saint-Agreve (from .toponym_instances)\n",
      "Analyzed: Cheylar (from .toponym_instances)\n",
      "Analyzed: Lycée Cévenol (from .toponym_instances)\n",
      "Analyzed: Londres (from .toponym_instances)\n",
      "Analyzed: Nîmes (from .toponym_instances)\n",
      "Analyzed: Gorges (from .toponym_instances)\n",
      "Analyzed: Saint-Clément (from .toponym_instances)\n",
      "Analyzed: Freycenet (from .toponym_instances)\n",
      "Analyzed: Mont Mouchet (from .toponym_instances)\n",
      "Analyzed: Bretagne (from .toponym_instances)\n",
      "Analyzed: Israël (from .toponym_instances)\n",
      "Analyzed: Belgique (from .toponym_instances)\n",
      "Analyzed: Vallées (from .toponym_instances)\n",
      "Analyzed: Pyrénées (from .toponym_instances)\n",
      "Analyzed: le Lignon (from .toponym_instances)\n",
      "Analyzed: Anvers (from .toponym_instances)\n",
      "Analyzed: Amérique (from .toponym_instances)\n",
      "Analyzed: Saint-Agrève (from .toponym_instances)\n",
      "Analyzed: Airelles (from .toponym_instances)\n",
      "Analyzed: Chambon sur Lignon (from .toponym_instances)\n",
      "Analyzed: Haute Loire (from .toponym_instances)\n",
      "Analyzed: Saint-Cergues (from .toponym_instances)\n",
      "Analyzed: Palestine (from .toponym_instances)\n",
      "Analyzed: Les Heures Claires (from .toponym_instances)\n",
      "Analyzed: Vichy (from .toponym_instances)\n",
      "Analyzed: Europe (from .toponym_instances)\n",
      "Analyzed: Strasbourg (from .toponym_instances)\n",
      "Analyzed: Normandie (from .toponym_instances)\n",
      "Analyzed: plateau Cévenol (from .toponym_instances)\n",
      "Analyzed: Fréjus (from .toponym_instances)\n",
      "Analyzed: Darcissac (from .toponym_instances)\n",
      "Analyzed: Isieux (from .toponym_instances)\n",
      "Analyzed: Afrique du Nord (from .toponym_instances)\n",
      "Analyzed: Villars (from .toponym_instances)\n",
      "Analyzed: Mulhouse (from .toponym_instances)\n",
      "Analyzed: Haut-Rhin (from .toponym_instances)\n",
      "Analyzed: Nantes (from .toponym_instances)\n",
      "Analyzed: Allemagne (from .toponym_instances)\n",
      "Analyzed: Canaan (from .toponym_instances)\n",
      "Analyzed: le Mas de Tence (from .toponym_instances)\n",
      "Analyzed: Sébastopol (from .toponym_instances)\n",
      "Analyzed: Lorraine (from .toponym_instances)\n",
      "Analyzed: Troyes (from .toponym_instances)\n",
      "Analyzed: l'Alsace (from .toponym_instances)\n",
      "Analyzed: l'université de Grenoble (from .toponym_instances)\n",
      "Analyzed: canton (from .toponym_instances)\n",
      "Analyzed: Genève (from .toponym_instances)\n",
      "Analyzed: Alsace (from .toponym_instances)\n",
      "Analyzed: européen (from .toponym_instances)\n",
      "Analyzed: Württemberg (from .toponym_instances)\n",
      "Analyzed: camp de Gurs (from .toponym_instances)\n",
      "Analyzed: La Papeterie (from .toponym_instances)\n",
      "Analyzed: Nuremberg (from .toponym_instances)\n",
      "Analyzed: la Madeleine (from .toponym_instances)\n",
      "Analyzed: ligne Thaude (from .toponym_instances)\n",
      "Analyzed: Vosges (from .toponym_instances)\n",
      "Analyzed: Val d'Ajolle (from .toponym_instances)\n",
      "Analyzed: rue Cambon (from .toponym_instances)\n",
      "Analyzed: Beaune (from .toponym_instances)\n",
      "Analyzed: Algérie (from .toponym_instances)\n",
      "Analyzed: mur de l'Atlantique (from .toponym_instances)\n",
      "Analyzed: Toules (from .toponym_instances)\n",
      "Analyzed: Nancy (from .toponym_instances)\n",
      "Analyzed: le Mazelgirard (from .toponym_instances)\n",
      "Analyzed: Riom (from .toponym_instances)\n",
      "Analyzed: Le Fourezon (from .toponym_instances)\n",
      "Analyzed: Gard (from .toponym_instances)\n",
      "Analyzed: Versillac (from .toponym_instances)\n",
      "Analyzed: Angleterre (from .toponym_instances)\n",
      "Analyzed: Hameau du Mazelgirard (from .toponym_instances)\n",
      "Analyzed: côte d'azur (from .toponym_instances)\n",
      "Analyzed: Jérusalem (from .toponym_instances)\n",
      "Analyzed: Chaumargeais (from .toponym_instances)\n",
      "Analyzed: Lamastre (from .toponym_instances)\n",
      "Analyzed: Spire (from .toponym_instances)\n",
      "Analyzed: Villeret (from .toponym_instances)\n",
      "Analyzed: Lille (from .toponym_instances)\n",
      "Analyzed: La Joyeuse (from .toponym_instances)\n",
      "Analyzed: Les Grillons (from .toponym_instances)\n",
      "Analyzed: Grillons (from .toponym_instances)\n",
      "Analyzed: le Haut (from .toponym_instances)\n",
      "Analyzed: La Ruchée (from .toponym_instances)\n",
      "Analyzed: Chambonnais (from .toponym_instances)\n",
      "Analyzed: Tarno (from .toponym_instances)\n",
      "Analyzed: Cévènes (from .toponym_instances)\n",
      "Analyzed: Clermont-Ferrand (from .toponym_instances)\n",
      "Analyzed: la gare du Chambon-sur-Lignon (from .toponym_instances)\n",
      "Analyzed: Roches (from .toponym_instances)\n",
      "Analyzed: Pré de Grennes (from .toponym_instances)\n",
      "Analyzed: Saint-André (from .toponym_instances)\n",
      "Analyzed: Dunière (from .toponym_instances)\n",
      "Analyzed: Toulouse (from .toponym_instances)\n",
      "Analyzed: la Joyeuse-Nichée (from .toponym_instances)\n",
      "\n",
      "Stage 2 complete: Produced 149 detailed toponym analyses.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Developing function to identify and resolve toponyms, and detect emotions in context \n",
    "on either side of each toponym.  Context length is based on trying different lengths,\n",
    "with the final context length chosen based on which gives the most likely detected emotion\n",
    "with the highest confidence score.\n",
    "\n",
    "\"\"\"\n",
    "# Access libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import hashlib\n",
    "from difflib import SequenceMatcher\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Set a global variable for my OpenAI API key so that the model can be accessed.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_KEY\"\n",
    "client = OpenAI()\n",
    "\n",
    "# Alternative data for testing and to DEBUG:\n",
    "#texts = \"I traveled from Paris to Berlin and saw New York on the way.  It was fantastic.  I was so happy.\"\n",
    "\n",
    "# ========== Robust OpenAI Output Extraction ==========\n",
    "def extract_json_from_arguments(response):\n",
    "    \"\"\"\n",
    "    Robust extraction for OpenAI responses.\n",
    "    Handles both function call and text output scenarios.\n",
    "    Returns dict or list or [].\n",
    "    \"\"\"\n",
    "    # Case 1: Function call pattern\n",
    "    if hasattr(response, \"output\") and response.output:\n",
    "        first = response.output[0]\n",
    "        if hasattr(first, \"arguments\"): # should be a string\n",
    "            arguments_string = first.arguments\n",
    "            if isinstance(arguments_string, (str, bytes)):\n",
    "                try:\n",
    "                    return json.loads(arguments_string)\n",
    "                except Exception as e:\n",
    "                    print(f\"JSON parsing error: {e}\")\n",
    "                    return []\n",
    "            else:\n",
    "                # If already parsed (rare)\n",
    "                return arguments_string\n",
    "        # If it's classic text response\n",
    "        if hasattr(first, \"content\") and first.content:\n",
    "            text_fragment = getattr(first.content[0], \"text\", None)\n",
    "            if text_fragment:\n",
    "                try:\n",
    "                    return json.loads(text_fragment)\n",
    "                except Exception as e:\n",
    "                    print(f\"JSON parsing error (text): {e}\\nTEXT: {text_fragment}\")\n",
    "                    return []\n",
    "    # Case 2: Tool-style .outputs (not present in your current responses)\n",
    "    if hasattr(response, \"outputs\") and response.outputs and hasattr(response.outputs[0], \"arguments\"):\n",
    "        arguments = response.outputs[0].arguments\n",
    "        if arguments is not None:\n",
    "            return arguments\n",
    "    print(\"No recognizable output format found in OpenAI response.\")\n",
    "    return []\n",
    "\n",
    "# 2. Character-based Chunking (if needed).\n",
    "# Reduced number of characters to just 600, with no overlap at all.  \n",
    "\n",
    "def chunk_text_by_chars(text, chunk_size=600, overlap=0):\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    text_len = len(text)\n",
    "    while i < text_len:\n",
    "        start_char = i\n",
    "        end_char = min(i + chunk_size, text_len)\n",
    "        chunk_text = text[start_char:end_char]\n",
    "        chunks.append((chunk_text, start_char))\n",
    "        if end_char == text_len:\n",
    "            break\n",
    "        i += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# 3. API Call with Retry for Thread Use\n",
    "\n",
    "def call_api_with_retry_chunk(chunk, extraction_instructions, client, max_output_tokens=2048, retries=4):\n",
    "    # print(\"Chunk being sent:\", repr(chunk))     # Can use this to DEBUG chunk issues\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4.1-2025-04-14\",\n",
    "                instructions=extraction_instructions,\n",
    "                input=chunk,\n",
    "                text={\"format\": {\"type\": \"text\"}},\n",
    "                reasoning={},\n",
    "                tools=[\n",
    "                    {\n",
    "                        \"type\": \"function\",\n",
    "                        \"name\": \"recognize_toponyms\",\n",
    "                        \"description\": \"Given the user input text, identify all the toponyms in the text.\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"required\": [\"input_text\", \"toponyms\"],\n",
    "                            \"properties\": {\n",
    "                                \"input_text\": {\n",
    "                                    \"type\": \"string\", \n",
    "                                    \"description\": \"The text string from which to recognize and identify toponyms.\"\n",
    "                                },\n",
    "                                \"toponyms\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"description\": \"Array of recognized and identified toponyms.\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"toponym\": {\"type\": \"string\"}\n",
    "                                        },\n",
    "                                        \"required\": [\"toponym\"],\n",
    "                                        \"additionalProperties\": False\n",
    "                                    }\n",
    "                                }\n",
    "                            },\n",
    "                            \"additionalProperties\": False\n",
    "                        },\n",
    "                        \"strict\": True\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "                tool_choice=\"required\",\n",
    "                max_output_tokens=max_output_tokens,\n",
    "                top_p=1,\n",
    "                store=True\n",
    "            )\n",
    "            \"\"\" These next three lines can be used to DEBUG responses or lack thereof\n",
    "            print(\"Raw response:\", response)\n",
    "            extracted = extract_json_from_arguments(response)\n",
    "            print(\"Extracted:\", extracted)\n",
    "            \"\"\"\n",
    "            return extract_json_from_arguments(response)         \n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"[API] Error: {e}\\nRetrying in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "    print(f\"[API] Failed after retries.\")\n",
    "    return []\n",
    "\n",
    "# 4. Stage 1: Parallel Toponym Extraction\n",
    "\n",
    "# ====== Load Extraction Prompt ======\n",
    "with open(\"FinalPrompt_openai_ToponymExtraction_prompt_FINAL.txt\", encoding=\"utf-8\") as f:\n",
    "    extraction_instructions = f.read()\n",
    "\n",
    "# ====== Chunk Input ======\n",
    "    # chunk via characters\n",
    "chunks = chunk_text_by_chars(texts, chunk_size=600, overlap=0)\n",
    "print(f\"Text split into {len(chunks)} char-based chunks for extraction.\")\n",
    "\n",
    "# ====== Run Extraction in Parallel ======\n",
    "max_workers = 20   # safe for modern high-tier; can adjust up/down\n",
    "extracted_toponyms = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            call_api_with_retry_chunk, chunk, extraction_instructions, client\n",
    "        )\n",
    "        for chunk, _ in chunks\n",
    "    ]\n",
    "    for f in as_completed(futures):\n",
    "        result = f.result()\n",
    "        # print(\"DEBUG:\", result)          # Can use this if need to DEBUG results\n",
    "        if isinstance(result, dict) and \"toponyms\" in result:\n",
    "            extracted_toponyms += result[\"toponyms\"]\n",
    "        elif isinstance(result, list):\n",
    "            extracted_toponyms += result\n",
    "        else:\n",
    "            print(\"Warning: Unexpected result format\", result)\n",
    "\n",
    "print(f\"\\nInitial extraction stage complete: Got {len(extracted_toponyms)} toponym instances (with possible duplicates).\")\n",
    "\n",
    "# ------------------ DEDUPLICATION STEP --------------------\n",
    "def get_local_context(text, name, window=50):\n",
    "    \"\"\"Find the first occurrence of name in text and return local context window.\"\"\"\n",
    "    lowers = text.lower()\n",
    "    name_lower = name.lower()\n",
    "    idx = lowers.find(name_lower)\n",
    "    if idx == -1:\n",
    "        # fallback: just use the first window of the text (may dedupe global substrings, edge case)\n",
    "        return text[:2*window]\n",
    "    start = max(0, idx - window)\n",
    "    end = min(len(text), idx + len(name) + window)\n",
    "    return text[start:end]\n",
    "\n",
    "def deduplicate_by_fuzzy_context_and_longest(toponym_list, texts, window=50, similarity=0.90):\n",
    "    \"\"\"\n",
    "    Group extracted toponyms by fuzzy context similarity.\n",
    "    Keeps only the longest (most specific) name in each group.\n",
    "    Can be more aggressive with wider window & lower similarity threshold!!\n",
    "    \"\"\"\n",
    "    items = [\n",
    "        (t['toponym'].strip(), get_local_context(texts, t['toponym'].strip(), window), t)\n",
    "        for t in toponym_list\n",
    "    ]\n",
    "    groups = []\n",
    "    used = set()\n",
    "    for i, (name_i, ctx_i, obj_i) in enumerate(items):\n",
    "        if i in used: continue\n",
    "        group = [(name_i, ctx_i, obj_i)]\n",
    "        used.add(i)\n",
    "        for j, (name_j, ctx_j, obj_j) in enumerate(items):\n",
    "            if j <= i or j in used: continue\n",
    "            if ctx_i and ctx_j:\n",
    "                score = SequenceMatcher(None, ctx_i, ctx_j).ratio()\n",
    "                if score >= similarity:\n",
    "                    group.append((name_j, ctx_j, obj_j))\n",
    "                    used.add(j)\n",
    "        # Within the group, eliminate all substrings: keep only the longest(s)\n",
    "        group.sort(key=lambda g: len(g[0]), reverse=True)\n",
    "        deduped_names = set()\n",
    "        deduped_objs = []\n",
    "        for name, ctx, obj in group:\n",
    "            if not any(name in longer for longer in deduped_names if len(name) < len(longer)):\n",
    "                deduped_names.add(name)\n",
    "                deduped_objs.append(obj)\n",
    "        # Option 1: Only keep the very longest:\n",
    "        groups.append(deduped_objs[0])\n",
    "        # Option 2: To keep all equally-long max variants, use:\n",
    "        # groups.extend(deduped_objs[:1])  # or groups.extend(deduped_objs)\n",
    "    return groups\n",
    "    \n",
    "before = len(extracted_toponyms)\n",
    "extracted_toponyms = deduplicate_by_fuzzy_context_and_longest(extracted_toponyms, texts, window=50, similarity=0.90)\n",
    "after = len(extracted_toponyms)\n",
    "print(f\"Deduplicated toponyms: {before} → {after}\")\n",
    "\n",
    "# ------------------ END DEDUPLICATION STEP --------------------\n",
    "\n",
    "\n",
    "with open(\"extracted_toponyms.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(extracted_toponyms, f, ensure_ascii=False, indent=2)\n",
    "print(f\"\\nStage 1 complete: Saved {len(extracted_toponyms)} unique toponym instances to file.\")\n",
    "\n",
    "# 5. Stage 2: Parallel Toponym Analysis\n",
    "\n",
    "# ====== Load Analysis Prompt ======\n",
    "with open(\"FinalPrompt_openai_ToponymEmotionAnalysis_prompt_FINAL.txt\", encoding=\"utf-8\") as f:\n",
    "    analysis_instructions = f.read()\n",
    "\n",
    "def call_api_with_retry_analysis(\n",
    "    toponym_obj,\n",
    "    texts,\n",
    "    client,\n",
    "    analysis_instructions,\n",
    "    max_output_tokens=32000,\n",
    "    retries=4,\n",
    "):\n",
    "    toponym_str = toponym_obj[\"toponym\"]\n",
    "    user_input = {\n",
    "        \"original_text\": texts,\n",
    "        \"toponym_instances\": [{**toponym_obj}]\n",
    "    }\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4.1-2025-04-14\",\n",
    "                instructions=analysis_instructions,\n",
    "                input=json.dumps(user_input),\n",
    "                text={\"format\": {\"type\": \"text\"}},\n",
    "                reasoning={},\n",
    "                tools=[{\n",
    "                    \"type\": \"function\",\n",
    "                    \"name\": \"resolve_toponyms_and_detect_emotions\",\n",
    "                    \"description\": (\n",
    "                        \"Given the user input of the original text and extracted toponyms, determine latitude and longitude of each toponym.\"\n",
    "                        \"If the toponym is in France then proceed and perform emotion detection. If not in France, then do no futher action on that toponym and do not include it in your response.\"\n",
    "                        \"Try multiple possible context window sizes (~different context lengths) for each French toponym and \"\n",
    "                        \"return the window (context) that maximizes the confidence score for the most likely detected emotion.\"\n",
    "                    ),\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"required\": [\"original_text\", \"toponym_instances\"],\n",
    "                        \"properties\": {\n",
    "                            \"original_text\": {\"type\": \"string\", \"description\": \"The text string from which to disambiguate toponyms and utilize their surrounding context.\"},\n",
    "                            \"toponym_instances\": {\n",
    "                                \"type\": \"array\",\n",
    "                \t\t\t\t\"description\": \"Array of identified toponyms, each containing properties of location details and emotional context.\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"required\": [\n",
    "                                        \"toponym\", \"resolved_name\", \"latitude\",\n",
    "                                        \"longitude\", \"emotion\", \"confidence_score\",\n",
    "                                        \"context\", \"context_length\", \"sub_category_emotion\"\n",
    "                                    ],\n",
    "                                    \"properties\": {\n",
    "                                        \"toponym\": {\"type\": \"string\", \"description\": \"The name of the toponym as found in the previous step.\"},\n",
    "                                        \"resolved_name\": {\"type\": \"string\", \"description\": \"The name of the resolved toponym as identified and disambiguated.\"},\n",
    "                                        \"latitude\": {\"type\": \"number\", \"description\": \"The latitude coordinate of the toponym.\"},\n",
    "                                        \"longitude\": {\"type\": \"number\", \"description\": \"The longitude coordinate of the toponym.\"},\n",
    "                                        \"emotion\": {\"type\": \"string\", \"description\": \"The most likely detected emotion around the toponym.\", \"enum\": [\n",
    "                                            \"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"\n",
    "                                        ]},\n",
    "                                        \"confidence_score\": {\"type\": \"number\", \"description\": \"The confidence score for the detected emotion, on a scale of 0 to 1.\"},\n",
    "                                        \"context\": {\"type\": \"string\", \"description\": \"The text block surrounding the toponym used for emotion detection, whose length is determined based on trying different lengths and seeing which one gives the highest confidence score for the most likely detected emotion.\"},\n",
    "                                        \"context_length\": {\"type\": \"number\", \"description\": \"The length, in characters including spaces, of the final text block surrounding the toponym used for emotion detection.\"},\n",
    "                                        \"sub_category_emotion\": {\"type\": \"string\", \"description\":  \"For each of the emotions that you concluded (anger, disgust, fear, joy, sadness, surprise, neutral), tell us which of the following sub-category of that emotion is most likely, using the Ekman emotion classification system\",\n",
    "                                                                \"enum\": [\"Annoyance\", \"Frustration\", \"Exasperation\", \"Argumentativeness\", \"Bitterness\", \"Vengefulness\", \"Fury\",\n",
    "                                                                         \"Dislike\", \"Aversion\", \"Distaste\", \"Repugnance\", \"Revulsion\", \"Abhorrence\", \"Loathing\",\n",
    "                                                                         \"Trepidation\", \"Nervousness\", \"Anxiety\", \"Dread\", \"Desperation\", \"Panic\", \"Horror\", \"Terror\",\n",
    "                                                                         \"Sensory Pleasure\", \"Rejoicing\", \"Compassion/Joy\", \"Amusement\", \"Schadenfreude\", \"Relief\", \"Peace\", \"Pride\", \"Fiero\", \"Naches\", \"Wonder\", \"Excitement\", \"Ecstasy\",\n",
    "                                                                         \"Disappointment\", \"Discouragement\", \"Distraughtness\", \"Resignation\", \"Helplessness\", \"Hopelessness\", \"Misery\", \"Despair\", \"Grief\", \"Sorrow\", \"Anguish\",\n",
    "                                                                         \"Surprise\",\n",
    "                                                                         \"Neutral\"\n",
    "                                                                        ]}\n",
    "                                    },\n",
    "                                    \"additionalProperties\": False,\n",
    "                                },\n",
    "                            }\n",
    "                        },\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                    \"strict\": True\n",
    "                }],\n",
    "                temperature=1,\n",
    "                tool_choice=\"required\",\n",
    "                max_output_tokens=max_output_tokens,\n",
    "                top_p=1,\n",
    "                store=True\n",
    "            )\n",
    "            return extract_json_from_arguments(response), toponym_str\n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"[API] Analysis error for '{toponym_str}': {e}\\nRetrying in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "    print(f\"[API] Analysis failed after retries for '{toponym_str}'.\")\n",
    "    return {\"toponym\": toponym_str, \"error\": \"Failed after retries\"}, toponym_str\n",
    "\n",
    "# Run Stage 2 in Parallel\n",
    "\n",
    "# ---- Load the extracted_toponyms ----\n",
    "with open(\"extracted_toponyms.json\", encoding=\"utf-8\") as f:\n",
    "    extracted_toponyms = json.load(f)\n",
    "\"\"\"    \n",
    "# This sets a context window that is at the maximum of 600 characters to avoid the sometimes random \n",
    "5000-character context windows that the model decides to use when calling the function, even though\n",
    "I told it to not give me more than 600 character windows\n",
    "\"\"\"\n",
    "def get_context(text, toponym, window=600):\n",
    "    idx = text.lower().find(toponym.lower())\n",
    "    if idx == -1:\n",
    "        print(f\"Warning: Toponym {toponym} not found in text.\")\n",
    "        return text\n",
    "    start = max(0, idx - window)\n",
    "    end = min(len(text), idx + len(toponym) + window)\n",
    "    return text[start:end]\n",
    "\n",
    "analysis_results = []\n",
    "\"\"\"\n",
    "Keep max_workers relatively low to prevent truncation of output (which results in \"JSON parsing errors\" \n",
    "due to attempting this on a truncated \"list\" rather than the actual dictionary that it is).  \n",
    "Also keeps it below rate limits.\n",
    "\"\"\"\n",
    "max_workers_analysis = 6\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers_analysis) as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            call_api_with_retry_analysis, t, get_context(texts, t[\"toponym\"]), client, analysis_instructions, 32000\n",
    "        )\n",
    "        for t in extracted_toponyms\n",
    "    ]\n",
    "    for f in as_completed(futures):\n",
    "        batch_result, toponym_str = f.result()\n",
    "        # Handle lists/dicts as before\n",
    "        if isinstance(batch_result, list):\n",
    "            analysis_results += batch_result\n",
    "            print(f\"Analyzed: {toponym_str} (got list)\")\n",
    "        elif isinstance(batch_result, dict) and \"toponym_instances\" in batch_result:\n",
    "            analysis_results += batch_result[\"toponym_instances\"]\n",
    "            print(f\"Analyzed: {toponym_str} (from .toponym_instances)\")\n",
    "        else:\n",
    "            analysis_results.append(batch_result)\n",
    "            print(f\"Analyzed: {toponym_str} (error or unexpected shape)\")\n",
    "\n",
    "with open(\"analysis_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(analysis_results, f, ensure_ascii=False, indent=2)\n",
    "print(f\"\\nStage 2 complete: Produced {len(analysis_results)} detailed toponym analyses.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d34a460-9826-4e63-8f62-5137413ccc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toponym</th>\n",
       "      <th>resolved_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>emotion</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>sub_category_emotion</th>\n",
       "      <th>emotion_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chambon-sur-Lignon</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>46.603354</td>\n",
       "      <td>1.888334</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.70</td>\n",
       "      <td>j'ai vécu dans un village de la \\nFrance profo...</td>\n",
       "      <td>527</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suisse</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>46.818188</td>\n",
       "      <td>8.227512</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.53</td>\n",
       "      <td>et les protestants ont reçu des aides et des s...</td>\n",
       "      <td>335</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haute-Loire</td>\n",
       "      <td>Haute-Loire</td>\n",
       "      <td>45.083300</td>\n",
       "      <td>3.916700</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.79</td>\n",
       "      <td>dans un village de 1500 habitants à la limite ...</td>\n",
       "      <td>486</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marseille</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>43.296482</td>\n",
       "      <td>5.369780</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Quelques jours après, mon père a décidé qu'on ...</td>\n",
       "      <td>389</td>\n",
       "      <td>Resignation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Pré de Grennes</td>\n",
       "      <td>Pré de Grennes</td>\n",
       "      <td>45.060810</td>\n",
       "      <td>4.302941</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.81</td>\n",
       "      <td>Mes parents sont venus habiter le Chambon-sur-...</td>\n",
       "      <td>268</td>\n",
       "      <td>Sensory Pleasure</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Saint-André</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Dunière</td>\n",
       "      <td>Dunière</td>\n",
       "      <td>45.208545</td>\n",
       "      <td>4.298853</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.77</td>\n",
       "      <td>Donc, on prenait la ligne normale de Saint-Éti...</td>\n",
       "      <td>532</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Toulouse</td>\n",
       "      <td>Toulouse</td>\n",
       "      <td>43.604652</td>\n",
       "      <td>1.444209</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.68</td>\n",
       "      <td>Mais j'avais plus hâte que jamais de participe...</td>\n",
       "      <td>375</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>la Joyeuse-Nich\u0000e9e</td>\n",
       "      <td>La Joyeuse-Nichée, Chambon-sur-Lignon</td>\n",
       "      <td>45.060810</td>\n",
       "      <td>4.302941</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.88</td>\n",
       "      <td>Donc il fallait nous éloigner, en tout cas mon...</td>\n",
       "      <td>1071</td>\n",
       "      <td>Relief</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 toponym                          resolved_name   latitude  \\\n",
       "0     Chambon-sur-Lignon                                          0.000000   \n",
       "1                 France                                 France  46.603354   \n",
       "2                 Suisse                            Switzerland  46.818188   \n",
       "3            Haute-Loire                            Haute-Loire  45.083300   \n",
       "4              Marseille                              Marseille  43.296482   \n",
       "..                   ...                                    ...        ...   \n",
       "144       Pré de Grennes                         Pré de Grennes  45.060810   \n",
       "145          Saint-André                                          0.000000   \n",
       "146              Dunière                                Dunière  45.208545   \n",
       "147             Toulouse                               Toulouse  43.604652   \n",
       "148  la Joyeuse-Nich\u0000e9e  La Joyeuse-Nichée, Chambon-sur-Lignon  45.060810   \n",
       "\n",
       "     longitude  emotion  confidence_score  \\\n",
       "0     0.000000  neutral              0.00   \n",
       "1     1.888334  neutral              0.70   \n",
       "2     8.227512  neutral              0.53   \n",
       "3     3.916700  neutral              0.79   \n",
       "4     5.369780  sadness              0.92   \n",
       "..         ...      ...               ...   \n",
       "144   4.302941      joy              0.81   \n",
       "145   0.000000  neutral              0.00   \n",
       "146   4.298853  neutral              0.77   \n",
       "147   1.444209  neutral              0.68   \n",
       "148   4.302941      joy              0.88   \n",
       "\n",
       "                                               context  context_length  \\\n",
       "0                                                                    0   \n",
       "1    j'ai vécu dans un village de la \\nFrance profo...             527   \n",
       "2    et les protestants ont reçu des aides et des s...             335   \n",
       "3    dans un village de 1500 habitants à la limite ...             486   \n",
       "4    Quelques jours après, mon père a décidé qu'on ...             389   \n",
       "..                                                 ...             ...   \n",
       "144  Mes parents sont venus habiter le Chambon-sur-...             268   \n",
       "145                                                                  0   \n",
       "146  Donc, on prenait la ligne normale de Saint-Éti...             532   \n",
       "147  Mais j'avais plus hâte que jamais de participe...             375   \n",
       "148  Donc il fallait nous éloigner, en tout cas mon...            1071   \n",
       "\n",
       "    sub_category_emotion emotion_numeric  \n",
       "0                Neutral               4  \n",
       "1                Neutral               4  \n",
       "2                Neutral               4  \n",
       "3                Neutral               4  \n",
       "4            Resignation               5  \n",
       "..                   ...             ...  \n",
       "144     Sensory Pleasure               3  \n",
       "145              Neutral               4  \n",
       "146              Neutral               4  \n",
       "147              Neutral               4  \n",
       "148               Relief               3  \n",
       "\n",
       "[149 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take response output in json format, put into a dataframe, then assign numeric values \n",
    "# to the detected emotions.\n",
    "\n",
    "df = pd.DataFrame(analysis_results)\n",
    "\n",
    "conditions = [\n",
    "    df[\"emotion\"] == \"anger\",\n",
    "    df[\"emotion\"] == \"disgust\",\n",
    "    df[\"emotion\"] == \"fear\",\n",
    "    df[\"emotion\"] == \"joy\",\n",
    "    df[\"emotion\"] == \"neutral\",\n",
    "    df[\"emotion\"] == \"sadness\",\n",
    "    df[\"emotion\"] == \"surprise\"\n",
    "]\n",
    "values = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "df[\"emotion_numeric\"] = np.select(conditions, values, default=\"Unknown\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace9f254-3313-4cca-91f7-498d370569b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to csv\n",
    "\n",
    "df.to_csv(\"Results_ToponymsEmotions_GPT_Fre.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3374587-95bb-4e16-b5b5-2c3c5ba442e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      latitude   longitude emotion_value  proportion emotion_label  \\\n",
      "0     0.000000    0.000000             4         1.0       neutral   \n",
      "1    26.000000   30.000000             4         1.0       neutral   \n",
      "2    28.000000    3.000000             4         1.0       neutral   \n",
      "3    31.046051   34.851612             4         1.0       neutral   \n",
      "4    31.791700   -7.092600             4         1.0       neutral   \n",
      "..         ...         ...           ...         ...           ...   \n",
      "107  51.507400   -0.127800             4         1.0       neutral   \n",
      "108  52.355500   -1.174300             4         1.0       neutral   \n",
      "109  52.631709   22.063350             5         1.0       sadness   \n",
      "110  54.526000   15.255100             4         1.0       neutral   \n",
      "111  61.524010  105.318756             4         1.0       neutral   \n",
      "\n",
      "     average_confidence_score  \n",
      "0                        0.00  \n",
      "1                        0.00  \n",
      "2                        0.00  \n",
      "3                        0.00  \n",
      "4                        0.00  \n",
      "..                        ...  \n",
      "107                      0.60  \n",
      "108                      0.00  \n",
      "109                      0.94  \n",
      "110                      0.00  \n",
      "111                      0.00  \n",
      "\n",
      "[112 rows x 6 columns]\n",
      "      latitude  longitude emotion_value  proportion emotion_label  \\\n",
      "6    36.806500  10.181500             3         1.0           joy   \n",
      "9    42.700000   0.900000             4         1.0       neutral   \n",
      "10   43.232824   0.077718             4         1.0       neutral   \n",
      "11   43.276099  -0.799450             4         1.0       neutral   \n",
      "12   43.296482   5.369780             5         1.0       sadness   \n",
      "..         ...        ...           ...         ...           ...   \n",
      "100  50.016700  20.983300             4         1.0       neutral   \n",
      "103  50.629250   3.057256             4         1.0       neutral   \n",
      "105  51.219448   4.402464             4         1.0       neutral   \n",
      "107  51.507400  -0.127800             4         1.0       neutral   \n",
      "109  52.631709  22.063350             5         1.0       sadness   \n",
      "\n",
      "     average_confidence_score resolved_name  \n",
      "6                        0.87         Tunis  \n",
      "9                        0.71      Pyrénées  \n",
      "10                       0.79        Tarbes  \n",
      "11                       0.73          Gurs  \n",
      "12                       0.92     Marseille  \n",
      "..                        ...           ...  \n",
      "100                      0.50        Tarnow  \n",
      "103                      0.75         Lille  \n",
      "105                      0.95       Antwerp  \n",
      "107                      0.60        London  \n",
      "109                      0.94     Treblinka  \n",
      "\n",
      "[91 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# COUNT/PROPORTION of EMOTION SCORES of LOCATIONS:  Calculate the COUNT of each emotion detected at a \n",
    "# given set of coordinates then calculate the proportion at that location of each emotion...\n",
    "# The first line groups by the coordinates of the locations, and COUNTS the occurrences of emotion \n",
    "# scores (in the column \"emotion_numeric\"), then the \"normalize=True\" argument calculates and returns the \n",
    "# relative frequency of that score.  \n",
    "# The next line renames the column for \"emotion_numeric\" to \"emotion_value.\"\n",
    "# The next sequence of lines sets conditions to add the \"labels\" to the \"emotion_value\" scores.\n",
    "# The next 3 lines calculates the confidence scores for the detected emotions at each location, merges the\n",
    "# results with the normalized count dataframe and prints the results.\n",
    "# Then the next line exports results to a csv.\n",
    "\n",
    "df_count = df.groupby([\"latitude\", \"longitude\"], as_index=False)[\"emotion_numeric\"].value_counts(normalize=True)\n",
    "df_count = df_count.rename(columns={\"emotion_numeric\": \"emotion_value\"})\n",
    "conditions = [\n",
    "    df_count[\"emotion_value\"] == \"0\",\n",
    "    df_count[\"emotion_value\"] == \"1\",\n",
    "    df_count[\"emotion_value\"] == \"2\",\n",
    "    df_count[\"emotion_value\"] == \"3\",\n",
    "    df_count[\"emotion_value\"] == \"4\",\n",
    "    df_count[\"emotion_value\"] == \"5\",\n",
    "    df_count[\"emotion_value\"] == \"6\"\n",
    "]\n",
    "values = [\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "df_count[\"emotion_label\"] = np.select(conditions, values, default=\"Unknown\")\n",
    "df_confScore = df.groupby([\"latitude\", \"longitude\"], as_index=False)[\"confidence_score\"].mean()\n",
    "df_confScore = df_confScore.rename(columns={\"confidence_score\": \"average_confidence_score\"})\n",
    "df_count_conf = pd.merge(df_count, df_confScore, on=(\"latitude\", \"longitude\"), how=\"left\")\n",
    "print(df_count_conf)\n",
    "\n",
    "# To merge the above results with the names, in order to have labels on the coordinates...\n",
    "# Create subset of original dataframe with the toponyms and coordinates\n",
    "df_toponyms = df[[\"resolved_name\", \"latitude\", \"longitude\"]]\n",
    "# Delete rows with a value of zero in latitude and longitude (i.e. they were not resolved because GPT \n",
    "# did not think they were toponyms)\n",
    "df_toponyms = df_toponyms[~((df_toponyms['latitude'] == 0) & (df_toponyms['longitude'] == 0))]\n",
    "# Now, have to get reduce to one the toponyms at a set of coordinates, since, for example, in Le Chambon\n",
    "# there are multiple toponyms with the same coordinates (the village, L'Abric, College Cevenol, etc.). We\n",
    "# will do this by simply returning the column with the longest length.  Not ideal, but it works OK.\n",
    "# First, create a column for string length\n",
    "df_toponyms['Toponym_Length'] = df_toponyms['resolved_name'].str.len()\n",
    "# Then, sort dataframe in descending order based on the merge keys and the new length column.  \n",
    "# This ensures that the rows with the longest strings will appear first for each key. \n",
    "df_toponyms = df_toponyms.sort_values(by=[\"latitude\", \"longitude\", 'Toponym_Length'], ascending=[True, True, False])\n",
    "#  Use drop_duplicates() on the merge key column ('ID' in this case), keeping only the first occurrence \n",
    "# for each key. Since the DataFrame is sorted by length, this will effectively keep the row with the \n",
    "# longest string for each duplicate key\n",
    "df_toponyms = df_toponyms.drop_duplicates(subset=[\"latitude\", \"longitude\"], keep='first')\n",
    "# Drop the temporary length column:\n",
    "df_toponyms = df_toponyms.drop(columns=['Toponym_Length'])\n",
    "# Merge the dataframe with the proportional emotion detection results with the new one with the names, \n",
    "# merged on the coordinates, and with no duplicate names at any coordinates.\n",
    "df_count_conf_labeled = pd.merge(df_count_conf, df_toponyms, on=(\"latitude\", \"longitude\"), how=\"left\")\n",
    "# Delete rows with a value of zero in the average confidence score column, since these are (supposed to be) \n",
    "# only toponyms outside of France that no emotion analysis was run on and thus irrelevant.\n",
    "df_count_conf_labeled = df_count_conf_labeled[df_count_conf_labeled['average_confidence_score'] != 0]\n",
    "print(df_count_conf_labeled)\n",
    "df_count_conf_labeled.to_csv(\"Results_ToponymsEmotions_GPT_Proportion_Fre.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73695eb0-6a03-4df7-9a1f-a3619d912935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
