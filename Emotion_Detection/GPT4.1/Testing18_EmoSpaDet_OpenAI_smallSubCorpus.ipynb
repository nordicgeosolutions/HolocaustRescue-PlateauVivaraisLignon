{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380e7cc7-cb38-4a47-8e37-7b8b355478e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for CUDA and GPU, and if True, GPU will be used.\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f7f4a3-1fc2-4369-8a5f-332f586b582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in the sample dataset, the smaller sub-corpus.\n",
    "\n",
    "import os\n",
    "path = \"YOUR_DATA_test\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    # Reads all .txt files in a directory and returns a combined string of their contents.\n",
    "\n",
    "    file_contents = ''\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
    "                file_contents = file_contents + (f.read())\n",
    "    return file_contents\n",
    "\n",
    "texts = read_txt_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fd835e-6d0d-4678-ba55-67a494f4174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 13 chunks for extraction (token-char mapped).\n",
      "\n",
      "Initial extraction stage complete: Got 159 toponym instances (with possible duplicates).\n",
      "BAD INDEX: Le Chambon @ 11685-11695 | Extracted: ', because '\n",
      "BAD INDEX: Washington @ 11757-11767 | Extracted: 'many times'\n",
      "BAD INDEX: Chambon @ 11803-11810 | Extracted: 'lves. Y'\n",
      "BAD INDEX: Saint-Etienne @ 11849-11863 | Extracted: 'getting imposs'\n",
      "BAD INDEX: Le Chambon @ 12654-12664 | Extracted: ' people? W'\n",
      "BAD INDEX: Chambon-sur-Lignon @ 12795-12814 | Extracted: 'stor took a whole b'\n",
      "BAD INDEX: Haute-Loire @ 12822-12833 | Extracted: 'people, the'\n",
      "BAD INDEX: Chambon-sur-Lignon @ 12995-13014 | Extracted: \"ey \\ncame to us, it'\"\n",
      "BAD INDEX: Chambon @ 13126-13133 | Extracted: 'u somet'\n",
      "BAD INDEX: Maison des Roches @ 13175-13192 | Extracted: 'o \\ndefend them. W'\n",
      "BAD INDEX: Europe @ 13266-13272 | Extracted: \"it's g\"\n",
      "BAD INDEX: Spain @ 13275-13280 | Extracted: 'g to '\n",
      "BAD INDEX: Belgium @ 13282-13289 | Extracted: 've to a'\n",
      "BAD INDEX: Austria @ 13291-13298 | Extracted: ' so tha'\n",
      "BAD INDEX: Poland @ 13300-13306 | Extracted: 'each a'\n",
      "BAD INDEX: Russia @ 13308-13314 | Extracted: ' every'\n",
      "BAD INDEX: Drancy @ 13581-13587 | Extracted: 'ry tim'\n",
      "BAD INDEX: Chambon @ 13628-13635 | Extracted: ', I wou'\n",
      "BAD INDEX: Switzerland @ 13711-13723 | Extracted: ', documents '\n",
      "BAD INDEX: Le Chambon-sur-Lignon @ 3693-3714 | Extracted: \"on New Year's Eve, \\nt\"\n",
      "BAD INDEX: Les Grillons @ 3837-3849 | Extracted: 's. And I was'\n",
      "BAD INDEX: Le Chambon @ 4027-4037 | Extracted: ' And I was'\n",
      "BAD INDEX: France @ 4079-4085 | Extracted: 'ocme, '\n",
      "BAD INDEX: Massif Central @ 4121-4135 | Extracted: ' very \\nlong wa'\n",
      "BAD INDEX: France @ 4170-4176 | Extracted: 'y, I w'\n",
      "BAD INDEX: Le Chambon @ 4615-4625 | Extracted: 'n, whose n'\n",
      "BAD INDEX: College Cevenol @ 4767-4782 | Extracted: 'r, that Le Cham'\n",
      "BAD INDEX: Les Grillons @ 5016-5028 | Extracted: '. Agricultur'\n",
      "BAD INDEX: France @ 4579-4585 | Extracted: 'usin o'\n",
      "BAD INDEX: Britain @ 22990-22997 | Extracted: 'ree of '\n",
      "BAD INDEX: France @ 23056-23062 | Extracted: 'nd Jac'\n",
      "BAD INDEX: Le Chambon @ 23146-23156 | Extracted: ' brings br'\n",
      "BAD INDEX: La Guespy @ 23190-23200 | Extracted: 'rmers brin'\n",
      "BAD INDEX: La Guespy @ 23306-23316 | Extracted: 'one here i'\n",
      "BAD INDEX: Le Chambon-sur-Lignon @ 23505-23526 | Extracted: \"ing. We think they're\"\n",
      "BAD INDEX: France @ 23528-23534 | Extracted: 'sendin'\n",
      "BAD INDEX: Gurs @ 23576-23580 | Extracted: ' Fra'\n",
      "BAD INDEX: Germany @ 23710-23717 | Extracted: 'ews of '\n",
      "BAD INDEX: Poland @ 23721-23727 | Extracted: 'war. U'\n",
      "BAD INDEX: Gurs @ 23779-23783 | Extracted: 'n in'\n",
      "BAD INDEX: Le Chambon-sur-Lignon @ 23945-23966 | Extracted: ' to see everyone agai'\n",
      "BAD INDEX: France @ 23968-23974 | Extracted: ' excep'\n",
      "BAD INDEX: Le Chambon @ 24049-24059 | Extracted: 'e, and she'\n",
      "BAD INDEX: La Guespy @ 24111-24121 | Extracted: 'ambon-sur-'\n",
      "BAD INDEX: Le Chambon-sur-Lignon @ 24239-24260 | Extracted: ' to go there to visit'\n",
      "BAD INDEX: France @ 24262-24268 | Extracted: 'er mot'\n",
      "BAD INDEX: Le Puy @ 24483-24489 | Extracted: 'o came'\n",
      "BAD INDEX: LePuy-en-Velay @ 24585-24599 | Extracted: 'for an hour \\nt'\n",
      "BAD INDEX: France @ 24601-24607 | Extracted: 't morn'\n",
      "BAD INDEX: LePuy-en-Velay @ 26170-26184 | Extracted: ' 1943, LePuy-e'\n",
      "BAD INDEX: France @ 26186-26192 | Extracted: 'Velay,'\n",
      "BAD INDEX: Le Chambon-sur-Lignon @ 26270-26292 | Extracted: 'y lucky. For some \\nrea'\n",
      "BAD INDEX: France @ 26294-26300 | Extracted: 'n, the'\n",
      "BAD INDEX: Le Chambon @ 26376-26387 | Extracted: ' March 1943'\n",
      "BAD INDEX: Algiers @ 26533-26540 | Extracted: \"I'm on \"\n",
      "BAD INDEX: France @ 26570-26576 | Extracted: 'my. Th'\n",
      "BAD INDEX: Algiers @ 26610-26617 | Extracted: 'ss Mart'\n",
      "BAD INDEX: Switzerland @ 26659-26670 | Extracted: 'ork in the '\n",
      "BAD INDEX: Switzerland @ 26707-26718 | Extracted: 'ut. The peo'\n",
      "BAD INDEX: Alsace-Lorraine @ 26830-26845 | Extracted: 'lip. I love her'\n",
      "BAD INDEX: Switzerland @ 26911-26922 | Extracted: ' husband is'\n",
      "BAD INDEX: France @ 26948-26954 | Extracted: ' de Ga'\n",
      "BAD INDEX: Annecy @ 27090-27096 | Extracted: 'o join'\n",
      "BAD INDEX: Le Chambon @ 27151-27162 | Extracted: 'e going to '\n",
      "BAD INDEX: Switzerland @ 27167-27178 | Extracted: 'erland!\" \\nS'\n",
      "BAD INDEX: Le Chambon @ 27266-27277 | Extracted: 'e Philip \\ns'\n",
      "BAD INDEX: Valence @ 27347-27354 | Extracted: 'e stamp'\n",
      "BAD INDEX: Valence @ 27412-27419 | Extracted: 's dinin'\n",
      "BAD INDEX: Annecy @ 27516-27522 | Extracted: 'tifica'\n",
      "BAD INDEX: Switzerland @ 27541-27552 | Extracted: 'the picture'\n",
      "BAD INDEX: France @ 27646-27652 | Extracted: 'on my '\n",
      "BAD INDEX: Le Chambon @ 27719-27730 | Extracted: 'e is Jacque'\n",
      "BAD INDEX: Camp de Gurs @ 27819-27831 | Extracted: 'he German bo'\n",
      "BAD INDEX: Toulouse @ 30428-30436 | Extracted: ' togethe'\n",
      "BAD INDEX: Le Chambon-sur Lignon @ 30531-30551 | Extracted: 'r children, help for'\n",
      "BAD INDEX: Massif Central @ 30724-30737 | Extracted: '\\nSo now we, i'\n",
      "BAD INDEX: Vichy @ 30806-30811 | Extracted: 'hey, '\n",
      "BAD INDEX: Vichy @ 30830-30835 | Extracted: 'gethe'\n",
      "BAD INDEX: France @ 30837-30843 | Extracted: ' and w'\n",
      "BAD INDEX: Camp de Gurs @ 31088-31100 | Extracted: 'went \\nto the'\n",
      "BAD INDEX: Lyon @ 31454-31458 | Extracted: 'ere.'\n",
      "BAD INDEX: England @ 31468-31475 | Extracted: 'me get '\n",
      "BAD INDEX: England @ 31486-31493 | Extracted: '\\nthe gr'\n",
      "BAD INDEX: Algiers @ 31497-31504 | Extracted: '. So I '\n",
      "BAD INDEX: Vichy @ 18967-18972 | Extracted: 'he sp'\n",
      "BAD INDEX: Chambon-sur-Lignon @ 19111-19130 | Extracted: 'om the minister of '\n",
      "BAD INDEX: Chambon-sur-Lignon @ 19192-19211 | Extracted: 'foreign workers leg'\n",
      "BAD INDEX: France @ 19330-19336 | Extracted: 'nkets.'\n",
      "BAD INDEX: France @ 19469-19475 | Extracted: 'ours a'\n",
      "BAD INDEX: Le Chambon-sur-Lignon @ 19511-19532 | Extracted: 'rents if they wanted '\n",
      "BAD INDEX: France @ 19534-19540 | Extracted: ' send '\n",
      "BAD INDEX: Le Chambon-sur-Lignon @ 19556-19577 | Extracted: 'somewhere in France w'\n",
      "BAD INDEX: Gurs @ 19631-19635 | Extracted: ' by '\n",
      "BAD INDEX: La Guespy @ 19656-19665 | Extracted: 'n. She sa'\n",
      "BAD INDEX: Le Chambon @ 19801-19811 | Extracted: 't will rea'\n",
      "BAD INDEX: La Guespy @ 19873-19882 | Extracted: ' France \\n'\n",
      "BAD INDEX: France @ 20071-20077 | Extracted: ' them '\n",
      "BAD INDEX: Le Chambon-sur-Lignon @ 20093-20114 | Extracted: 'becoming friends now.'\n",
      "BAD INDEX: France @ 20116-20122 | Extracted: \"'m gla\"\n",
      "BAD INDEX: the plateau @ 20711-20722 | Extracted: 'ch! None of'\n",
      "BAD INDEX: Haute-Loire @ 120-131 | Extracted: 'g whether s'\n",
      "BAD INDEX: La Rouvière @ 187-199 | Extracted: 'n Haute-Loir'\n",
      "BAD INDEX: Les Caillols @ 258-270 | Extracted: '\\nand another'\n",
      "BAD INDEX: Les Caillols @ 410-422 | Extracted: 'ère today.I '\n",
      "BAD INDEX: Les Grillons @ 445-457 | Extracted: ' with tears.'\n",
      "BAD INDEX: Marseilles @ 604-614 | Extracted: '[Les Caill'\n",
      "BAD INDEX: France @ 704-710 | Extracted: ' if he'\n",
      "BAD INDEX: Le Chambon sur Lignon @ 749-770 | Extracted: 'place. I had \\nasked h'\n",
      "BAD INDEX: Marseilles @ 847-857 | Extracted: '\\nFullenbau'\n",
      "BAD INDEX: Paris @ 861-866 | Extracted: 'ho  l'\n",
      "BAD INDEX: Lavoulte bridge @ 916-931 | Extracted: 'es  at  Les \\nGr'\n",
      "BAD INDEX: Cheylard @ 958-966 | Extracted: ' hope th'\n",
      "BAD INDEX: St. Agrève @ 981-992 | Extracted: ' to go ther'\n",
      "BAD INDEX: St. Agrève @ 1010-1021 | Extracted: 'is fit for '\n",
      "BAD INDEX: Les Grillons @ 1139-1151 | Extracted: ' 1943 \\nWe we'\n",
      "BAD INDEX: Marseilles @ 1431-1441 | Extracted: 'be able to'\n",
      "BAD INDEX: Gurs @ 1621-1625 | Extracted: 'n] \\n'\n",
      "BAD INDEX: Vichy @ 1647-1652 | Extracted: ' firs'\n",
      "BAD INDEX: Lyon @ 33364-33368 | Extracted: 'yon,'\n",
      "BAD INDEX: England @ 33384-33391 | Extracted: 'land, a'\n",
      "BAD INDEX: England @ 33402-33409 | Extracted: 'land \\nt'\n",
      "BAD INDEX: Algiers @ 33414-33421 | Extracted: 'iers.  '\n",
      "BAD INDEX: University of Lyon @ 33485-33503 | Extracted: 'e a mother to me. '\n",
      "BAD INDEX: France @ 33585-33591 | Extracted: ' was a'\n",
      "BAD INDEX: Camp de Gurs @ 33691-33703 | Extracted: 'ariot with \\n'\n",
      "BAD INDEX: New York @ 33862-33870 | Extracted: 'st at th'\n",
      "BAD INDEX: Le Chambon @ 33940-33950 | Extracted: 'tatoes off'\n",
      "BAD INDEX: Gurs @ 33987-33991 | Extracted: 'il. '\n",
      "BAD INDEX: Vichy @ 34074-34079 | Extracted: 'ed th'\n",
      "BAD INDEX: Vichy @ 34140-34145 | Extracted: 'f Cam'\n",
      "BAD INDEX: Le Chambon @ 34250-34260 | Extracted: '\\nstring be'\n",
      "BAD INDEX: France @ 34406-34412 | Extracted: ' was i'\n",
      "BAD INDEX: Drancy @ 15033-15039 | Extracted: 'ither '\n",
      "BAD INDEX: Chambon @ 15070-15077 | Extracted: 'were af'\n",
      "BAD INDEX: Switzerland @ 15138-15149 | Extracted: 'then, and m'\n",
      "BAD INDEX: Switzerland @ 15205-15216 | Extracted: 'iary, and t'\n",
      "BAD INDEX: France @ 15220-15226 | Extracted: 'onsequ'\n",
      "BAD INDEX: France @ 15350-15356 | Extracted: 'fficia'\n",
      "BAD INDEX: France @ 15415-15421 | Extracted: ', in I'\n",
      "BAD INDEX: Vallorcine @ 15558-15568 | Extracted: 'en for a w'\n",
      "BAD INDEX: Vallorcine @ 15570-15580 | Extracted: 'le in \\nCha'\n",
      "BAD INDEX: Rivesaltes @ 15624-15634 | Extracted: ' farmers, '\n",
      "BAD INDEX: Chambon-sur-Lignon @ 15689-15708 | Extracted: 'been summer, becaus'\n",
      "BAD INDEX: Rivesaltes @ 15722-15732 | Extracted: 'r \\nresiden'\n",
      "BAD INDEX: Rivesaltes @ 15852-15862 | Extracted: 'he looked '\n",
      "BAD INDEX: France @ 15883-15889 | Extracted: 'me ove'\n",
      "BAD INDEX: Chambon-sur-Lignon @ 15922-15941 | Extracted: ' And we showed him '\n",
      "BAD INDEX: Chambon-sur-Lignon @ 15996-16015 | Extracted: 'hone call. And he m'\n",
      "BAD INDEX: Chambon-sur-Lignon @ 16093-16112 | Extracted: 'urn right away to F'\n",
      "BAD INDEX: Chambon-sur-Lignon @ 16198-16217 | Extracted: 'let you into France'\n",
      "BAD INDEX: Perpignan @ 16342-16351 | Extracted: 'y \\nFrench'\n",
      "BAD INDEX: Chambon @ 16397-16404 | Extracted: 'iendly.'\n",
      "BAD INDEX: Le Chambon @ 16505-16515 | Extracted: 'ertain amo'\n",
      "BAD INDEX: Chambon @ 16526-16533 | Extracted: ' import'\n",
      "BAD INDEX: France @ 16632-16638 | Extracted: ' broug'\n",
      "BAD INDEX: Swiss @ 16661-16666 | Extracted: 'tatio'\n",
      "BAD INDEX: Swiss @ 16777-16782 | Extracted: 'were '\n",
      "BAD INDEX: Swiss @ 16857-16862 | Extracted: 't the'\n",
      "BAD INDEX: Chambon-sur-Lignon @ 16962-16981 | Extracted: 'y Strong came. And '\n",
      "After validation + deduplication: 0 valid, unique entries.\n",
      "\n",
      "Stage 2 complete: Produced 0 final, validated toponym analyses.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Developing function to identify and resolve toponyms, and detect emotions in context \n",
    "on either side of each toponym.  Context length is based on trying different lengths,\n",
    "with the final context length chosen based on which gives the most likely detected emotion\n",
    "with the highest confidence score.\n",
    "\n",
    "\"\"\"\n",
    "# Access libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import tiktoken\n",
    "import difflib # <-- for similarity\n",
    "\n",
    "\n",
    "# Set a global variable for my OpenAI API key so that the model can be accessed.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_KEY\"\n",
    "client = OpenAI()\n",
    "\n",
    "# Alternative data for testing:\n",
    "#texts = \"I traveled from Paris to Berlin and saw New York on the way.  It was fantastic.  I was so happy.\"\n",
    "\n",
    "# ========== Robust OpenAI Output Extraction ==========\n",
    "def extract_json_from_arguments(response):\n",
    "    \"\"\"\n",
    "    Robust extraction for OpenAI responses.\n",
    "    Handles both function call and text output scenarios.\n",
    "    Returns dict or list or [].\n",
    "    \"\"\"\n",
    "    # Case 1: Function call pattern\n",
    "    if hasattr(response, \"output\") and response.output:\n",
    "        first = response.output[0]\n",
    "        if hasattr(first, \"arguments\"): # should be a string\n",
    "            arguments_string = first.arguments\n",
    "            if isinstance(arguments_string, (str, bytes)):\n",
    "                try:\n",
    "                    return json.loads(arguments_string)\n",
    "                except Exception as e:\n",
    "                    print(f\"JSON parsing error: {e}\\nARGUMENTS STRING: {arguments_string}\")\n",
    "                    return []\n",
    "            else:\n",
    "                # If already parsed (rare)\n",
    "                return arguments_string\n",
    "        # If it's classic text response\n",
    "        if hasattr(first, \"content\") and first.content:\n",
    "            text_fragment = getattr(first.content[0], \"text\", None)\n",
    "            if text_fragment:\n",
    "                try:\n",
    "                    return json.loads(text_fragment)\n",
    "                except Exception as e:\n",
    "                    print(f\"JSON parsing error (text): {e}\\nTEXT: {text_fragment}\")\n",
    "                    return []\n",
    "    # Case 2: Tool-style .outputs (not present in your current responses)\n",
    "    if hasattr(response, \"outputs\") and response.outputs and hasattr(response.outputs[0], \"arguments\"):\n",
    "        arguments = response.outputs[0].arguments\n",
    "        if arguments is not None:\n",
    "            return arguments\n",
    "    print(\"No recognizable output format found in OpenAI response.\")\n",
    "    return []\n",
    "\n",
    "# 2. Token_to_Character-based Chunking (if needed).\n",
    "# For iteration 13 and following, reduced tokens to 1000 and overlap to 50 to try to improve performance and reduce duplicates.\n",
    "\n",
    "def compute_token_to_char(text, encoding):\n",
    "    all_tokens = encoding.encode(text)\n",
    "    token_to_char = []\n",
    "    curr_char = 0\n",
    "    for tok in all_tokens:\n",
    "        piece = encoding.decode([tok])\n",
    "        token_to_char.append(curr_char)\n",
    "        curr_char += len(piece)\n",
    "    return all_tokens, token_to_char\n",
    "    \n",
    "def chunk_text_by_tokens_precise(text, max_tokens=1000, overlap_tokens=50):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    all_tokens, token_to_char = compute_token_to_char(text, enc)\n",
    "    n = len(all_tokens)\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        start_token = i\n",
    "        end_token = min(i + max_tokens, n)\n",
    "        start_char = token_to_char[start_token]\n",
    "        end_char = token_to_char[end_token] if end_token < len(all_tokens) else len(text)\n",
    "        chunk_text = text[start_char:end_char]\n",
    "        chunks.append((chunk_text, start_char, end_char, start_token, end_token))\n",
    "        if end_token == n:\n",
    "            break\n",
    "        i += max_tokens - overlap_tokens\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# 3. API Call with Retry for Thread Use\n",
    "\n",
    "def call_api_with_retry_chunk(chunk, offset, extraction_instructions, client, max_output_tokens=2048, retries=4):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4.1-2025-04-14\",\n",
    "                instructions=extraction_instructions,\n",
    "                input=chunk,\n",
    "                text={\"format\": {\"type\": \"text\"}},\n",
    "                reasoning={},\n",
    "                tools=[\n",
    "                    {\n",
    "                        \"type\": \"function\",\n",
    "                        \"name\": \"recognize_toponyms\",\n",
    "                        \"description\": \"Given the user input text, identify all the toponyms in the text.\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"required\": [\"input_text\", \"toponyms\"],\n",
    "                            \"properties\": {\n",
    "                                \"input_text\": {\"type\": \"string\", \"description\": \"The text string from which to recognize and identify toponyms.\"},\n",
    "                                \"toponyms\": {\n",
    "                                    \"type\": \"array\",\n",
    "                \t\t\t\t    \"description\": \"Array of recognized and identified toponyms.\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"toponym\": {\"type\": \"string\"},\n",
    "                                            \"start_idx\": {\"type\": \"integer\"},\n",
    "                                            \"end_idx\": {\"type\": \"integer\"},\n",
    "                                        },\n",
    "                                        \"required\": [\"toponym\", \"start_idx\", \"end_idx\"],\n",
    "                                        \"additionalProperties\": False\n",
    "                                    }\n",
    "                                }\n",
    "                            },\n",
    "                            \"additionalProperties\": False\n",
    "                        },\n",
    "                        \"strict\": True\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0.25,\n",
    "                tool_choice=\"required\",\n",
    "                max_output_tokens=max_output_tokens,\n",
    "                top_p=1,\n",
    "                store=True\n",
    "            )\n",
    "            return extract_json_from_arguments(response), offset\n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"[API] Error: {e}\\nRetrying in {wait}s (chunk at char {offset})...\")\n",
    "            time.sleep(wait)\n",
    "    print(f\"[API] Failed after retries for chunk at {offset}\")\n",
    "    return [], offset\n",
    "\n",
    "# 4. Stage 1: Parallel Toponym Extraction\n",
    "\n",
    "# ====== Load Extraction Prompt ======\n",
    "with open(\"openai_ToponymExtraction_prompt_complicated_18.txt\", encoding=\"utf-8\") as f:\n",
    "    extraction_instructions = f.read()\n",
    "\n",
    "# ====== Chunk Input ======\n",
    "    # chunk via token-to-char mapping \n",
    "# As noted above, for this iteration reduced chunk size to 1000 and overlap to 50\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "input_tokens = len(enc.encode(texts))\n",
    "# chunk ALWAYS with token/char mapping, never with .find()!\n",
    "chunks = chunk_text_by_tokens_precise(texts, max_tokens=1000, overlap_tokens=50)\n",
    "print(f\"Text split into {len(chunks)} chunks for extraction (token-char mapped).\")\n",
    "\n",
    "\n",
    "# ====== Run Extraction in Parallel ======\n",
    "max_workers = 20   # safe for modern high-tier; can adjust up/down\n",
    "extracted_toponyms = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            call_api_with_retry_chunk, chunk, start_char, extraction_instructions, client\n",
    "        )\n",
    "        for chunk, start_char, end_char, start_token, end_token in chunks\n",
    "    ]\n",
    "    for f in as_completed(futures):\n",
    "        toponyms_chunk, offset = f.result()\n",
    "        # Normalize returned indices to global!\n",
    "        if isinstance(toponyms_chunk, list):\n",
    "            for t in toponyms_chunk:\n",
    "                t[\"start_idx\"] += offset\n",
    "                t[\"end_idx\"] += offset\n",
    "            extracted_toponyms += toponyms_chunk\n",
    "        elif isinstance(toponyms_chunk, dict) and \"toponyms\" in toponyms_chunk:\n",
    "            for t in toponyms_chunk[\"toponyms\"]:\n",
    "                t[\"start_idx\"] += offset\n",
    "                t[\"end_idx\"] += offset\n",
    "            extracted_toponyms += toponyms_chunk[\"toponyms\"]\n",
    "\n",
    "print(f\"\\nInitial extraction stage complete: Got {len(extracted_toponyms)} toponym instances (with possible duplicates).\")\n",
    "\n",
    "# ------STRICT INDEX/SUBSTR VALIDATION & DEDUPLICATION STEP -------\n",
    "    # nearby, identical name (window adjustable)\n",
    "def validate_and_deduplicate_toponyms(toponym_list, texts, window=40):\n",
    "    # Filter for exact matches\n",
    "    validated = []\n",
    "    for t in toponym_list:\n",
    "        s, e = t['start_idx'], t['end_idx']\n",
    "        extract = texts[s:e]\n",
    "        # Only accept if exact match:\n",
    "        if extract.strip().lower() == t['toponym'].strip().lower():\n",
    "            validated.append(t)\n",
    "        else:\n",
    "            print(f\"BAD INDEX: {t['toponym']} @ {s}-{e} | Extracted: {repr(extract)}\")\n",
    "    # Dedupe: same toponym, overlapping window\n",
    "    deduped = []\n",
    "    for t in validated:\n",
    "        found = False\n",
    "        for other in deduped:\n",
    "            # If same spot (or in window) and same toponym string, skip\n",
    "            if t['toponym'].strip().lower() == other['toponym'].strip().lower() and abs(t['start_idx'] - other['start_idx']) < window:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            deduped.append(t)\n",
    "    return deduped\n",
    "\n",
    "final_toponyms = validate_and_deduplicate_toponyms(extracted_toponyms, texts)\n",
    "print(f\"After validation + deduplication: {len(final_toponyms)} valid, unique entries.\")\n",
    "\n",
    "# ------------------ END DEDUPLICATION STEP --------------------\n",
    "\n",
    "with open(\"extracted_toponyms.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_toponyms, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 5. Stage 2: Parallel Toponym Analysis\n",
    "\n",
    "# ====== Load Analysis Prompt ======\n",
    "with open(\"openai_ToponymEmotionAnalysis_prompt_complicated_18.txt\", encoding=\"utf-8\") as f:\n",
    "    analysis_instructions = f.read()\n",
    "\n",
    "# Load validated output (from Stage 1)\n",
    "with open(\"extracted_toponyms.json\", encoding=\"utf-8\") as f:\n",
    "    extracted_toponyms = json.load(f)\n",
    "\n",
    "def call_api_with_retry_analysis(\n",
    "    toponym_obj,\n",
    "    texts,\n",
    "    client,\n",
    "    analysis_instructions,\n",
    "    max_output_tokens=2048,\n",
    "    retries=4,\n",
    "):\n",
    "    toponym_str = toponym_obj[\"toponym\"]\n",
    "    # Use global indices, slice context\n",
    "    s, e = toponym_obj[\"start_idx\"], toponym_obj[\"end_idx\"]\n",
    "    # Define largest window (use LLM to narrow as needed)\n",
    "    pre = 300\n",
    "    post = 300\n",
    "    text_len = len(texts)\n",
    "    start = max(0, s - pre)\n",
    "    end = min(text_len, e + post)\n",
    "    context = texts[start:end]\n",
    "    \n",
    "    user_input = {\n",
    "        \"original_text\": context,\n",
    "        \"toponym_instances\": [{\n",
    "            \"toponym\": toponym_str,\n",
    "            \"original_range\": [s, e]\n",
    "        }]\n",
    "    }\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4.1-2025-04-14\",\n",
    "                instructions=analysis_instructions,\n",
    "                input=json.dumps(user_input),\n",
    "                text={\"format\": {\"type\": \"text\"}},\n",
    "                reasoning={},\n",
    "                tools=[{\n",
    "                    \"type\": \"function\",\n",
    "                    \"name\": \"resolve_toponyms_and_detect_emotions\",\n",
    "                    \"description\": (\n",
    "                        \"Given the user input of the original text and extracted toponyms, \"\n",
    "                        \"determine latitude and longitude of each toponym and perform emotion detection. \"\n",
    "                        \"Try multiple possible context window sizes (~different context lengths) for each toponym and \"\n",
    "                        \"return the window (context) that maximizes the confidence score for the most likely detected emotion.\"\n",
    "                    ),\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"required\": [\"original_text\", \"toponym_instances\"],\n",
    "                        \"properties\": {\n",
    "                            \"original_text\": {\"type\": \"string\", \"description\": \"The text string from which to disambiguate toponyms and utilize their surrounding context.\"},\n",
    "                            \"toponym_instances\": {\n",
    "                                \"type\": \"array\",\n",
    "                \t\t\t\t\"description\": \"Array of identified toponyms, each containing properties of location details and emotional context.\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"required\": [\n",
    "                                        \"toponym\", \"resolved_name\", \"latitude\",\n",
    "                                        \"longitude\", \"emotion\", \"confidence_score\",\n",
    "                                        \"context\", \"context_length\", \"original_range\"\n",
    "                                    ],\n",
    "                                    \"properties\": {\n",
    "                                        \"toponym\": {\"type\": \"string\", \"description\": \"The name of the toponym as found in the previous step.\"},\n",
    "                                        \"resolved_name\": {\"type\": \"string\", \"description\": \"The name of the resolved toponym as identified and disambiguated.\"},\n",
    "                                        \"latitude\": {\"type\": \"number\", \"description\": \"The latitude coordinate of the toponym.\"},\n",
    "                                        \"longitude\": {\"type\": \"number\", \"description\": \"The longitude coordinate of the toponym.\"},\n",
    "                                        \"emotion\": {\"type\": \"string\", \"description\": \"The most likely detected emotion around the toponym.\", \"enum\": [\n",
    "                                            \"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"\n",
    "                                        ]},\n",
    "                                        \"confidence_score\": {\"type\": \"number\", \"description\": \"The confidence score for the detected emotion, on a scale of 0 to 1.\"},\n",
    "                                        \"context\": {\"type\": \"string\", \"description\": \"The text block surrounding the toponym used for emotion detection, whose length is determined based on trying different lengths and seeing which one gives the highest confidence score for the most likely detected emotion.\"},\n",
    "                                        \"context_length\": {\"type\": \"number\", \"description\": \"The length, in characters including spaces, of the final text block surrounding the toponym used for emotion detection.\"},\n",
    "                                        \"original_range\": {\"type\": \"array\", \"description\": \"The original start and end position in the text of the toponym.\", \"items\": {\"type\": \"number\"}}\n",
    "                                    },\n",
    "                                    \"additionalProperties\": False,\n",
    "                                },\n",
    "                            }\n",
    "                        },\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                    \"strict\": True\n",
    "                }],\n",
    "                temperature=1,\n",
    "                tool_choice=\"required\",\n",
    "                max_output_tokens=max_output_tokens,\n",
    "                top_p=1,\n",
    "                store=True\n",
    "            )\n",
    "            return extract_json_from_arguments(response), toponym_str\n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"[API] Analysis error for '{toponym_str}': {e}\\nRetrying in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "    print(f\"[API] Analysis failed after retries for '{toponym_str}'.\")\n",
    "    return {\"toponym\": toponym_str, \"error\": \"Failed after retries\"}, toponym_str\n",
    "\n",
    "# Define function to validate results for Stage 2\n",
    "def validate_analysis_results(results, texts):\n",
    "    # For every output dict, compare the context string and indices (if present)\n",
    "    valid = []\n",
    "    for entry in results:\n",
    "        if \"context\" in entry and \"toponym\" in entry and \"original_range\" in entry:\n",
    "            s, e = entry[\"original_range\"]\n",
    "            text_snip = texts[s:e]\n",
    "            if text_snip.strip().lower() == entry[\"toponym\"].strip().lower():\n",
    "                valid.append(entry)\n",
    "            else:\n",
    "                print(f\"Mismatch after phase 2: {entry['toponym']} @ {s}-{e} | Extracted: {repr(text_snip)}\")\n",
    "        else:\n",
    "            valid.append(entry)\n",
    "    return valid\n",
    "\n",
    "# Run Stage 2 in Parallel\n",
    "\n",
    "analysis_results = []\n",
    "max_workers_analysis = 20  # You can go higher if needed\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers_analysis) as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            call_api_with_retry_analysis, t, texts, client, analysis_instructions, 2048\n",
    "        )\n",
    "        for t in extracted_toponyms\n",
    "    ]\n",
    "    for f in as_completed(futures):\n",
    "        batch_result = f.result()\n",
    "        # Each batch_result should be a list of result dicts\n",
    "        if isinstance(batch_result, list):\n",
    "            analysis_results += batch_result\n",
    "        elif isinstance(batch_result, dict):\n",
    "            analysis_results.append(batch_result)\n",
    "        # else: ignore/print\n",
    "\n",
    "# Validate indices and context after analysis, so they always match\n",
    "final_results = validate_analysis_results(analysis_results, texts)\n",
    "\n",
    "with open(\"analysis_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_results, f, ensure_ascii=False, indent=2)\n",
    "print(f\"\\nStage 2 complete: Produced {len(final_results)} final, validated toponym analyses.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d90d8a-b1f8-4507-84aa-0389fe053388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toponym</th>\n",
       "      <th>resolved_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>emotion</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>original_range</th>\n",
       "      <th>emotion_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drancy</td>\n",
       "      <td>Drancy</td>\n",
       "      <td>48.925278</td>\n",
       "      <td>2.445556</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.98</td>\n",
       "      <td>because already in July the French started col...</td>\n",
       "      <td>393</td>\n",
       "      <td>[37547, 37553]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>46.603354</td>\n",
       "      <td>1.888334</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.76</td>\n",
       "      <td>When I returned from Marseilles at noon, Mrs. ...</td>\n",
       "      <td>427</td>\n",
       "      <td>[19261, 19267]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>College Cevenol</td>\n",
       "      <td>Collège Cévenol</td>\n",
       "      <td>45.063200</td>\n",
       "      <td>4.302300</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.77</td>\n",
       "      <td>I was sent to school, to a school that they ha...</td>\n",
       "      <td>287</td>\n",
       "      <td>[4777, 4792]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vichy</td>\n",
       "      <td>Vichy</td>\n",
       "      <td>46.126400</td>\n",
       "      <td>3.426500</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.85</td>\n",
       "      <td>His father [is] in [the French internment camp...</td>\n",
       "      <td>184</td>\n",
       "      <td>[18956, 18961]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Les Grillons</td>\n",
       "      <td>Les Grillons, guesthouse near Le Chambon-sur-L...</td>\n",
       "      <td>45.065000</td>\n",
       "      <td>4.317000</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.91</td>\n",
       "      <td>Mr. Trocmé came on his bicycle to meet me (sti...</td>\n",
       "      <td>501</td>\n",
       "      <td>[3897, 3909]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>61.524010</td>\n",
       "      <td>105.318756</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.66</td>\n",
       "      <td>was the home for students from all \\ncountries...</td>\n",
       "      <td>359</td>\n",
       "      <td>[228, 234]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Drancy</td>\n",
       "      <td>Drancy</td>\n",
       "      <td>48.925799</td>\n",
       "      <td>2.445120</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.97</td>\n",
       "      <td>This idyll didn't last too long, because alrea...</td>\n",
       "      <td>278</td>\n",
       "      <td>[13393, 13399]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Chambon-sur-Lignon</td>\n",
       "      <td>Le Chambon-sur-Lignon</td>\n",
       "      <td>45.060810</td>\n",
       "      <td>4.302941</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.93</td>\n",
       "      <td>And on New Year's Eve, \\nthey explained to me ...</td>\n",
       "      <td>535</td>\n",
       "      <td>[12836, 12855]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.463667</td>\n",
       "      <td>-3.749220</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.67</td>\n",
       "      <td>which was the home for students from all \\ncou...</td>\n",
       "      <td>307</td>\n",
       "      <td>[13110, 13115]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Le Chambon</td>\n",
       "      <td>Le Chambon-sur-Lignon</td>\n",
       "      <td>45.060810</td>\n",
       "      <td>4.302941</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td>od there is fit for \\nkings (butter, potatoes,...</td>\n",
       "      <td>1074</td>\n",
       "      <td>[1001, 2211]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                toponym                                      resolved_name  \\\n",
       "0                Drancy                                             Drancy   \n",
       "1                France                                             France   \n",
       "2       College Cevenol                                    Collège Cévenol   \n",
       "3                 Vichy                                              Vichy   \n",
       "4          Les Grillons  Les Grillons, guesthouse near Le Chambon-sur-L...   \n",
       "..                  ...                                                ...   \n",
       "124              Russia                                             Russia   \n",
       "125              Drancy                                             Drancy   \n",
       "126  Chambon-sur-Lignon                              Le Chambon-sur-Lignon   \n",
       "127               Spain                                              Spain   \n",
       "128          Le Chambon                              Le Chambon-sur-Lignon   \n",
       "\n",
       "      latitude   longitude  emotion  confidence_score  \\\n",
       "0    48.925278    2.445556     fear              0.98   \n",
       "1    46.603354    1.888334  neutral              0.76   \n",
       "2    45.063200    4.302300  neutral              0.77   \n",
       "3    46.126400    3.426500      joy              0.85   \n",
       "4    45.065000    4.317000      joy              0.91   \n",
       "..         ...         ...      ...               ...   \n",
       "124  61.524010  105.318756  neutral              0.66   \n",
       "125  48.925799    2.445120     fear              0.97   \n",
       "126  45.060810    4.302941     fear              0.93   \n",
       "127  40.463667   -3.749220  neutral              0.67   \n",
       "128  45.060810    4.302941  neutral              0.00   \n",
       "\n",
       "                                               context  context_length  \\\n",
       "0    because already in July the French started col...             393   \n",
       "1    When I returned from Marseilles at noon, Mrs. ...             427   \n",
       "2    I was sent to school, to a school that they ha...             287   \n",
       "3    His father [is] in [the French internment camp...             184   \n",
       "4    Mr. Trocmé came on his bicycle to meet me (sti...             501   \n",
       "..                                                 ...             ...   \n",
       "124  was the home for students from all \\ncountries...             359   \n",
       "125  This idyll didn't last too long, because alrea...             278   \n",
       "126  And on New Year's Eve, \\nthey explained to me ...             535   \n",
       "127  which was the home for students from all \\ncou...             307   \n",
       "128  od there is fit for \\nkings (butter, potatoes,...            1074   \n",
       "\n",
       "     original_range emotion_numeric  \n",
       "0    [37547, 37553]               2  \n",
       "1    [19261, 19267]               4  \n",
       "2      [4777, 4792]               4  \n",
       "3    [18956, 18961]               3  \n",
       "4      [3897, 3909]               3  \n",
       "..              ...             ...  \n",
       "124      [228, 234]               4  \n",
       "125  [13393, 13399]               2  \n",
       "126  [12836, 12855]               2  \n",
       "127  [13110, 13115]               4  \n",
       "128    [1001, 2211]               4  \n",
       "\n",
       "[129 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take response output in json format, put into a dataframe, then assign numeric values \n",
    "# to the detected emotions.\n",
    "\n",
    "df = pd.DataFrame(analysis_results)\n",
    "\n",
    "conditions = [\n",
    "    df[\"emotion\"] == \"anger\",\n",
    "    df[\"emotion\"] == \"disgust\",\n",
    "    df[\"emotion\"] == \"fear\",\n",
    "    df[\"emotion\"] == \"joy\",\n",
    "    df[\"emotion\"] == \"neutral\",\n",
    "    df[\"emotion\"] == \"sadness\",\n",
    "    df[\"emotion\"] == \"surprise\"\n",
    "]\n",
    "values = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "df[\"emotion_numeric\"] = np.select(conditions, values, default=\"Unknown\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2222fa53-54b9-49a9-8fec-2d18892200cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to csv\n",
    "\n",
    "df.to_csv(\"Results18_ToponymsEmotions_smallSubCorpus.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f13006-7409-41d6-b74e-4a80e4ff5414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
