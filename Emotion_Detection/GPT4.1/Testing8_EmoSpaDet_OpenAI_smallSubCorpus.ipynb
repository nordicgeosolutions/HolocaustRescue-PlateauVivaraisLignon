{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380e7cc7-cb38-4a47-8e37-7b8b355478e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for CUDA and GPU, and if True, GPU will be used.\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f7f4a3-1fc2-4369-8a5f-332f586b582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in the sample dataset, the smaller sub-corpus.\n",
    "\n",
    "import os\n",
    "path = \"YOUR_DATA_test\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    # Reads all .txt files in a directory and returns a combined string of their contents.\n",
    "\n",
    "    file_contents = ''\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
    "                file_contents = file_contents + (f.read())\n",
    "    return file_contents\n",
    "\n",
    "texts = read_txt_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46fd835e-6d0d-4678-ba55-67a494f4174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 57 toponyms from this chunk.\n",
      "Extracted 0 toponyms from this chunk.\n",
      "Extracted 70 toponyms from this chunk.\n",
      "\n",
      "Stage 1 complete: Extracted 127 total toponym instances.\n",
      "JSON parsing error (text): Expecting value: line 1 column 1 (char 0)\n",
      "TEXT: Let's analyze each toponym instance, one by one, reflecting both on toponym resolution and emotion detection with optimal context window size, to maximize confidence and accuracy.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Haute-Loire (119–130)\n",
      "**Assessment:**  \n",
      "The text says:  \n",
      "\"During rest hour Mrs. Cavailhon called me. She received a letter asking whether she wanted to send some children to a very nice school in Haute-Loire at an elevation of one thousand meters.\"  \n",
      "Haute-Loire is a department in south-central France, historically well known for hosting Le Chambon-sur-Lignon and other safe havens for refugees. In WWII context, “Haute-Loire” unambiguously refers to this French administrative region.  \n",
      "**Coordinates:** 45.0477, 3.8886  \n",
      "\n",
      "**Emotion context optimization:**  \n",
      "The broader context is a mix of anxiety (not knowing if it’s safe) and hope (nice school, possibility of safety), but the dominant immediate emotion is apprehension or fear, given: “she is afraid that perhaps I won’t be safe there.”  \n",
      "Context to maximize emotion confidence: include from \"She received a letter asking\" to \"she is afraid that perhaps I won't be safe there.\"\n",
      "\n",
      "---\n",
      "\n",
      "### 2. La Rouvière (258–270)\n",
      "**Assessment:**  \n",
      "\"Mr. Brémond came to La Rouvière today.\"  \n",
      "“La Rouvière” can refer to several places in France, but in this context (WWII, children’s homes, near Le Chambon/Haute-Loire references), it almost certainly refers to the children’s home or property near Le Chambon-sur-Lignon, Haute-Loire, that was employed for refugee/rescue work.  \n",
      "**Coordinates:** Likely near Le Chambon-sur-Lignon: 45.06081, 4.302941\n",
      "\n",
      "**Emotion context optimization:**  \n",
      "The passage: “Mr. Brémond came to La Rouvière today. I practically flooded him with tears. Then he told me to pack my things within five minutes because he is taking me along.”   \n",
      "Emotion is strong sadness at first, then relief/happiness at being saved. Highest confidence in sadness in this earlier segment.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Les Caillols (451–463 and 587–599)\n",
      "**Assessment:**  \n",
      "Referenced twice, with context indicating a locality where children (or narrators) lived/stayed. “Les Caillols” is a district east of Marseille, Bouches-du-Rhône, France, known to have held homes for children evacuated during WWII.\n",
      "**Coordinates:** 43.3156, 5.4622\n",
      "\n",
      "**Emotion context optimization — first instance (451–463):**  \n",
      "The heading: “Tuesday, January 5, 1943 [Les Caillols]” followed by “Mrs. Brémond... wrote a letter to Mr. Trocmé...” and hope for opportunity: “I hope that I’ll be able to go there. The food there is fit for kings...”  \n",
      "Most likely emotion: hope/anticipation, but likely “joy” or “neutral” (emotional relief at prospect of help).\n",
      "\n",
      "**Emotion context optimization — second instance (587–599):**  \n",
      "“In Les Caillols and now lives at Les Grillons with Mr. Trocmé...” refers to location transfers. Less personal emotion, but continues from context above.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Les Grillons (629–641)\n",
      "**Assessment:**  \n",
      "\"Les Grillons\" is repeatedly described as a children’s home near Le Chambon-sur-Lignon, Haute-Loire, often referenced as a safehouse or farm for refugees.  \n",
      "**Coordinates:** Near Le Chambon-sur-Lignon: 45.06081, 4.302941\n",
      "\n",
      "**Emotion context optimization:**  \n",
      "Passage: “We arrived at Les Grillons at 2:30 a.m. There we ate something warm and then I went to sleep...” Safe haven after a difficult journey, strong relief/joy.\n",
      "\n",
      "---\n",
      "\n",
      "I will now prepare the detailed output per the required format, preserving all diagnostic detail per entity and ensuring I use the optimal block of text for each instance.\n",
      "\n",
      "---\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"toponym\": \"Haute-Loire\",\n",
      "    \"resolved_name\": \"Haute-Loire\",\n",
      "    \"latitude\": 45.0477,\n",
      "    \"longitude\": 3.8886,\n",
      "    \"emotion\": \"fear\",\n",
      "    \"confidence_score\": 0.94,\n",
      "    \"context\": \"She received a letter asking whether she wanted to send some children to a very nice school in Haute-Loire at an elevation of one thousand meters. She selected me and another boy. I'll be able to go there but she is afraid that perhaps I won't be safe there.\",\n",
      "    \"context_length\": 231,\n",
      "    \"original_range\": [119, 130]\n",
      "  },\n",
      "  {\n",
      "    \"toponym\": \"La Rouvière\",\n",
      "    \"resolved_name\": \"La Rouvière (children's home near Le Chambon-sur-Lignon, Haute-Loire)\",\n",
      "    \"latitude\": 45.06081,\n",
      "    \"longitude\": 4.302941,\n",
      "    \"emotion\": \"sadness\",\n",
      "    \"confidence_score\": 0.91,\n",
      "    \"context\": \"Mr. Brémond came to La Rouvière today.I practically flooded him with tears. Then he told me to pack my things within five minutes because he is taking me along.\",\n",
      "    \"context_length\": 143,\n",
      "    \"original_range\": [258, 270]\n",
      "  },\n",
      "  {\n",
      "    \"toponym\": \"Les Caillols\",\n",
      "    \"resolved_name\": \"Les Caillols (district of Marseille)\",\n",
      "    \"latitude\": 43.3156,\n",
      "    \"longitude\": 5.4622,\n",
      "    \"emotion\": \"joy\",\n",
      "    \"confidence_score\": 0.89,\n",
      "    \"context\": \"Tuesday, January 5, 1943 [Les Caillols] Mrs. Brémond (they got married) wrote a letter to Mr. Trocmé in which she asked him if he did not have an opening for me at his place. I had asked her to allow me to go to school. She gave this letter to a young girl, Simone Fullenbaum, who  lived  previously  at  Les  Caillols  and  now  lives  at  Les Grillons  with  Mr. Trocmé. I hope that I'll be able to go there. The food there is fit for kings (butter, potatoes, et cetera). Whatever is happening to you? Your son is thinking of you.\",\n",
      "    \"context_length\": 405,\n",
      "    \"original_range\": [451, 463]\n",
      "  },\n",
      "  {\n",
      "    \"toponym\": \"Les Caillols\",\n",
      "    \"resolved_name\": \"Les Caillols (district of Marseille)\",\n",
      "    \"latitude\": 43.3156,\n",
      "    \"longitude\": 5.4622,\n",
      "    \"emotion\": \"neutral\",\n",
      "    \"confidence_score\": 0.77,\n",
      "    \"context\": \"She gave this letter to a young girl, Simone Fullenbaum, who  lived  previously  at  Les  Caillols  and  now  lives  at  Les Grillons  with  Mr. Trocmé. I hope that I'll be able to go there. The food there is fit for kings (butter, potatoes, et cetera). Whatever is happening to you?\",\n",
      "    \"context_length\": 219,\n",
      "    \"original_range\": [587, 599]\n",
      "  },\n",
      "  {\n",
      "    \"toponym\": \"Les Grillons\",\n",
      "    \"resolved_name\": \"Les Grillons (children's home near Le Chambon-sur-Lignon, Haute-Loire)\",\n",
      "    \"latitude\": 45.06081,\n",
      "    \"longitude\": 4.302941,\n",
      "    \"emotion\": \"joy\",\n",
      "    \"confidence_score\": 0.97,\n",
      "    \"context\": \"We arrived at Les Grillons at 2:30 a.m. There we ate something warm and then I went to sleep in the annex (I only saw Mr. T.). Sunday, January 17, 1943 I got up at the stroke of nine [in the morning] and little by little got acquainted in the kitchen. It was really very nice and clean. Later, I went to see Amedée, the boy who was to come here with me. I played and thought a lot about you.\",\n",
      "    \"context_length\": 371,\n",
      "    \"original_range\": [629, 641]\n",
      "  }\n",
      "]\n",
      "Processed batch 1: 0 results.\n",
      "JSON parsing error (text): Expecting value: line 1 column 1 (char 0)\n",
      "TEXT: Let's create a plan, ensuring a thorough approach before proceeding to the function call.\n",
      "\n",
      "## Step 1: Disambiguating Toponyms\n",
      "There are five toponym instances listed:\n",
      "1. \"Marseilles\", twice (indices: 850-860 and 1136-1146)\n",
      "2. \"UGIF\" (968-972)\n",
      "3. \"Union Générale des Israélites de France\" (974-1012)\n",
      "4. \"Le Chambon sur Lignon\" (1043-1064)\n",
      "\n",
      "### Disambiguation logic and mapping:\n",
      "- \"Marseilles\": Refers clearly to the city in France, spelled \"Marseille\" in French. Key indicators: references to travel and context of WWII France.\n",
      "- \"UGIF\": Acronym for \"Union Générale des Israélites de France.\" Not a toponym (not a geographical place); it's an organization headquartered in Paris but not a place itself.\n",
      "- \"Union Générale des Israélites de France\": As above, it's a Jewish welfare organization, not a location; its headquarters was in Paris.\n",
      "- \"Le Chambon sur Lignon\": Refers to the town in Haute-Loire, France, well-documented in Holocaust history.\n",
      "  \n",
      "## Step 2: Extracting Emotional Contexts\n",
      "- For each instance, extract context windows around each occurrence (100–600 chars either side, as needed). For \"UGIF\" and \"Union Générale des Israélites de France\", per instructions, since these are not true place names, we'll attempt to resolve but must explain (should ultimately not return invalid/abstract locations).\n",
      "\n",
      "## Step 3: Expected Output\n",
      "- Array for each instance where the toponym is genuinely geographic, with all required details.\n",
      "- For non-geographic names, note that they're not valid for toponym resolution and return a reason.\n",
      "\n",
      "## Step 4: Operations for Each Toponym Instance\n",
      "1. Resolve the toponym to its specific geographic identity using context.\n",
      "2. For each, determine latitude/longitude.\n",
      "3. Slide context windows (100–600 chars either side), picking the window that yields the highest confidence for emotion detection (anger, disgust, fear, joy, sadness, surprise, neutral).\n",
      "4. Output the required record for every listed instance.\n",
      "\n",
      "## Next Step: \n",
      "Call the function with the five instances as specified. For UGIF/Union Générale des Israélites de France, attempt to resolve as Paris but return a note that this is an organization, not a location, if needed.\n",
      "\n",
      "Proceeding to function call now.\n",
      "Processed batch 2: 0 results.\n"
     ]
    },
    {
     "ename": "APITimeoutError",
     "evalue": "Request timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_exceptions.py:10\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:  \u001b[38;5;66;03m# noqa: PIE786\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpx\\_transports\\default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_sync\\http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_sync\\http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    106\u001b[0m     (\n\u001b[0;32m    107\u001b[0m         http_version,\n\u001b[0;32m    108\u001b[0m         status,\n\u001b[0;32m    109\u001b[0m         reason_phrase,\n\u001b[0;32m    110\u001b[0m         headers,\n\u001b[1;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    113\u001b[0m         http_version,\n\u001b[0;32m    114\u001b[0m         status,\n\u001b[0;32m    115\u001b[0m         reason_phrase,\n\u001b[0;32m    116\u001b[0m         headers,\n\u001b[0;32m    117\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_sync\\http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_sync\\http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    214\u001b[0m     )\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_backends\\sync.py:124\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    123\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {socket\u001b[38;5;241m.\u001b[39mtimeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(value)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mReadTimeout\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\openai\\_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    970\u001b[0m         request,\n\u001b[0;32m    971\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    972\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    915\u001b[0m     request,\n\u001b[0;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    919\u001b[0m )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    943\u001b[0m         request,\n\u001b[0;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpx\\_transports\\default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m    233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(value)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\httpx\\_transports\\default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mReadTimeout\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPITimeoutError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 162\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_num, toponym_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch(extracted_toponyms, batch_size)):\n\u001b[0;32m    158\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: texts,\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoponym_instances\u001b[39m\u001b[38;5;124m\"\u001b[39m: toponym_batch\n\u001b[0;32m    161\u001b[0m     }\n\u001b[1;32m--> 162\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mresponses\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    163\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4.1-2025-04-14\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    164\u001b[0m         instructions\u001b[38;5;241m=\u001b[39manalysis_instructions,\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(user_input),\n\u001b[0;32m    166\u001b[0m         text\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[0;32m    167\u001b[0m         reasoning\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    168\u001b[0m         tools\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    169\u001b[0m           {\n\u001b[0;32m    170\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    171\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolve_toponyms_and_detect_emotions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    172\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven the user input of the original text and the extracted toponyms from the previous step, determine latitude and longitude of each toponym and perform emotion detection on surrounding context for each toponym.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    173\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    174\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    175\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    176\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    177\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoponym_instances\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    178\u001b[0m                 ],\n\u001b[0;32m    179\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    180\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    182\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe text string from which to disambiguate toponyms and utilize their surrounding context.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m                   },\n\u001b[0;32m    184\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoponym_instances\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    185\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    186\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray of identified toponyms, each containing properties of location details and emotional context.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    187\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    188\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    189\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    190\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoponym\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    191\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    192\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe name of the toponym as found in the previous step.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m                         },\n\u001b[0;32m    194\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolved_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    195\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    196\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe name of the resolved toponym as identified and disambiguated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m                         },\n\u001b[0;32m    198\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    199\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe latitude coordinate of the toponym.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    201\u001b[0m                         },\n\u001b[0;32m    202\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    203\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    204\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe longitude coordinate of the toponym.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    205\u001b[0m                         },\n\u001b[0;32m    206\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    207\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    208\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe most likely detected emotion around the toponym.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    209\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menum\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    210\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manger\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisgust\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    212\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msadness\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m                           ]\n\u001b[0;32m    218\u001b[0m                         },\n\u001b[0;32m    219\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    220\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe confidence score for the detected emotion, on a scale of 0 to 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m                         },\n\u001b[0;32m    223\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    224\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe text block surrounding the toponym used for emotion detection, whose length is determined based on trying different lengths and seeing which one gives the highest confidence score for the most likely detected emotion.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m                         },\n\u001b[0;32m    227\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    228\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    229\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length, in characters including spaces, of the final text block surrounding the toponym used for emotion detection.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                         },\n\u001b[0;32m    231\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_range\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    232\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    233\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe original start and end position in the text of the toponym.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m                         }\n\u001b[0;32m    235\u001b[0m                       },\n\u001b[0;32m    236\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    237\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoponym\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    238\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolved_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    239\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    240\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    241\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    242\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    243\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    244\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    245\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_range\u001b[39m\u001b[38;5;124m\"\u001b[39m                          \n\u001b[0;32m    246\u001b[0m                       ],\n\u001b[0;32m    247\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditionalProperties\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    248\u001b[0m                     }\n\u001b[0;32m    249\u001b[0m                   }\n\u001b[0;32m    250\u001b[0m                 },\n\u001b[0;32m    251\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditionalProperties\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    252\u001b[0m               },\n\u001b[0;32m    253\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    254\u001b[0m           }\n\u001b[0;32m    255\u001b[0m         ],\n\u001b[0;32m    256\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    257\u001b[0m         max_output_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32768\u001b[39m,\n\u001b[0;32m    258\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    259\u001b[0m         store\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     )\n\u001b[0;32m    262\u001b[0m     batch_result \u001b[38;5;241m=\u001b[39m extract_json_from_arguments(response)\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# Either a list (preferred), or a dict with a .toponym_instances key\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\openai\\resources\\responses\\responses.py:656\u001b[0m, in \u001b[0;36mResponses.create\u001b[1;34m(self, input, model, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    655\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response \u001b[38;5;241m|\u001b[39m Stream[ResponseStreamEvent]:\n\u001b[1;32m--> 656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    657\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/responses\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    658\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    659\u001b[0m             {\n\u001b[0;32m    660\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    661\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    662\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m: include,\n\u001b[0;32m    663\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: instructions,\n\u001b[0;32m    664\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_output_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_output_tokens,\n\u001b[0;32m    665\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    666\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    667\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevious_response_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: previous_response_id,\n\u001b[0;32m    668\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning,\n\u001b[0;32m    669\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    670\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    671\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    672\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    673\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[0;32m    674\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    675\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    676\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    677\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncation\u001b[39m\u001b[38;5;124m\"\u001b[39m: truncation,\n\u001b[0;32m    678\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    679\u001b[0m             },\n\u001b[0;32m    680\u001b[0m             response_create_params\u001b[38;5;241m.\u001b[39mResponseCreateParamsStreaming\n\u001b[0;32m    681\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m    682\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params\u001b[38;5;241m.\u001b[39mResponseCreateParamsNonStreaming,\n\u001b[0;32m    683\u001b[0m         ),\n\u001b[0;32m    684\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    685\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    686\u001b[0m         ),\n\u001b[0;32m    687\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mResponse,\n\u001b[0;32m    688\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    689\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ResponseStreamEvent],\n\u001b[0;32m    690\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM_spaCy\\Lib\\site-packages\\openai\\_base_client.py:987\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 987\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    989\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAPITimeoutError\u001b[0m: Request timed out."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Developing function to identify and resolve toponyms, and detect emotions in context \n",
    "on either side of each toponym.  Context length is based on trying different lengths,\n",
    "with the final context length chosen based on which gives the most likely detected emotion\n",
    "with the highest confidence score.\n",
    "\n",
    "\"\"\"\n",
    "# Access libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Set a global variable for my OpenAI API key so that the model can be accessed.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_KEY\"\n",
    "client = OpenAI()\n",
    "\n",
    "# Alternative data for testing:\n",
    "#texts = \"I traveled from Paris to Berlin and saw New York on the way.  It was fantastic.  I was so happy.\"\n",
    "\n",
    "# ====== General Utility: Robust Extraction ======\n",
    "def extract_json_from_arguments(response):\n",
    "    \"\"\"\n",
    "    Robust extraction for OpenAI responses.\n",
    "    Handles both function call and text output scenarios.\n",
    "    Returns dict or list or [].\n",
    "    \"\"\"\n",
    "    # Case 1: Function call pattern\n",
    "    if hasattr(response, \"output\") and response.output:\n",
    "        first = response.output[0]\n",
    "        if hasattr(first, \"arguments\"):  # should be a string\n",
    "            arguments_string = first.arguments\n",
    "            if isinstance(arguments_string, (str, bytes)):\n",
    "                try:\n",
    "                    return json.loads(arguments_string)\n",
    "                except Exception as e:\n",
    "                    print(f\"JSON parsing error: {e}\\nARGUMENTS STRING: {arguments_string}\")\n",
    "                    return []\n",
    "            else:\n",
    "                # If already parsed (rare)\n",
    "                return arguments_string\n",
    "        # If it's classic text response\n",
    "        if hasattr(first, \"content\") and first.content:\n",
    "            text_fragment = getattr(first.content[0], \"text\", None)\n",
    "            if text_fragment:\n",
    "                try:\n",
    "                    return json.loads(text_fragment)\n",
    "                except Exception as e:\n",
    "                    print(f\"JSON parsing error (text): {e}\\nTEXT: {text_fragment}\")\n",
    "                    return []\n",
    "    # Case 2: Tool-style .outputs (not present in your current responses)\n",
    "    if hasattr(response, \"outputs\") and response.outputs and hasattr(response.outputs[0], \"arguments\"):\n",
    "        arguments = response.outputs[0].arguments\n",
    "        if arguments is not None:\n",
    "            return arguments\n",
    "    print(\"No recognizable output format found in OpenAI response.\")\n",
    "    return []\n",
    "\n",
    "# ====== Utility: Chunk Text for Context Window ======\n",
    "def chunk_text(text, chunk_size=17000, overlap=1000):\n",
    "    chunks = []\n",
    "    idx = 0\n",
    "    while idx < len(text):\n",
    "        end = min(len(text), idx + chunk_size)\n",
    "        chunk = text[idx:end]\n",
    "        chunks.append((chunk, idx))\n",
    "        idx += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def batch(lst, n):\n",
    "    \"\"\"Yield successive n-sized batches from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "# ====== 1. Load Prompts ======\n",
    "with open(\"openai_ToponymExtraction_prompt_complicated.txt\", encoding=\"utf-8\") as f:\n",
    "    extraction_instructions = f.read()\n",
    "with open(\"openai_ToponymEmotionAnalysis_prompt_complicated.txt\", encoding=\"utf-8\") as f:\n",
    "    analysis_instructions = f.read()\n",
    "\n",
    "# ====== 2. Stage One: Extract Toponyms ======\n",
    "chunks = chunk_text(texts)\n",
    "extracted_toponyms = []\n",
    "for chunk, offset in chunks:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "        instructions=extraction_instructions,\n",
    "        input=chunk,\n",
    "        text={\"format\": {\"type\": \"text\"}},\n",
    "        reasoning={},\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"name\": \"recognize_toponyms\",\n",
    "                \"description\": \"Given the user input text, identify all the toponyms in the text.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"required\": [\"input_text\", \"toponyms\"],\n",
    "                    \"properties\": {\n",
    "                        \"input_text\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The text string from which to recognize and identify toponyms.\"\n",
    "                        },\n",
    "                        \"toponyms\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"description\": \"Array of recognized and identified toponyms.\",\n",
    "                            \"items\": {\n",
    "                              \"type\": \"object\",\n",
    "                              \"properties\": {\n",
    "                                \"toponym\": {\"type\": \"string\"},\n",
    "                                \"start_idx\": {\"type\": \"integer\"},\n",
    "                                \"end_idx\": {\"type\": \"integer\"}\n",
    "                              },\n",
    "                              \"required\": [\"toponym\", \"start_idx\", \"end_idx\"],\n",
    "                              \"additionalProperties\": False\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"additionalProperties\": False\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        ],\n",
    "        temperature=1.0,\n",
    "        max_output_tokens=32768,\n",
    "        top_p=1,\n",
    "        store=True\n",
    "    )\n",
    "    toponyms_chunk = extract_json_from_arguments(response)\n",
    "    if isinstance(toponyms_chunk, list):\n",
    "        # Toponyms immediately\n",
    "        for t in toponyms_chunk:\n",
    "            if 'start_idx' in t: t[\"start_idx\"] += offset\n",
    "            if 'end_idx' in t: t[\"end_idx\"] += offset\n",
    "        extracted_toponyms += toponyms_chunk\n",
    "        print(f\"Extracted {len(toponyms_chunk)} toponyms from this chunk.\")\n",
    "    elif isinstance(toponyms_chunk, dict) and \"toponyms\" in toponyms_chunk:\n",
    "        # Sometimes a dict with .toponyms key\n",
    "        for t in toponyms_chunk[\"toponyms\"]:\n",
    "            if 'start_idx' in t: t[\"start_idx\"] += offset\n",
    "            if 'end_idx' in t: t[\"end_idx\"] += offset\n",
    "        extracted_toponyms += toponyms_chunk[\"toponyms\"]\n",
    "        print(f\"Extracted {len(toponyms_chunk['toponyms'])} toponyms from this chunk.\")\n",
    "    else:\n",
    "        print(f\"Extracted 0 toponyms from this chunk (result was {toponyms_chunk!r})\")\n",
    "\n",
    "print(f\"\\nStage 1 complete: Extracted {len(extracted_toponyms)} total toponym instances.\")\n",
    "with open(\"extracted_toponyms.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(extracted_toponyms, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ====== 3. Stage Two: Toponym Analysis ======\n",
    "analysis_results = []\n",
    "batch_size = 5  # Adjust as appropriate for your response size\n",
    "\n",
    "for batch_num, toponym_batch in enumerate(batch(extracted_toponyms, batch_size)):\n",
    "    user_input = {\n",
    "        \"original_text\": texts,\n",
    "        \"toponym_instances\": toponym_batch\n",
    "    }\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "        instructions=analysis_instructions,\n",
    "        input=json.dumps(user_input),\n",
    "        text={\"format\": {\"type\": \"text\"}},\n",
    "        reasoning={},\n",
    "        tools=[\n",
    "          {\n",
    "              \"type\": \"function\",\n",
    "              \"name\": \"resolve_toponyms_and_detect_emotions\",\n",
    "              \"description\": \"Given the user input of the original text and the extracted toponyms from the previous step, determine latitude and longitude of each toponym and perform emotion detection on surrounding context for each toponym.\",\n",
    "              \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"required\": [\n",
    "                  \"original_text\",\n",
    "                  \"toponym_instances\"\n",
    "                ],\n",
    "                \"properties\": {\n",
    "                  \"original_text\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The text string from which to disambiguate toponyms and utilize their surrounding context.\"\n",
    "                  },\n",
    "                  \"toponym_instances\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"Array of identified toponyms, each containing properties of location details and emotional context.\",\n",
    "                    \"items\": {\n",
    "                      \"type\": \"object\",\n",
    "                      \"properties\": {\n",
    "                        \"toponym\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"description\": \"The name of the toponym as found in the previous step.\"\n",
    "                        },\n",
    "                        \"resolved_name\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"description\": \"The name of the resolved toponym as identified and disambiguated.\"\n",
    "                        },\n",
    "                        \"latitude\": {\n",
    "                          \"type\": \"number\",\n",
    "                          \"description\": \"The latitude coordinate of the toponym.\"\n",
    "                        },\n",
    "                        \"longitude\": {\n",
    "                          \"type\": \"number\",\n",
    "                          \"description\": \"The longitude coordinate of the toponym.\"\n",
    "                        },\n",
    "                        \"emotion\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"description\": \"The most likely detected emotion around the toponym.\",\n",
    "                          \"enum\": [\n",
    "                            \"anger\",\n",
    "                            \"disgust\",\n",
    "                            \"fear\",\n",
    "                            \"joy\",\n",
    "                            \"sadness\",\n",
    "                            \"surprise\",\n",
    "                            \"neutral\"\n",
    "                          ]\n",
    "                        },\n",
    "                        \"confidence_score\": {\n",
    "                          \"type\": \"number\",\n",
    "                          \"description\": \"The confidence score for the detected emotion, on a scale of 0 to 1.\"\n",
    "                        },\n",
    "                        \"context\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"description\": \"The text block surrounding the toponym used for emotion detection, whose length is determined based on trying different lengths and seeing which one gives the highest confidence score for the most likely detected emotion.\"\n",
    "                        },\n",
    "                        \"context_length\": {\n",
    "                          \"type\": \"number\",\n",
    "                          \"description\": \"The length, in characters including spaces, of the final text block surrounding the toponym used for emotion detection.\"\n",
    "                        },\n",
    "                        \"original_range\": {\n",
    "                          \"type\": \"number\",\n",
    "                          \"description\": \"The original start and end position in the text of the toponym.\"\n",
    "                        }\n",
    "                      },\n",
    "                      \"required\": [\n",
    "                        \"toponym\",\n",
    "                        \"resolved_name\",\n",
    "                        \"latitude\",\n",
    "                        \"longitude\",\n",
    "                        \"emotion\",\n",
    "                        \"confidence_score\",\n",
    "                        \"context\",\n",
    "                        \"context_length\",\n",
    "                        \"original_range\"                          \n",
    "                      ],\n",
    "                      \"additionalProperties\": False\n",
    "                    }\n",
    "                  }\n",
    "                },\n",
    "                \"additionalProperties\": False\n",
    "              },\n",
    "              \"strict\": True\n",
    "          }\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_output_tokens=32768,\n",
    "        top_p=1,\n",
    "        store=True\n",
    "    )\n",
    "\n",
    "    batch_result = extract_json_from_arguments(response)\n",
    "    # Either a list (preferred), or a dict with a .toponym_instances key\n",
    "    if isinstance(batch_result, list):\n",
    "        analysis_results += batch_result\n",
    "        print(f\"Processed batch {batch_num+1}: {len(batch_result)} results.\")\n",
    "    elif isinstance(batch_result, dict) and \"toponym_instances\" in batch_result:\n",
    "        batch_list = batch_result[\"toponym_instances\"]\n",
    "        analysis_results += batch_list\n",
    "        print(f\"Processed batch {batch_num+1}: {len(batch_list)} results (from dict).\")\n",
    "    else:\n",
    "        print(f\"Processed batch {batch_num+1}: 0 results (batch_result was {batch_result!r})\")\n",
    "\n",
    "print(f\"\\nStage 2 complete: Produced {len(analysis_results)} detailed toponym analyses.\")\n",
    "with open(\"analysis_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(analysis_results, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19db9c7c-4673-4dd4-954d-b12208729eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW RESPONSE: Response(id='resp_683793512c8c8191bee5e5ea4a5d7f020823006e689be9ad', created_at=1748472657.0, error=None, incomplete_details=None, instructions='## IDENTITY\\nYou are a natural language processer now performing both toponym resolution \\nand emotion detection.  \\n\\n## INSTRUCTIONS\\nFor each toponym instance below (with its position in the provided text), do all of the following:\\n- Use context to disambiguate to the correct modern or historic entity and obtain coordinates (latitude, longitude).\\n- Extract several blocks of text (100–600 chars each side). For each, run emotion detection (anger, disgust, fear, joy, sadness, surprise, neutral), select the emotion+window with highest confidence score, and record:\\n    - toponym (as-found),\\n    - resolved_name,\\n    - latitude,\\n    - longitude,\\n    - detected emotion,\\n    - confidence score,\\n    - text block used,\\n    - length of text block used (in characters, including spaces),\\n    - original start & end positions.\\nReturn an array as in:\\n[\\n  {\\n    \"toponym\": \"...\",\\n    \"resolved_name\": \"...\",\\n    \"latitude\": ...,\\n    \"longitude\": ...,\\n    \"emotion\": \"...\",\\n    \"confidence_score\": ...,\\n    \"context\": \"...\",\\n    \"context_length\": \"...\",\\n    \"original_range\": [start, end]\\n  },\\n  ...\\n]\\nDo not aggregate or skip duplicates.\\n', metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseFunctionToolCall(arguments='{\"original_text\":\"\\\\u0000Monday, September 21, 1942 \\\\nI am sad and weary. During rest hour Mrs. Cavailhon called me. She \\\\nreceived a letter asking whether she wanted to send some children to a very nice \\\\nschool in Haute-Loire at an elevation of one thousand meters.  She selected me \\\\nand another boy. I\\'ll be able to go there but she is afraid that perhaps I \\\\nwon\\'t be safe there. \\\\nMonday, January 4, 1943 \\\\nMr. Br\\\\u001e9mond came to La Rouvi\\\\u00100re today.I practically flooded him with tears. \\\\nThen he told me to pack my things within five minutes because he is \\\\ntaking me along. I can tell you that I was happy. \\\\nTuesday, January 5, 1943 [Les Caillols] \\\\nMrs. Br\\\\u00100mond (they got married) wrote a letter to Mr. Trocm\\\\u00100 in \\\\nwhich she asked him if he did not have an opening for me at his place. I had \\\\nasked her to allow me to go to school. She gave this letter to a young girl, Simone \\\\nFullenbaum, who  lived  previously  at  Les  Caillols  and  now  lives  at  Les \\\\nGrillons  with  Mr. Trocm\\\\u00100. I hope that I\\'ll be able to go there. The food there is fit for \\\\nkings (butter, potatoes, et cetera). Whatever is happening to you? Your son is \\\\nthinking of you. \\\\nFriday, January 15, 1943 \\\\nWe were told that we\\'ll have to get out in two or three days. When I \\\\nreturned from Marseilles at noon, Mrs. B. told me that she received a telegram from Mr. \\\\nTrocm\\\\u00100. He has a vacancy and expects me as soon as possible. Once again I am in \\\\nluck. I quickly packed my suitcases so as to be able to leave early Saturday at \\\\n7:20 a.m. At the same time, the thing from the UGIF [Union G\\\\u00145n\\\\u00145rale des Isra\\\\u00145lites de \\\\nFrance] arrived. \\\\nSaturday, January 16, 1943 [ Le Chambon sur Lignon] \\\\nI took leave, took the first streetcar at 6 a.m. and at 7:20 a.m. I left aboard the \\\\nMarseilles to Paris express (travel, change train, bus, wrong [place?], \\\\nLavoulte bridge, telephone, fast train, Cheylard local train, St. Agr\\\\u00100ve). I arrived at \\\\nSt. Agr\\\\u00100ve at 11:49 p.m. The train did not go beyond there. \\\\nMr. Trocm\\\\u00100 came on his bicycle to meet me (still a young man and very nice). \\\\nNow we still had to cover fifteen kilometers through the snow and a moonlit night. \\\\nWe arrived at Les Grillons at 2:30 a.m. There we ate something warm and then I \\\\nw...\",\"toponym_instances\":[{\"toponym\":\"Chambon\",\"resolved_name\":\"Le Chambon-sur-Lignon, Haute-Loire, France\",\"latitude\":45.0606,\"longitude\":4.2931,\"emotion\":\"neutral\",\"confidence_score\":0.76,\"context\":\"...And I got confronted with people who were doing the sneaking \\\\nout of children. And so here and there I was find myself having a few \\\\nchildren on my hands and tried to find a place to put them. And so we \\\\nestablished a kind of a chain, being tremendously helped by the priest \\\\nand the nuns who were taking them into monasteries or in their own \\\\nquarters until they could place them in farm. \\\\nAnd this was really, the women were mainly involved in that. I mean, it \\\\nwas one of the big, one of the big way you could help. I mean, there \\\\nwere so many children who were abandoned, abandoned by the Germans, when \\\\nthey took their parents and left the children behind. I mean, and those \\\\nkids could practically speak no French. \\\\nAnd it was the biggest tragedy of that time was to have those people \\\\nwho came from Eastern Europe and escaped to France. And France was the \\\\nhaven. I mean, they thought nothing could happen to them when they got to \\\\nFrance. They didn\\'t realize that they would be picked up there just as \\\\nwell as they could have been in Germany or in Hungary or in Romania or \\\\nanywhere else. \\\\nAnd they never talked the language. And they were, they were easy prey \\\\nfor the Germans because they themselves didn\\'t have enough, enough \\\\nknowledge of a language. And if they spoke the language a little, they \\\\nhad a terrible accent. So they were immediately denounced. \\\\nAnd the children were usually left? \\\\nSometimes. Sometimes not, depending. \\\\nSo part of the resistance was to work together and find farms for \\\\nthese children? \\\\nYeah. We find place to, place to put them. And it was good that we \\\\nknew where they were, and we knew, we knew the kind of name they had. \\\\nAnd they were given the farmer\\'s name, of course. In many, many \\\\ninstance, 90% of the time, they didn\\'t think that the father was not \\\\ntheir parents. They thought they were their children. \\\\nThey didn\\'t know any better, to a point that when we finally were \\\\nliberated, and when we got those children back, I mean, they simply spat \\\\nin our face because they heard they were Jewish. They said, I don\\'t want \\\\nto die. I want to live. I don\\'t be, I\\'m not a Jewish person. I am not \\\\nJewish. Don\\'t tell me I\\'m Jewish. \\\\nAnd this was one of the greatest problems that we had, because to try to \\\\nget them by force, get them away, we established those children homes for \\\\nthat reason, to put them together and be able to educate them as Jewish \\\\nchildren and try to go beyond what they wanted, I mean, because they were \\\\ntoo young, anyway, to know what it was all about. But they had been fed \\\\nwith the terrible propaganda that the Germans did for five years. I mean, \\\\nevery day there was something against the Jews. There was never a day \\\\nwithout it. And so they learned that when you\\'re Jewish, you die. And \\\\nthat\\'s all they knew. \\\\nI mean, there is no way to know why you escape and why you survive. There \\\\nis no way. All I say is that if the war had last only for another six \\\\nmonths, we could no longer go, because we changed our name so many time. \\\\nWe changed our location so many times. We changed everything about \\\\nourselves. You could no more hide yourself. It was getting impossible. \\\\nYeah. I put my children in, I told you once about Le Chambon. I \\\\nmean, if you ever go to the museum, the Holocaust museum in Washington, \\\\nyou\\'ll see a very good display of what Chambon was. \\\\nIt was a little village up above Saint-Etienne, about 15 miles away. The \\\\nhead of that village was a famous pastor, a Protestant pastor by the name \\\\nof Trocme. He and his wife and the children lived, of course, in the, in \\\\nthe, what do you call the house that belongs to the church, where they \\\\nlive? \\\\nAnd there were 5,000 villager there. And somebody had heard that someone \\\\nin that village would hide them. So all of a sudden, one Jewish family \\\\ncame there and went to the pastor. And he gave them to a family. \\\\nAnd that family came to him after and said, what are we going to do with \\\\nthese people? We don\\'t want, we don\\'t want to be responsible for them. \\\\nThey can arrest us because we\\'re hiding them. We can\\'t do that. \\\\nSo the pastor took a whole bunch of people, there were 5,000 in that \\\\nvillage, and put them in a big place in the church and talked to them \\\\nand said to them, now, look. Our duty is to save these people. If they \\\\ncame to us, it\\'s because there is no other place to go to be saved, and \\\\nyou\\'re not going to denounce them. \\\\nAnd I\\'m telling you something. We have no weapon. We have nothing to \\\\ndefend them. We can\\'t defend ourselves. All we have are the weapons of \\\\nour spirit. And it\\'s going to have to act so that each and every one of \\\\nyou feel that it\\'s his duty to do something. And 5,000 villagers hid \\\\n5,000 Jews. \\\\nSo Le Chambon was a fantastic place. And there was a little, tiny \\\\nchildren boarding school there. And my children were there many times. \\\\nEvery time, something was wrong, every time I wasn\\'t sure what was going \\\\nto happen, I would bring them up there. \\\\u0000\",\"context_length\":1106,\"original_range\":3095}]}', call_id='call_SwT1EJoCrwo2kkyNt5RKoTl6', name='resolve_toponyms_and_detect_emotions', type='function_call', id='fc_68379355d4d88191bbc940833cbaf5140823006e689be9ad', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='resolve_toponyms_and_detect_emotions', parameters={'type': 'object', 'required': ['original_text', 'toponym_instances'], 'properties': {'original_text': {'type': 'string', 'description': 'The text string from which to disambiguate toponyms and utilize their surrounding context.'}, 'toponym_instances': {'type': 'array', 'description': 'Array of identified toponyms, each containing properties of location details and emotional context.', 'items': {'type': 'object', 'properties': {'toponym': {'type': 'string', 'description': 'The name of the toponym as found in the previous step.'}, 'resolved_name': {'type': 'string', 'description': 'The name of the resolved toponym as identified and disambiguated.'}, 'latitude': {'type': 'number', 'description': 'The latitude coordinate of the toponym.'}, 'longitude': {'type': 'number', 'description': 'The longitude coordinate of the toponym.'}, 'emotion': {'type': 'string', 'description': 'The most likely detected emotion around the toponym.', 'enum': ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']}, 'confidence_score': {'type': 'number', 'description': 'The confidence score for the detected emotion, on a scale of 0 to 1.'}, 'context': {'type': 'string', 'description': 'The text block surrounding the toponym used for emotion detection, whose length is determined based on trying different lengths and seeing which one gives the highest confidence score for the most likely detected emotion.'}, 'context_length': {'type': 'number', 'description': 'The length, in characters including spaces, of the final text block surrounding the toponym used for emotion detection.'}, 'original_range': {'type': 'number', 'description': 'The original start and end position in the text of the toponym.'}}, 'required': ['toponym', 'resolved_name', 'latitude', 'longitude', 'emotion', 'confidence_score', 'context', 'context_length', 'original_range'], 'additionalProperties': False}}}, 'additionalProperties': False}, strict=True, type='function', description='Given the user input of the original text and the extracted toponyms from the previous step, determine latitude and longitude of each toponym and perform emotion detection on surrounding context for each toponym.')], top_p=1.0, max_output_tokens=32768, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=0, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=0, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=0), user=None, background=False, store=True)\n",
      "RAW OUTPUTS: None\n"
     ]
    }
   ],
   "source": [
    "print(\"RAW RESPONSE:\", response)\n",
    "print(\"RAW OUTPUTS:\", getattr(response, \"outputs\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53d90d8a-b1f8-4507-84aa-0389fe053388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toponym</th>\n",
       "      <th>resolved_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>emotion</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>original_range</th>\n",
       "      <th>emotion_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paris</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>48.8566</td>\n",
       "      <td>2.3522</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.80</td>\n",
       "      <td>I traveled from Paris to Berlin and saw New Yo...</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>52.5200</td>\n",
       "      <td>13.4050</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.79</td>\n",
       "      <td>I traveled from Paris to Berlin and saw New Yo...</td>\n",
       "      <td>62</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York City, USA</td>\n",
       "      <td>40.7128</td>\n",
       "      <td>-74.0060</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.97</td>\n",
       "      <td>I traveled from Paris to Berlin and saw New Yo...</td>\n",
       "      <td>88</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toponym       resolved_name  latitude  longitude  emotion  \\\n",
       "0     Paris       Paris, France   48.8566     2.3522  neutral   \n",
       "1    Berlin     Berlin, Germany   52.5200    13.4050  neutral   \n",
       "2  New York  New York City, USA   40.7128   -74.0060      joy   \n",
       "\n",
       "   confidence_score                                            context  \\\n",
       "0              0.80  I traveled from Paris to Berlin and saw New Yo...   \n",
       "1              0.79  I traveled from Paris to Berlin and saw New Yo...   \n",
       "2              0.97  I traveled from Paris to Berlin and saw New Yo...   \n",
       "\n",
       "   context_length  original_range emotion_numeric  \n",
       "0              62              17               4  \n",
       "1              62              26               4  \n",
       "2              88              42               3  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take response output in json format, put into a dataframe, then assign numeric values \n",
    "# to the detected emotions.\n",
    "\n",
    "df = pd.DataFrame(analysis_results)\n",
    "\n",
    "conditions = [\n",
    "    df[\"emotion\"] == \"anger\",\n",
    "    df[\"emotion\"] == \"disgust\",\n",
    "    df[\"emotion\"] == \"fear\",\n",
    "    df[\"emotion\"] == \"joy\",\n",
    "    df[\"emotion\"] == \"neutral\",\n",
    "    df[\"emotion\"] == \"sadness\",\n",
    "    df[\"emotion\"] == \"surprise\"\n",
    "]\n",
    "values = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "df[\"emotion_numeric\"] = np.select(conditions, values, default=\"Unknown\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2222fa53-54b9-49a9-8fec-2d18892200cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to csv\n",
    "\n",
    "df.to_csv(\"Results8_ToponymsEmotions_smallSubCorpus.csv\", encoding=\"utf-8-sig\", index=False, header=True, mode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f13006-7409-41d6-b74e-4a80e4ff5414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
